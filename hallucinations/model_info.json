{
  "DeepSeek-V3.1-Reasoner": [
    671,
    37
  ],
  "Grok-3-beta-thinking-20250221": [
    2700,
    50
  ],
  "Qwen-3-14B-nothink": [
    14
  ],
  "Qwen-3-235B-A22B-nothink": [
    235,
    22
  ],
  "Qwen-3-30B-A3B-nothink": [
    30,
    3
  ],
  "Qwen-3-32B-nothink": [
    32
  ],
  "Qwen3-235B-A22B-Thinking-2507": [
    235,
    22
  ],
  "Qwen3-30B-A3B-2507-Thinking": [
    30,
    3
  ],
  "QwenQwQ-32B-Preview": [
    32
  ],
  "QwenQwen2.5-Coder-32B-Instruct": [
    32
  ],
  "QwenQwen3-14B": [
    14
  ],
  "QwenQwen3-235B-A22B": [
    235,
    22
  ],
  "QwenQwen3-30B-A3B": [
    30,
    3
  ],
  "QwenQwen3-32B": [
    32
  ],
  "ai21jamba-large-1.7": [
    398,
    94
  ],
  "ai21jamba-mini-1.7": [
    52,
    12
  ],
  "allenaiolmo-3-32b-think": [
    32
  ],
  "allenaiolmo-3-7b-instruct": [
    7
  ],
  "allenaiolmo-3-7b-think": [
    7
  ],
  "amazonnova-2-lite-v1": [],
  "arcee-aitrinity-mini": [
    26,
    3
  ],
  "baiduernie-4.5-21b-a3b-thinking": [
    21,
    3
  ],
  "baiduernie-4.5-300b-a47b": [
    300,
    47
  ],
  "chatgpt-4o-latest-2025-03-26": [
    400
  ],
  "claude-3-5-haiku-20241022": [
    80,
    20
  ],
  "claude-3-5-sonnet-20241022": [
    400,
    100
  ],
  "claude-3-7-sonnet-20250219": [
    400,
    100
  ],
  "claude-3-7-sonnet-thinkhigh-20250219": [
    400,
    100
  ],
  "claude-3-opus-20240229": [
    2000,
    250
  ],
  "claude-4-opus-20250514": [
    2000,
    250
  ],
  "claude-4-opus-thinking-20250514": [
    2000,
    250
  ],
  "claude-4-sonnet-20250514": [
    300,
    70
  ],
  "claude-4-sonnet-thinking-20250514": [
    300,
    70
  ],
  "claude-haiku-4-5-20251001": [
    80,
    20
  ],
  "claude-opus-4-1-20250805": [
    2000,
    250
  ],
  "claude-opus-4-1-thinking-20250805": [
    2000,
    250
  ],
  "claude-opus-4-5-20251101": [
    1700,
    170
  ],
  "claude-opus-4-5-thinking-20251101": [
    1700,
    170
  ],
  "claude-sonnet-4-5-20250929": [
    300,
    70
  ],
  "claude-sonnet-4-5-thinking-20250929": [
    300,
    70
  ],
  "codestral-2501": [
    24
  ],
  "cogito14b-v1-preview-qwen-fp16": [
    14
  ],
  "deepseek-aiDeepSeek-R1": [
    671,
    37
  ],
  "deepseek-aiDeepSeek-R1-0528": [
    671,
    37
  ],
  "deepseek-aiDeepSeek-R1-Distill-Llama-70B": [
    70
  ],
  "deepseek-aiDeepSeek-R1-Distill-Qwen-32B": [
    32
  ],
  "deepseek-aiDeepSeek-V3": [
    671,
    37
  ],
  "deepseek-aiDeepSeek-V3-0324": [
    671,
    37
  ],
  "deepseek-aiDeepSeek-V3.1": [
    671,
    37
  ],
  "deepseekdeepseek-r1-distill-llama-8b": [
    8
  ],
  "deepseekdeepseek-r1-distill-qwen-1.5b": [
    1.5
  ],
  "deepseekdeepseek-r1-distill-qwen-14b": [
    14
  ],
  "deepseekdeepseek-r1-distill-qwen-7b": [
    7
  ],
  "deepseekdeepseek-r1-zerofree": [
    671,
    37
  ],
  "deepseekdeepseek-v3.2-exp": [
    671,
    37
  ],
  "deepseekdeepseek-v3.2-exp-thinking": [
    671,
    37
  ],
  "deepseekdeepseek-v3.2-speciale-thinking": [
    671,
    37
  ],
  "deepseekdeepseek-v3.2-thinking": [
    671,
    37
  ],
  "devstral-medium-2507": [
    24
  ],
  "essentialairnj-1-instruct": [
    8
  ],
  "exaone-deep2.4b-fp16": [
    2.4
  ],
  "exaone-deep32b-fp16": [
    32
  ],
  "exaone-deep7.8b-fp16": [
    7.8
  ],
  "falcon310b-instruct-q8": [
    10
  ],
  "falcon33b-instruct-q8": [
    3
  ],
  "falcon37b-instruct-q8": [
    7
  ],
  "gemini-1.5-pro-002": [
    1200,
    120
  ],
  "gemini-2.0-flash": [
    40,
    18
  ],
  "gemini-2.0-flash-lite": [
    10,
    2.5
  ],
  "gemini-2.5-flash-09-2025-nothink": [
    400,
    20
  ],
  "gemini-2.5-flash-09-2025-thinkhigh": [
    400,
    20
  ],
  "gemini-2.5-flash-lite-09-2025-nothink": [
    10,
    2.5
  ],
  "gemini-2.5-flash-lite-09-2025-thinkhigh": [
    10,
    2.5
  ],
  "gemini-2.5-flash-lite-nothink": [
    10,
    2.5
  ],
  "gemini-2.5-flash-lite-thinkhigh": [
    10,
    2.5
  ],
  "gemini-2.5-flash-nothink": [
    400,
    20
  ],
  "gemini-2.5-flash-thinkhigh": [
    400,
    20
  ],
  "gemini-2.5-pro-thinkhigh": [
    1500,
    40
  ],
  "gemini-2.5-pro-thinklow": [
    1500,
    40
  ],
  "gemini-3-flash-preview-nothink": [],
  "gemini-3-flash-preview-thinkhigh": [],
  "gemini-3-pro-preview": [
    7500,
    40
  ],
  "gemma-3n-e4b-it": [
    4
  ],
  "gemma312b-it-q8": [
    12
  ],
  "gemma31b-it-q8": [
    1
  ],
  "gemma3270m": [
    0.27
  ],
  "gemma327b-it-q8": [
    27
  ],
  "gemma34b-it-q8": [
    4
  ],
  "gpt-3.5-turbo": [
    20
  ],
  "gpt-4-turbo-2024-04-09": [
    1800,
    280
  ],
  "gpt-4.1-2025-04-14": [
    200,
    32
  ],
  "gpt-4.1-mini-2025-04-14": [
    60,
    8
  ],
  "gpt-4.1-nano-2025-04-14": [
    17,
    2
  ],
  "gpt-4.5-preview": [
    6000,
    600
  ],
  "gpt-4o-2024-05-13": [
    400
  ],
  "gpt-4o-2024-11-20": [
    400
  ],
  "gpt-4o-mini-2024-07-18": [
    8
  ],
  "gpt-5-2025-08-07": [
    200,
    32
  ],
  "gpt-5-2025-08-07-HIGH": [
    200,
    32
  ],
  "gpt-5-chat-latest-2025-08-08": [
    200,
    23
  ],
  "gpt-5-chat-latest-2025-08-22": [
    200,
    23
  ],
  "gpt-5-mini-2025-08-07": [
    60,
    8
  ],
  "gpt-5-nano-2025-08-07": [
    17,
    2
  ],
  "gpt-5-pro-2025-10-06": [
    200,
    23
  ],
  "gpt-5.1-2025-11-13-HIGH": [
    200,
    23
  ],
  "gpt-5.1-2025-11-13-NONE": [
    200,
    23
  ],
  "gpt-5.1-codex-max-XHIGH": [
    200,
    23
  ],
  "gpt-5.2-2025-12-11-HIGH": [],
  "gpt-5.2-2025-12-11-NONE": [],
  "gpt-5.2-2025-12-11-XHIGH": [],
  "gpt-oss-120b": [
    117,
    5.1
  ],
  "gpt-oss-20b": [
    21,
    3.6
  ],
  "granite3.3": [
    8
  ],
  "granite4micro": [
    3
  ],
  "granite4micro-h": [
    3
  ],
  "granite4small-h": [
    32,
    9
  ],
  "granite4tiny-h": [
    7,
    1
  ],
  "grok-2-1212": [
    400
  ],
  "grok-3": [
    2700,
    50
  ],
  "grok-3-mini-high": [
    250,
    35
  ],
  "grok-3-mini-low": [
    250,
    35
  ],
  "grok-4-0709": [
    2700,
    50
  ],
  "grok-4-1-fast-non-reasoning": [
    500,
    30
  ],
  "grok-4-1-fast-reasoning": [
    500,
    30
  ],
  "grok-4-fast-non-reasoning": [
    500,
    30
  ],
  "grok-4-fast-reasoning": [
    500,
    30
  ],
  "grok-code-fast-1": [
    300,
    80
  ],
  "ibmgranite41b-h": [
    1
  ],
  "ibmgranite4350m-h": [
    0.35
  ],
  "inceptionmercury": [
    15
  ],
  "liquidlfm-2.2-6b": [
    6
  ],
  "liquidlfm2-8b-a1b": [
    8,
    1
  ],
  "magistral-medium-2506": [
    70
  ],
  "magistral-medium-2509": [
    70
  ],
  "magistral-small-2506": [
    24
  ],
  "magistral-small-2509": [
    24
  ],
  "meta-llamaLlama-3.3-70B-Instruct": [
    70
  ],
  "meta-llamallama-4-maverick": [
    400,
    17
  ],
  "meta-llamallama-4-scout": [
    100,
    17
  ],
  "microsoftPhi-4-multimodal-instruct": [
    5.6
  ],
  "microsoftWizardLM-2-8x22B": [
    176
  ],
  "microsoftphi-4": [
    14
  ],
  "minimaxminimax-m2free": [
    230,
    10
  ],
  "ministral-14b-2512": [
    14
  ],
  "ministral-3b-2410": [
    3
  ],
  "ministral-3b-2512": [
    3
  ],
  "ministral-8b-2512": [
    8
  ],
  "mistral-large-2411": [
    123
  ],
  "mistral-large-2512": [
    675,
    41
  ],
  "mistral-medium-2505": [
    70
  ],
  "mistral-medium-2508": [
    70
  ],
  "mistral-small-2501": [
    24
  ],
  "mistral-small-2503": [
    24
  ],
  "mistral-small-2506": [
    24
  ],
  "moonshotaikimi-k2": [
    1000,
    32
  ],
  "moonshotaikimi-k2-0905": [
    1000,
    32
  ],
  "moonshotaikimi-k2-thinking": [
    1000,
    32
  ],
  "moonshotaikimi-linear-48b-a3b-instruct": [
    1000,
    32
  ],
  "nousresearchhermes-4-70b": [
    70
  ],
  "nvidiaLlama-3.1-Nemotron-70B-Instruct": [
    70
  ],
  "nvidiallama-3.1-nemotron-ultra-253b-v1-thinkenab": [
    253
  ],
  "nvidiallama-3.3-nemotron-super-49b-v1-thinkenab": [
    49
  ],
  "nvidiallama-3.3-nemotron-super-49b-v1.5-thinking": [
    49
  ],
  "nvidianemotron-3-nano-30b-a3b-thinking": [
    30,
    3
  ],
  "nvidianemotron-nano-9b-v2-thinking": [
    9
  ],
  "o1-2024-12-17": [
    300
  ],
  "o1-mini-2024-09-12": [
    60,
    8
  ],
  "o3-2025-04-16": [
    200,
    32
  ],
  "o3-2025-04-16-codeinterpr": [
    200,
    32
  ],
  "o3-2025-04-16-search": [
    200,
    32
  ],
  "o3-mini-2025-01-31": [
    60,
    8
  ],
  "o3-mini-20250131-HIGH": [
    60,
    8
  ],
  "o3-pro-2025-06-10": [
    200,
    32
  ],
  "o3-pro-2025-06-10-HIGH": [
    200,
    32
  ],
  "o3-pro-2025-06-10-codeinterpr": [
    200,
    32
  ],
  "o3-pro-2025-06-10-search": [
    200,
    32
  ],
  "o4-mini-2025-04-16-HIGH": [
    60,
    8
  ],
  "o4-mini-2025-04-16-codeinterpr-HIGH": [
    60,
    8
  ],
  "o4-mini-2025-04-16-search-HIGH": [
    60,
    8
  ],
  "olmo27b-1124-instruct-q8": [
    7
  ],
  "open-mixtral-8x22b": [
    176
  ],
  "openaigpt-5-codex": [
    200,
    23
  ],
  "openrouterbert-nebulon-alpha": [
    675,
    41
  ],
  "openroutercypher-alphafree": [
    12,
    3
  ],
  "openrouterhorizon-alpha": [
    5,
    117
  ],
  "openrouterhorizon-beta": [
    5,
    117
  ],
  "phi4-mini-reasoning": [
    3.8
  ],
  "phi4-reasoning": [
    14
  ],
  "phi4-reasoningplus": [
    14
  ],
  "pixtral-12b-2409": [
    12
  ],
  "pixtral-large-2411": [
    123
  ],
  "prime-intellectintellect-3": [
    106,
    12
  ],
  "qwen-max-2025-01-25": [
    325
  ],
  "qwen-plus-2025-04-28": [
    271,
    37
  ],
  "qwen-qwq-32b-nostepbystep": [
    32
  ],
  "qwen-qwq-32b-stepbystep": [
    32
  ],
  "qwen-turbo-2025-04-28": [
    42,
    6
  ],
  "qwen2.5-14b-instruct-1m": [
    14
  ],
  "qwen2.5-32b-instruct": [
    32
  ],
  "qwen2.5-72b-instruct": [
    72
  ],
  "qwen2.5-7b-instruct-1m": [
    7
  ],
  "qwen2.5-omni-7b": [
    7
  ],
  "qwen30.6b": [
    0.6
  ],
  "qwen31.7b": [
    1.7
  ],
  "qwen34b": [
    4
  ],
  "qwen34b-instruct-2507-q8": [
    4
  ],
  "qwen34b-thinking-2507-q8": [
    4
  ],
  "qwen38b": [
    8
  ],
  "qwenqwen3-235b-a22b-07-25": [
    235,
    22
  ],
  "qwenqwen3-30b-a3b-instruct-2507": [
    30,
    3
  ],
  "qwenqwen3-coder": [
    480,
    35
  ],
  "qwenqwen3-max": [
    1175,
    110
  ],
  "qwenqwen3-next-80b-a3b-instruct": [
    80,
    3
  ],
  "qwenqwen3-next-80b-a3b-thinking": [
    80,
    3
  ],
  "r1-1776": [
    671,
    37
  ],
  "sonar-pro": [
    70
  ],
  "sonar-reasoning-pro": [
    70
  ],
  "thudmglm-4.1v-9b-thinking": [
    9
  ],
  "thudmglm-z1-32b": [
    32
  ],
  "thudmglm-z1-9bfree": [
    9
  ],
  "xiaomimimo-v2-flashfree": [
    309,
    15
  ],
  "z-aiglm-4.5": [
    355,
    32
  ],
  "z-aiglm-4.5-air": [
    106,
    12
  ],
  "z-aiglm-4.6": [
    355,
    32
  ]
}