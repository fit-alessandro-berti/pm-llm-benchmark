{
  "categories": {
    "1a_instruction_override": { "count": 0, "instances": [] },
    "1b_context_omission": { "count": 0, "instances": [] },
    "1c_prompt_contradiction": { "count": 1, "instances": [
      {
        "snippet": "Gateway 1 leads directly to 'Send back to Supplier' and 'End Event: Invoice Rejected' contradicting Mary and others",
        "why": "This statement contradicts the prompt context, as several interviewees describe follow-up actions before rejection, not immediate rejection at Gateway 1.",
        "severity": "high"
      }
    ] },
    "2a_concept_fabrication": { "count": 0, "instances": [] },
    "2b_spurious_numeric": { "count": 0, "instances": [] },
    "2c_false_citation": { "count": 0, "instances": [] },
    "3a_unsupported_leap": { "count": 3, "instances": [
      {
        "snippet": "Gateway 3 assumes waiting for corrected invoice is the only outcome from contacting supplier",
        "why": "The conclusion restricts outcome possibilities without justification; contacting supplier can resolve discrepancy without correction.",
        "severity": "medium"
      },
      {
        "snippet": "Escalation assigned to AP Clerk incorrectly; Dan (Purchasing) found discrepancy, Mary escalates only later",
        "why": "This misassigns responsibility without support from interview data, making escalation logic flawed and unjustified.",
        "severity": "high"
      },
      {
        "snippet": "Flow back to Activity 4 from Activity 4b is logically incorrect after escalation resolution",
        "why": "Resolution of exceptions found at Activity 6 (Mary's checking) shouldn't loop back to Activity 4 (Purchasing), lacking logical support.",
        "severity": "high"
      }
    ] },
    "3b_self_contradiction": { "count": 1, "instances": [
      {
        "snippet": "Activity 4b placement after Gateway 4 but numbered '4b', implying connection to Activity 4",
        "why": "This produces confusion by conflicting logical and numbering cues about where the activity belongs in the flow.",
        "severity": "medium"
      }
    ] },
    "3c_circular_reasoning": { "count": 0, "instances": [] },
    "4a_syntax_error": { "count": 0, "instances": [] },
    "4b_model_semantics_breach": { "count": 0, "instances": [] },
    "4c_visual_descr_mismatch": { "count": 0, "instances": [] }
  },
  "totals": { "hallucinations_overall": 6 }
}