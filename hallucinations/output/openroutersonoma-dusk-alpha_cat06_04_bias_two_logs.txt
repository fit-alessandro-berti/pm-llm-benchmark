{
  "categories": {
    "1a_instruction_override": { "count": 0, "instances": [] },
    "1b_context_omission":    { "count": 0, "instances": [] },
    "1c_prompt_contradiction":{ "count": 0, "instances": [] },
    "2a_concept_fabrication": { "count": 0, "instances": [] },
    "2b_spurious_numeric":    { "count": 0, "instances": [] },
    "2c_false_citation":      { "count": 0, "instances": [] },
    "3a_unsupported_leap":    {
      "count": 1,
      "instances": [
        {
          "snippet": "incorrectly infers that 'approvals appearing to require a threshold around 720–730' while others with 710 rejected...",
          "why": "The answer concludes a threshold that is contradicted by data points showing approvals and rejections inconsistent with it, indicating an unsupported logical leap.",
          "severity": "high"
        }
      ]
    },
    "3b_self_contradiction":  {
      "count": 1,
      "instances": [
        {
          "snippet": "U003 was approved with adjusted score 705 but threshold claimed around 720–730 contradicting own data",
          "why": "The answer fails to reconcile that U003's approval at a lower score conflicts with the proposed threshold, causing a self-contradiction.",
          "severity": "high"
        }
      ]
    },
    "3c_circular_reasoning":  { "count": 0, "instances": [] },
    "4a_syntax_error":        { "count": 0, "instances": [] },
    "4b_model_semantics_breach": { "count": 0, "instances": [] },
    "4c_visual_descr_mismatch": { "count": 0, "instances": [] }
  },
  "totals": { "hallucinations_overall": 2 }
}