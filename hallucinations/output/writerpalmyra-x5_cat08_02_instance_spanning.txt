{
  "categories": {
    "1a_instruction_override": { "count": 0, "instances": [] },
    "1b_context_omission": { "count": 0, "instances": [] },
    "1c_prompt_contradiction": { "count": 0, "instances": [] },
    "2a_concept_fabrication": { "count": 0, "instances": [] },
    "2b_spurious_numeric": {
      "count": 4,
      "instances": [
        {
          "snippet": "\"-  60% cold-packing queue time for express orders\" outcome bullet point",
          "why": "The percentage reduction or target is ambiguous and unsupported explicitly by baseline data, making the numeric claim unsupported by source data.",
          "severity": "medium"
        },
        {
          "snippet": "\"-  40% average wait for standard orders\" outcome bullet point",
          "why": "Similar ambiguity and unclear if this is a reduction or final metric, unsupported by exact data from logs or prompt.",
          "severity": "medium"
        },
        {
          "snippet": "\"-  50% average wait due to unplanned blocking\" outcome bullet point",
          "why": "Numeric value presented without sufficient justification or source, leading to spurious number hallucination.",
          "severity": "medium"
        },
        {
          "snippet": "\"Avg. wait time... |  40% YoY |\" and \"Standard order disruption rate | 50% |\" monitoring table entries",
          "why": "The metrics lack clarity in meaning (e.g., reduce by or achieve) and baseline support, representing spurious numeric claims.",
          "severity": "medium"
        }
      ]
    },
    "2c_false_citation": { "count": 0, "instances": [] },
    "3a_unsupported_leap": {
      "count": 2,
      "instances": [
        {
          "snippet": "Priority detection example assumes station-specific preemption, but policy allows pausing any necessary resource",
          "why": "The conclusion narrows policy scope unjustifiably, which is unsupported by the stated policy allowing pausing of any resource.",
          "severity": "low"
        },
        {
          "snippet": "\"Hazmat identification: 'at every second' precise but ignores timestamp granularity\"",
          "why": "Assumes timestamp granularity finer than log actually provides, making precise 'every second' identification unsupported by data.",
          "severity": "low"
        }
      ]
    },
    "3b_self_contradiction": { "count": 0, "instances": [] },
    "3c_circular_reasoning": { "count": 0, "instances": [] },
    "4a_syntax_error": { "count": 0, "instances": [] },
    "4b_model_semantics_breach": { "count": 0, "instances": [] },
    "4c_visual_descr_mismatch": { "count": 0, "instances": [] }
  },
  "totals": { "hallucinations_overall": 6 }
}