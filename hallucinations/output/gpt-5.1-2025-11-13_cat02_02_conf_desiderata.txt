{
  "categories": {
    "1a_instruction_override": {
      "count": 1,
      "instances": [
        {
          "snippet": "\"The answer erroneously labels it as 'recommended but not stated as mandatory'...directly contradicting the query's 'must' language.\"",
          "why": "The model ignores the prompt's explicit instruction that 'Inform Applicant' is mandatory, treating it as optional, thus overriding a direct constraint.",
          "severity": "critical"
        }
      ]
    },
    "1b_context_omission": {
      "count": 2,
      "instances": [
        {
          "snippet": "\"No interpretation for the missing Inform Applicant in Case 2...leaves the analysis incomplete.\"",
          "why": "The model omits critical context needed to fully justify or interpret the missing mandatory step, reducing answer completeness.",
          "severity": "high"
        },
        {
          "snippet": "\"Doesn't fully trace how the premature Risk Assessment invalidates the downstream Loan Decision...logical gap.\"",
          "why": "Key prompt context about cascading effects is left out, causing unclear reasoning and incomplete explanation.",
          "severity": "medium"
        }
      ]
    },
    "1c_prompt_contradiction": {
      "count": 0,
      "instances": []
    },
    "2a_concept_fabrication": {
      "count": 0,
      "instances": []
    },
    "2b_spurious_numeric": {
      "count": 0,
      "instances": []
    },
    "2c_false_citation": {
      "count": 0,
      "instances": []
    },
    "3a_unsupported_leap": {
      "count": 1,
      "instances": [
        {
          "snippet": "\"The answer understates Case 2's severity and misaligns with the 'strict sequence' constraint.\"",
          "why": "The model draws a conclusion minimizing severity without sufficient support from the prompt, making an unsupported logical leap.",
          "severity": "high"
        }
      ]
    },
    "3b_self_contradiction": {
      "count": 0,
      "instances": []
    },
    "3c_circular_reasoning": {
      "count": 0,
      "instances": []
    },
    "4a_syntax_error": {
      "count": 0,
      "instances": []
    },
    "4b_model_semantics_breach": {
      "count": 0,
      "instances": []
    },
    "4c_visual_descr_mismatch": {
      "count": 0,
      "instances": []
    }
  },
  "totals": { "hallucinations_overall": 4 }
}