{
  "categories": {
    "1a_instruction_override": {
      "count": 0,
      "instances": []
    },
    "1b_context_omission": {
      "count": 0,
      "instances": []
    },
    "1c_prompt_contradiction": {
      "count": 0,
      "instances": []
    },
    "2a_concept_fabrication": {
      "count": 1,
      "instances": [
        {
          "snippet": "\"5 document requests over 7 days\" is fabricated—log shows exactly 3 requests (04-01 11:30, 04-02 17:00, 04-03 15:00)...",
          "why": "The analysis invents a 7-day period with 5 document requests for Case 2005, contradicting the log showing only 3 requests over ~2.5 days, fabricating data not in the prompt.",
          "severity": "critical"
        }
      ]
    },
    "2b_spurious_numeric": {
      "count": 5,
      "instances": [
        {
          "snippet": "\"Case 2003's Approve Claim is at 2024-04-02 16:00 (not 2024-04-01 17:00 as stated)\"",
          "why": "Timestamps are misreported, misrepresenting event timing and lead times, forming a false numeric basis for delay calculations.",
          "severity": "high"
        },
        {
          "snippet": "\"Close Claim is at 09:30 (not 15:00)\" for Case 2003",
          "why": "Incorrect timestamp for claim closure skews total case duration and delay evaluation.",
          "severity": "high"
        },
        {
          "snippet": "\"'6h 50 min after evaluate to approve' is wrong; actual evaluate-to-approve is ~30.5 hours.\"",
          "why": "The stated interval is factually incorrect by a large margin, invalidating temporal conclusions.",
          "severity": "critical"
        },
        {
          "snippet": "\"Includes a blatant typo (2025 vs. 2024) in Case 2005 close date\"",
          "why": "Factual error in year leads to misinterpretation of timeline and event sequencing.",
          "severity": "medium"
        },
        {
          "snippet": "\"Claims like 'all cases within 4 days (latest=5 days)' are vague/inaccurate—2005 is 3 days, not 5\"",
          "why": "The numeric summary of lead times does not match the prompt data, misleading about overall durations.",
          "severity": "medium"
        }
      ]
    },
    "2c_false_citation": {
      "count": 0,
      "instances": []
    },
    "3a_unsupported_leap": {
      "count": 3,
      "instances": [
        {
          "snippet": "\"Resource 'medium-to-low effectiveness' for managers lacks evidence (Ann approves fast)\"",
          "why": "The conclusion about manager effectiveness is drawn without supporting data, thus an unsupported inference.",
          "severity": "medium"
        },
        {
          "snippet": "\"'Cascading requests' assumes causes not in log, like overlapping workloads\"",
          "why": "Attributing root causes not evidenced by data is an unsupported logical leap.",
          "severity": "high"
        },
        {
          "snippet": "\"'Surprisingly short' final steps contradict 'overall lag' emphasis—no quantitative phase timing\"",
          "why": "This contradictory claim about step durations lacks justification and quantification, weakening logical consistency.",
          "severity": "medium"
        }
      ]
    },
    "3b_self_contradiction": {
      "count": 1,
      "instances": [
        {
          "snippet": "\"Region analysis confuses (claims Region A for 2004/2005—2004 is B, low complexity, fast; 2005 is B)\"",
          "why": "Contradictory statements on region assignments within the same evaluation reflect self-conflicting data interpretation.",
          "severity": "medium"
        }
      ]
    },
    "3c_circular_reasoning": {
      "count": 0,
      "instances": []
    },
    "4a_syntax_error": {
      "count": 0,
      "instances": []
    },
    "4b_model_semantics_breach": {
      "count": 0,
      "instances": []
    },
    "4c_visual_descr_mismatch": {
      "count": 0,
      "instances": []
    }
  },
  "totals": {
    "hallucinations_overall": 10
  }
}