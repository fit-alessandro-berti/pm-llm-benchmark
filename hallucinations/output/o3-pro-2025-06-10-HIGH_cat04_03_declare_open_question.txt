{
  "categories": {
    "1a_instruction_override": {
      "count": 0,
      "instances": []
    },
    "1b_context_omission": {
      "count": 0,
      "instances": []
    },
    "1c_prompt_contradiction": {
      "count": 0,
      "instances": []
    },
    "2a_concept_fabrication": {
      "count": 0,
      "instances": []
    },
    "2b_spurious_numeric": {
      "count": 0,
      "instances": []
    },
    "2c_false_citation": {
      "count": 0,
      "instances": []
    },
    "3a_unsupported_leap": {
      "count": 4,
      "instances": [
        {
          "snippet": "\"QA stamps the offer\" ritual found in many lending departments.",
          "why": "The answer asserts the offer package is created before the QA review, contradicting the model's requirement that QA review must be immediately followed by the offer package creation.",
          "severity": "critical"
        },
        {
          "snippet": "The signature committee bases its decision directly on the latest credit score; no other task may sneak in that could invalidate the rating.",
          "why": "The answer reverses the chainprecedence constraint by implying a reversed temporal order contrary to what the model states, substituting a logical but incorrect interpretation.",
          "severity": "critical"
        },
        {
          "snippet": "After the first-level rating, missing paperwork must be chased.",
          "why": "The explanation captures only the Response aspect but omits the Precedence part of the 'Succession' constraint, providing an incomplete interpretation.",
          "severity": "medium"
        },
        {
          "snippet": "\"Terms cannot be authorised before QA approved the dossier.\"",
          "why": "The answer implies mandatory QA approval before authorization, but Precedence only conditions order if the consequent occurs; the explanation slightly misrepresents the rule's meaning.",
          "severity": "low"
        }
      ]
    },
    "3b_self_contradiction": {
      "count": 0,
      "instances": []
    },
    "3c_circular_reasoning": {
      "count": 0,
      "instances": []
    },
    "4a_syntax_error": {
      "count": 0,
      "instances": []
    },
    "4b_model_semantics_breach": {
      "count": 0,
      "instances": []
    },
    "4c_visual_descr_mismatch": {
      "count": 0,
      "instances": []
    }
  },
  "totals": {
    "hallucinations_overall": 4
  }
}