{
  "categories": {
    "1a_instruction_override": { "count": 0, "instances": [] },
    "1b_context_omission":    { "count": 0, "instances": [] },
    "1c_prompt_contradiction":{ "count": 0, "instances": [] },
    "2a_concept_fabrication": { "count": 0, "instances": [] },
    "2b_spurious_numeric":    { 
      "count": 1, 
      "instances": [
        {
          "snippet": "\"~740 vs. ~700\" is slightly imprecise when actual scores (740, 700, 720) are available",
          "why": "Uses approximate numbers when exact values exist in the prompt/log, which may mislead about precision.",
          "severity": "low"
        }
      ]
    },
    "2c_false_citation":      { "count": 0, "instances": [] },
    "3a_unsupported_leap":    { 
      "count": 1, 
      "instances": [
        {
          "snippet": "Recommendations - Manual Review audit despite no direct log evidence of bias at Manual Review step",
          "why": "Extrapolates potential bias at Manual Review beyond what the log explicitly supports, lacking direct evidence.",
          "severity": "medium"
        }
      ]
    },
    "3b_self_contradiction":  { "count": 0, "instances": [] },
    "3c_circular_reasoning":  { "count": 0, "instances": [] },
    "4a_syntax_error":        { "count": 0, "instances": [] },
    "4b_model_semantics_breach": { "count": 0, "instances": [] },
    "4c_visual_descr_mismatch": { "count": 0, "instances": [] }
  },
  "totals": { "hallucinations_overall": 2 }
}