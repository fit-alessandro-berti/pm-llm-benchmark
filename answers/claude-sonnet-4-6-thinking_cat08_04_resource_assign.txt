# Comprehensive Process Mining Analysis and Optimization of TechSolve's Resource Assignment Practices

---

## Section 1: Analyzing Resource Behavior and Assignment Patterns

### 1.1 Agent and Tier Performance Analysis

The event log is the foundational dataset. Before any analysis, I would perform data preparation: conformance checking for timestamp consistency, deduplication, enrichment with static reference data (agent skill profiles, SLA thresholds per priority), and construction of a case-centric view that traces the complete lifecycle of every ticket.

**Key Metrics to Compute per Agent and per Tier:**

| Metric | Definition | Analytical Purpose |
|--------|------------|-------------------|
| **Activity Processing Time** | Duration between `Work Start` and `Work End` per agent per ticket type | Identifies slow or fast processors; reveals skill mismatches |
| **Ticket Throughput** | Tickets completed per agent per unit time (day/week) | Baseline workload productivity |
| **Workload Distribution (Queue Depth)** | Count of concurrently open tickets assigned to each agent at any timestamp | Reveals overloaded vs. underutilized agents |
| **First-Contact Resolution Rate (FCR)** | % of L1-touched tickets resolved without escalation | Core L1 effectiveness metric |
| **Escalation Rate** | % of tickets escalated from L1L2 and L2L3 per agent | Flags agents escalating excessively |
| **Reassignment Count per Case** | Number of reassignment events within a single ticket's lifecycle | Directly correlates with delay and SLA risk |
| **Mean Time to Assign (MTTA)** | Time from ticket creation to first agent work start | Reveals dispatcher inefficiency or queue saturation |
| **Mean Time to Resolve (MTTR)** | End-to-end ticket resolution time, segmented by tier, priority, category | Foundational SLA compliance indicator |
| **Skill Match Rate** | % of assignments where agent's documented skills include the ticket's required skill | Measures routing logic quality |
| **SLA Breach Rate per Agent** | % of tickets handled by each agent that breach SLA | Links individual behavior to SLA outcomes |
| **Rework/Revisit Rate** | Tickets returning to a previously visited agent or tier | Reveals circular escalations and inadequate resolutions |

For tier-level analysis, I would aggregate these metrics and additionally compute **tier utilization** (active work time / available capacity × 100%). A high utilization rate at L2/L3 combined with a large queue signals a bottleneck; a low utilization at L1 with high escalation rates signals empowerment or skill gaps.

**Temporal Dimension:** I would plot all metrics across time (hourly, daily, weekly) to detect demand seasonality — for example, Monday morning spikes or month-end peaks — which are critical for capacity planning.

---

### 1.2 Actual vs. Intended Assignment Pattern Discovery

**Process Discovery and Conformance Checking:**

Using a process discovery algorithm (Inductive Miner is preferred for its noise-handling capabilities on large ITSM logs), I would mine the actual process model from the event log. The discovered model will show all actual routing paths — including the escalation chains, reassignment loops, and direct L1-to-L3 shortcuts that may not appear in the documented procedure. I would then overlay the *intended* process model (derived from TechSolve's ITSM process documentation) and run conformance checking to identify:

- **Deviations (Non-Conforming Cases):** Tickets taking unexpected paths (e.g., L1 skipping dispatcher and self-assigning, or L2 agent reassigning to another L2 without escalating to L3).
- **Fitness Score:** A global metric (0–1) indicating how well the log conforms to the intended model. A fitness below 0.85 would indicate systemic deviation.

**Resource Interaction Analysis and Social Network Analysis (SNA):**

I would construct a **Handover-of-Work network** where nodes are agents (or agent roles/tiers) and directed edges represent ticket handovers between them. Edge weights represent the frequency of handovers; edge thickness in visualization reflects volume. Key analyses include:

- **Betweenness Centrality:** Agents who sit on many shortest handover paths are potential single points of failure. A dispatcher with extremely high betweenness is a bottleneck.
- **In-degree / Out-degree Analysis:** An L2 agent with high in-degree but low out-degree is a resolution specialist; one with high out-degree suggests inability to resolve and frequent re-routing.
- **Subgraph Clustering:** Identifying informal "cliques" — e.g., Agent A02 always escalates to Agent B08 regardless of formal routing rules — reveals shadow workflows that bypass the intended logic.
- **Working-Together Network:** Constructed when multiple agents collaborate on a single ticket simultaneously. Low frequency here might indicate insufficient collaborative problem-solving on complex tickets.

**Role Discovery:**

Using organizational mining techniques, I would cluster agents based on their *actual behavioral profiles* — which activities they perform, which ticket types they handle, which agents they hand off to — rather than their *assigned tier*. This often reveals:
- L1 agents who are functionally performing L2 work (possibly underpaid and at risk of burnout).
- L2 agents who predominantly handle L1-equivalent tasks (wasted specialization).
- Informal "super-resolvers" who handle disproportionately many complex tickets outside their documented tier.

The discovered roles are then compared to the formal tier structure to identify misalignment between actual behavior and organizational design.

---

### 1.3 Skill Utilization Analysis

**Skill-Ticket Matching Matrix:**

I would build a cross-tabulation of every assignment event: the required skill field of the ticket vs. the documented skill set of the assigned agent. From this matrix, I can calculate:

- **Skill Match %:** The proportion of assignments where required skill  agent's skill set.
- **Skill Mismatch Patterns:** Which specific skill mismatches are most frequent (e.g., tickets requiring `Networking-Firewall` are frequently assigned to agents with only `Basic-Troubleshoot`).
- **Over-Qualification Index:** Tickets assigned to agents possessing skills significantly more advanced than required (e.g., a `Database-SQL` specialist handling a `Basic-Troubleshoot` password reset). High values indicate specialist waste.

**Skill Bottleneck Identification:**

By correlating ticket arrival rates for each required skill with the count of agents possessing that skill, I can compute an **effective skill-demand-to-supply ratio**. Skills with ratios significantly above 1.0 (more demand than skilled supply) are bottleneck skills. For TechSolve, if `Networking-Firewall` tickets arrive at 15/day and only 2 agents possess this skill, each is handling 7.5 tickets/day, making this a high-risk bottleneck.

**Proficiency Depth Analysis:**

Beyond binary skill matching, I would use processing time as a proxy for proficiency: an agent who resolves `App-CRM` tickets 40% faster than their peers handling the same ticket type likely has deeper proficiency. This proficiency estimate enriches the skill profile beyond the binary "has skill / doesn't have skill" recorded in HR systems.

---

## Section 2: Identifying Resource-Related Bottlenecks and Issues

### 2.1 Bottleneck Detection Methods

**Queue Analysis at Assignment Points:**

By measuring the time difference between `Escalate L2` and `Work L2 Start` across all tickets, I can compute the **L2 queue waiting time distribution**. In the sample log, INC-1001 waited from 09:36 to 10:05 (29 minutes) at L2 queue before work started. If this is representative, and SLA for P3 is, say, 4 hours total resolution, 29 minutes of idle queue time is already a measurable SLA risk. Aggregated over thousands of tickets, I would calculate:

- **Mean Queue Wait Time per Tier** and per **Skill Category**
- **95th Percentile Queue Wait** (captures worst-case experiences)
- **Correlation Coefficient between Queue Wait and SLA Breach** (expected to be strongly positive)

**Reassignment Impact Quantification:**

For each reassignment event, I calculate the time elapsed between the reassignment activity timestamp and the next `Work Start` event on the same ticket. This "reassignment-induced delay" can be averaged across all reassignments:

> **Formula:** Reassignment Delay = Timestamp(Next Work Start after Reassign)  Timestamp(Reassign Event)

From the INC-1001 example: Reassignment at 11:15, new assignment at 11:16, but if new agent B15 doesn't start until 13:00, the reassignment added ~105 minutes of delay. If the average reassignment delay across the year's log is, say, 47 minutes, and there are 3,200 reassignment events per year on P2/P3 tickets, the total SLA risk exposure from reassignments alone is quantifiable.

**Specific Issues I Would Expect to Find:**

| Issue | Detection Method | Expected Finding |
|-------|-----------------|-----------------|
| **Skill bottleneck at L2** | Skill demand/supply ratio | 2–3 skills (e.g., Networking-Firewall, Security-IAM) with ratio >3x |
| **Excessive L1 escalation** | Per-agent escalation rate vs. peer average | 20–30% of L1 agents escalating >70% of tickets vs. team average of 35% |
| **Incorrect initial categorization** | Cases where required skill changes after assignment | Estimate 15–25% of tickets have skill requirement revised post-assignment |
| **Dispatcher-induced delay** | MTTA for dispatcher-routed vs. auto-assigned tickets | Dispatcher routing adds 8–12 min average vs. auto-assignment |
| **Specialist misuse** | Over-qualification index | 30–40% of L2/L3 work time spent on tasks matchable to L1 skill set |
| **Overloaded agents** | Queue depth time series | Top 10% of agents handle 35–40% of total volume |
| **SLA breach correlation with skill mismatch** | Logistic regression: SLA breach ~ skill_match + reassignment_count + wait_time | Skill mismatch OR each reassignment multiplies SLA breach probability by ~1.8x |

### 2.2 SLA Breach Correlation Analysis

I would run a **logistic regression** (or decision tree for interpretability) with the binary SLA breach outcome as the dependent variable and the following independent variables:

- Number of reassignments (expected: strong positive predictor)
- Initial skill match (expected: strong negative predictor — match reduces breach probability)
- Queue wait time at each tier
- Ticket priority × day of week (interaction term for temporal effects)
- Number of tiers touched (L1 only vs. L1+L2 vs. L1+L2+L3)

The regression coefficients would be translated into business terms: "Each additional reassignment increases the probability of SLA breach by X percentage points." This quantification creates a compelling business case for the proposed improvements.

---

## Section 3: Root Cause Analysis for Assignment Inefficiencies

### 3.1 Systematic Root Cause Framework

I would apply an **Ishikawa (Fishbone) framework** informed by the data findings, organizing root causes across four domains:

**Process Design Deficiencies:**
- **Round-robin assignment ignores skill requirements and workload.** Round-robin guarantees equal distribution of ticket *volume* but not equal distribution of *appropriate work*. An agent receiving a `Networking-Firewall` ticket via round-robin who lacks that skill will either struggle (slow resolution, SLA breach) or escalate immediately (unnecessary delay).
- **Escalation criteria are subjective.** Without quantitative escalation thresholds (e.g., "if L1 working time exceeds 20 minutes without resolution, escalate"), individual agent judgment — which varies significantly — drives escalation decisions inconsistently.
- **Dispatcher bottleneck.** A human dispatcher as a sequential gateway for L2/L3 assignment creates a single point of failure and introduces processing delay.

**Data and Information Gaps:**
- **Skill profiles are binary and static.** They don't capture proficiency levels, recency of training, or current certification status. An agent listed as having `App-CRM` skill may have been trained 3 years ago on an old version.
- **Poor ticket categorization at intake.** If the channel (phone call) relies on the caller to self-describe the problem, the `Required Skill` field is often wrong at creation time. I would quantify this by measuring how often the required skill field is updated after the ticket is created.
- **No real-time workload visibility.** Assignment decisions (especially manual ones) are made without knowing current agent queue depths, making workload balancing impossible without a dedicated tool.

**Human Factors:**
- **L1 agent skill gaps and risk aversion.** Some L1 agents escalate at the first sign of complexity rather than attempting resolution, either due to genuine skill gaps or a cultural incentive (escalation is "safe"; failed resolution attempts might be scrutinized).
- **Informal routing preferences.** SNA may reveal that certain agents prefer routing to specific colleagues, creating uneven workload distribution and bypassing the formal assignment system.

**Organizational and Structural Factors:**
- **Tier boundaries are rigid.** A highly skilled L1 agent cannot be formally assigned an L2 ticket even if they are available and capable, because the system enforces tier-based routing.

---

### 3.2 Variant Analysis and Decision Mining

**Variant Analysis — Smooth vs. Problematic Cases:**

I would partition the case population into two groups:
- **"Clean" Cases:** Resolved with zero reassignments, zero tier violations, and within SLA. Expected ~35–40% of volume.
- **"Complex-Routing" Cases:** Two or more reassignments OR SLA breach OR three or more tiers touched. Expected ~25–35% of volume.

For each group, I would compute the distributional profile across: ticket category, required skill, priority, creation channel, day/time of creation, initial assigning agent/dispatcher, and initial skill match. Statistically significant differences between the two groups (using chi-squared tests for categorical variables, t-tests for continuous) identify the *decision points* where complexity originates.

Expected findings from variant analysis:
- Clean cases are disproportionately represented in Hardware and Access Management categories (more routine, skill requirements predictable).
- Complex-routing cases concentrate in Security and Network categories with multi-skill requirements.
- Clean cases show initial skill match rate of ~85%; complex-routing cases show ~40%.
- Specific L1 agents appear disproportionately in the escalation chain of complex-routing cases, identifying candidates for targeted training.

**Decision Mining at Escalation Points:**

At each `Escalate L2` event, I would extract the decision context (ticket age at escalation point, L1 working time, ticket category, required skill, L1 agent ID) and use a decision tree algorithm (C4.5 or CART) to learn the *actual* escalation decision rules being applied in practice. The discovered decision tree is then compared to the *documented* escalation policy. Gaps reveal:

- L1 agents escalating based on ticket *category* rather than actual complexity (e.g., any "Network" category ticket is immediately escalated regardless of complexity).
- Escalation thresholds vary dramatically by agent (some escalate after 10 minutes, others after 60 minutes on identical ticket types).
- Some L1 agents have learned a "correct" escalation pattern (aligning with what would have been optimal based on eventual resolution path) while others have not.

The output of decision mining directly informs which escalation criteria should be formalized and what training interventions are needed.

---

## Section 4: Data-Driven Resource Assignment Strategies

### Strategy 1: Skill-Proficiency-Weighted Routing Engine

**Issue Addressed:** Skill mismatches causing reassignments and resolution delays; specialist underutilization; L1 agents receiving tickets requiring skills they don't possess.

**How Process Mining Informs It:**
The skill utilization analysis (Section 1.3) produces an empirically derived **Proficiency Score** for each agent-skill combination, calculated from historical processing time performance relative to peers. The SNA identifies which agents produce the best resolution outcomes for each ticket category. These inputs replace the binary skill flag in the routing engine with a numeric proficiency score.

**Implementation:**

The routing decision for each new or escalated ticket would execute the following logic:

```
For incoming ticket T with Required_Skill = S and Priority = P:
  1. Query agent pool for agents where S  agent.skills AND agent.tier  minimum_tier(P)
  2. For each eligible agent A, compute:
       Score(A,T) =  × Proficiency(A,S) +  × (1 - CurrentLoad(A)) +  × AvailabilityFlag(A)
       where  +  +  = 1 (weights tunable via simulation)
  3. Assign ticket to argmax(Score(A,T))
  4. If no eligible agent available: route to skill-specific queue with escalation timer
```

Proficiency(A,S) is derived from historical processing time percentile: an agent in the 80th percentile of speed for skill S gets a proficiency score of 0.8. CurrentLoad(A) is the real-time count of open assigned tickets normalized by the agent's historical comfortable capacity.

**Data Required:**
- Historical processing times per agent per skill category (from event log)
- Real-time agent availability status (from ITSM tool API)
- Real-time queue depth per agent (from ITSM tool)
- Agent skill profiles (enriched with proficiency scores, refreshed quarterly)
- Ticket required skill field (must be reliably populated — see Strategy 3)

**Expected Benefits:**
- Reduction in skill-mismatch reassignments by an estimated 50–65% (based on the proportion currently caused by incorrect skill matching)
- Reduction in average resolution time for L2/L3 tickets by 15–25% due to assignment to higher-proficiency agents
- More even distribution of specialist work, reducing burnout risk for top performers
- Measurable reduction in SLA breach rate for P2/P3 tickets, particularly in bottleneck skill categories

---

### Strategy 2: Real-Time Workload-Aware Assignment with Dynamic Tier Flexibility

**Issue Addressed:** Uneven workload distribution; overloaded specialists; underutilized agents; rigid tier boundaries preventing efficient use of capable L1 agents.

**How Process Mining Informs It:**
The queue depth time series analysis (Section 1.1) reveals systematic overload patterns at specific agents and times. The role discovery analysis (Section 1.2) identifies L1 agents who are *behaviorally* performing L2-equivalent work but are structurally constrained. The temporal analysis identifies peak demand windows where cross-tier flexibility would be most beneficial.

**Implementation:**

This strategy has two components:

*Component A — Workload Balancing Algorithm:*
The assignment engine continuously monitors a **workload heat map** across all agents. When any agent's queue depth exceeds their 75th percentile historical comfortable capacity (a personal threshold derived from data, not a universal number), that agent is marked as "load-protected" and excluded from new assignments until queue depth drops below the 50th percentile threshold. New tickets are then routed to eligible agents with the lowest current relative load.

*Component B — Dynamic Tier Boundary Permeability:*
Based on the role discovery analysis, a curated list of L1 agents with demonstrated L2-equivalent capability in specific skill domains is compiled. When L2 queue depth for a particular required skill exceeds a defined threshold (e.g., average wait time > 20 minutes), the system automatically makes the identified capable L1 agents available to receive that ticket type, with appropriate priority flagging and supervisor notification. Resolution outcomes are tracked; agents who successfully resolve these "stretch" tickets update their proficiency scores upward.

*Component C — Demand-Driven Shift Reallocation:*
Using the temporal demand analysis, I would build a **shift-staffing recommendation model** that, at the start of each shift, recommends which agents should be "surge-pooled" to cover anticipated high-demand skill areas based on historical patterns for that day/hour/season.

**Data Required:**
- Real-time agent status and queue depth (ITSM API integration)
- Historical queue depth time series (from event log, used to set personal capacity thresholds)
- Intraday demand forecasts by skill category (time-series model trained on 12 months of log data)
- Role discovery output identifying L1 agents with demonstrated L2 capability
- Supervisor approval workflow integration for cross-tier assignments

**Expected Benefits:**
- Reduction in the workload variance across agents by 40–50% (more even distribution)
- Reduction in L2/L3 queue wait times during peak periods by 20–35%
- Increased job satisfaction for high-capability L1 agents through more challenging work
- Measurable capacity increase without hiring: equivalent of 1–2 FTEs through better utilization of existing staff
- Faster response to demand spikes without requiring manual manager intervention

---

### Strategy 3: Predictive Ticket Triage with AI-Assisted Required Skill Identification

**Issue Addressed:** Incorrect initial categorization and required skill misidentification at intake; unnecessary L1 work time on tickets destined for escalation; dispatcher inefficiency.

**How Process Mining Informs It:**
The variant analysis (Section 3.2) quantifies how often the initial required skill field is incorrect. The process model reveals that tickets with initial skill misidentification predictably take longer paths with more reassignments. The conformance analysis identifies which ticket categories are consistently misclassified at intake.

**Implementation:**

I would train a **multi-label classification model** (e.g., gradient boosting or BERT-based text classifier for ticket descriptions) that predicts:
1. The correct **Required Skill(s)** for a ticket
2. The likely **resolution tier** (L1 resolvable, L2 required, L3 required)
3. An **estimated complexity score** (1–5) based on similar historical tickets

**Training Data:** The event log provides supervision: for every closed ticket, the *actual* resolution path reveals the true required skill (the skill of the agent who ultimately resolved it) and the resolution tier. This retrospective labeling corrects for intake misclassification and creates a high-quality training set.

**Model Features:**
- Ticket title and description (NLP features: TF-IDF, embeddings)
- Ticket category as selected by reporter
- Channel (phone tickets may have different language patterns)
- Time of day and day of week (some issue types have temporal patterns)
- Reporter/user characteristics (department, location, historical ticket types)

**Operational Integration:**

At ticket creation, the model scores the ticket in real time and:
- Pre-populates the Required Skill field with the top prediction (confidence displayed to agent)
- Flags tickets where L2/L3 resolution is predicted with >80% confidence for immediate bypass of L1, going directly to the appropriate skill queue
- Alerts dispatchers when predicted required skill does not match the initial category selected by the reporter
- Provides the L1 agent with the predicted complexity score, giving them an evidence-based signal about whether to attempt resolution or escalate

**Data Required:**
- Historical ticket text data paired with actual resolution outcomes (from event log linked to ticket descriptions)
- Model inference infrastructure (can be a lightweight API call at ticket creation)
- Continuous retraining pipeline (monthly model refresh as new resolved tickets accumulate)
- A/B testing framework to compare prediction-assisted vs. unassisted routing decisions

**Expected Benefits:**
- Reduction in skill-mismatch at initial assignment by 55–70%
- Elimination of 20–35% of unnecessary L1 work time on tickets the model predicts will require L2/L3 (direct routing saves the time wasted on predictable escalations)
- Improved L1 FCR rate by focusing L1 effort on tickets the model identifies as genuinely L1-resolvable
- Reduction in dispatcher workload, allowing transition to exception-handling only
- More accurate SLA commitment calculation at ticket creation (tickets predicted as complex can immediately be assigned a more conservative SLA expectation, managing customer expectations proactively)

---

### Strategy 4 (Supplementary): Data-Driven Escalation Threshold Standardization and L1 Empowerment Program

**Issue Addressed:** Excessive and inconsistent escalation decisions; L1 agents escalating based on habit or risk aversion rather than genuine inability to resolve.

**How Process Mining Informs It:**
Decision mining (Section 3.2) reveals that escalation rules vary dramatically by agent. Variant analysis identifies ticket types that high-performing L1 agents consistently resolve in-tier, but average or lower-performing L1 agents escalate. This identifies both: (a) tickets that should have a formal L1 resolution playbook and (b) agents who need targeted training.

**Implementation:**

- Publish **data-derived escalation thresholds** as formal policy: based on historical median L1 working time per ticket type before successful resolution, if working time exceeds 1.5× the median without resolution progress, escalation is triggered automatically (rather than left to agent discretion).
- Identify the top 15 ticket types by escalation frequency where high-performing L1 agents resolve at >60% rate. For each, create a **structured resolution playbook** for L1 agents (decision tree troubleshooting guides).
- **L1 Knowledge Base Enhancement:** Use the event log to extract resolution notes from successfully resolved tickets and use them to populate an AI-assisted knowledge base that L1 agents query during ticket handling.
- **Gamified FCR Tracking:** Make each L1 agent's FCR rate visible to them in real time on their dashboard, with benchmarking against anonymized peer percentiles, creating positive reinforcement for resolution attempts.

**Expected Benefits:**
- Reduction in unnecessary L1L2 escalations by 20–30%
- Reduction in L2 queue pressure, cascading to reduced L2 queue wait times
- Increased L1 agent skill development and career satisfaction

---

## Section 5: Simulation, Implementation, and Monitoring

### 5.1 Pre-Implementation Simulation

**Simulation Model Construction:**

Using the mined process model as the basis, I would build a **discrete-event simulation (DES)** model (tools: ProM with SimuCPN, BIMP, or AnyLogic). The simulation model would be parameterized with empirically derived values from the event log:

| Parameter | Derivation from Event Log |
|-----------|--------------------------|
| Ticket arrival rate by category/priority | Fitted distribution (likely Poisson with time-varying rate) from inter-arrival times |
| Activity processing time distributions | Per-agent, per-skill, per-ticket-type empirical distributions (log-normal typically fits well) |
| Escalation probabilities | Per-agent, per-ticket-type escalation rates from historical data |
| Reassignment probabilities under current routing | Observed reassignment frequencies per routing scenario |
| Agent capacity and availability | Working hours, break patterns, historical utilization rates |
| SLA thresholds | From SLA documentation |

**Simulation Experiments:**

I would run a series of experiments, each representing a "what-if" scenario:

1. **Baseline:** Simulate current round-robin + manual escalation system. Validate against known KPIs from the real event log (model is calibrated when simulated SLA breach rates and average resolution times match actual within ±5%).

2. **Strategy 1 Only:** Activate skill-proficiency-weighted routing, keep all other parameters equal. Observe change in SLA breach rate, reassignment count, and resolution time.

3. **Strategy 2 Only:** Activate workload-aware assignment. Observe queue depth distribution, overtime incidents, and throughput.

4. **Strategy 3 Only:** Activate predictive triage. Observe reduction in L1 wasted work time and initial mismatch rates.

5. **Combined Strategies 1+2+3:** Full target state. This is the primary business case scenario.

6. **Sensitivity Analysis:** Vary the , ,  weights in the Strategy 1 scoring formula to find optimal weighting. Test robustness under different demand scenarios (30% volume increase, sudden spike in Security tickets).

The simulation outputs — projected SLA compliance rates, average resolution times, queue depths, agent utilization levels — become the quantitative business case for investment in the implementation. If the simulation projects a 40% reduction in P2/P3 SLA breaches, this can be translated directly into avoided SLA penalty costs, which is the language that secures executive buy-in.

**Risk Simulation:** I would also simulate failure modes: what happens to SLA performance if the predictive model has 20% error rate in skill prediction? The simulation would show whether the system degrades gracefully, informing the design of fallback logic.

---

### 5.2 Post-Implementation Monitoring Framework

**Monitoring Architecture:**

I recommend a **live process mining dashboard** (e.g., Celonis, Disco, or custom-built on a process mining platform) that continuously ingests event data from the ITSM tool, refreshed at least every 15 minutes for operational awareness and daily for strategic views.

**Dashboard Layer 1 — Operational Real-Time View (Shift Supervisors):**

| KPI | Target | Alert Threshold |
|-----|--------|----------------|
| Current open P1/P2 tickets | Trending | Any P1 open >15 min without active work |
| Live queue depth per skill category | Balanced within ±20% of mean | Any skill queue >45 min average wait |
| Active assignment accuracy (predicted skill match %) | >90% | <80% triggers routing rule review |
| SLA breach imminent (tickets within 20% of SLA deadline, unresolved) | Minimize | >5 concurrent triggers alert |
| Agent availability status summary | % available within expected range | >30% of agents unavailable simultaneously |

**Dashboard Layer 2 — Daily Management View:**

- **SLA Performance Trend:** Daily SLA compliance rate by priority, with 7-day moving average. Target: P2  95%, P3  90%.
- **Reassignment Frequency Trend:** Average reassignments per ticket per day, segmented by tier and category. Target: <0.3 reassignments per ticket (down from baseline).
- **Skill Match Rate:** % of assignments where agent skill includes required skill. Target: >92%.
- **L1 FCR Rate:** Daily FCR, segmented by agent and category. Target: >70% (up from baseline).
- **Specialist Utilization:** % of L2/L3 work time spent on tickets matching their specialist skills. Target: >80%.
- **Prediction Model Accuracy:** Daily monitoring of the predictive triage model's skill prediction accuracy (validated against eventual resolution agent's skill). Alert if accuracy drops below 80% (model drift detection).

**Dashboard Layer 3 — Weekly Process Mining View (Process Improvement Team):**

- **Conformance Checking Score:** Weekly fitness score of actual process vs. intended model. Target: >0.92 (up from baseline).
- **Bottleneck Evolution Map:** Animated process map showing where time accumulates, compared week-over-week. Should show progressive elimination of previously identified bottleneck points.
- **Social Network Analysis Update:** Weekly refresh of handover network, monitoring for re-emergence of informal routing cliques or new shadow workflows.
- **Variant Distribution:** Tracking the proportion of "clean" vs. "complex-routing" case variants. Target: clean cases increase from ~35% baseline toward 60%+.
- **Agent Skill Proficiency Drift:** Monitoring whether individual agents' processing times for specific skills are improving (training investment ROI) or degrading (retraining trigger).
- **SLA Breach Root Cause Attribution:** Automated classification of each SLA breach event into root cause categories (skill mismatch, queue delay, reassignment chain, etc.) to track whether the specific root causes targeted by each strategy are being eliminated.

**Continuous Improvement Feedback Loop:**

The monitoring framework should feed into a structured quarterly review process:

1. **Monthly:** Routing weight (, , ) recalibration based on observed performance.
2. **Quarterly:** Full variant analysis refresh to detect new emerging problem patterns; predictive model retraining.
3. **Semi-Annual:** Full process rediscovery to capture process evolution; agent skill profile updates incorporating performance data; assessment of whether new bottleneck skills have emerged as resolved ones are cleared.
4. **Annual:** Strategic review of tier structure, agent hiring/training plan informed by 12 months of bottleneck skill data, and SLA target recalibration.

---

## Summary: End-to-End Value Architecture

```
EVENT LOG DATA
      
      
PROCESS MINING ANALYSIS
 Process Discovery  Actual process model vs. intended
 Resource Analysis  Workload, skill utilization, proficiency
 Social Network Analysis  Handover patterns, informal routing
 Variant Analysis  Clean vs. problematic case drivers
 Decision Mining  Escalation decision rules
      
      
ROOT CAUSE IDENTIFICATION
 Round-robin ignores skills/workload
 Static skill profiles, no proficiency data
 Poor intake categorization
 Inconsistent escalation decisions
      
      
SIMULATION-VALIDATED STRATEGIES
 Strategy 1: Skill-Proficiency-Weighted Routing
 Strategy 2: Workload-Aware Dynamic Tier Assignment
 Strategy 3: Predictive Triage Model
 Strategy 4: L1 Empowerment & Escalation Standardization
      
      
MONITORED IMPLEMENTATION
 Live process mining dashboards with KPI targets, alerts,
    and quarterly recalibration loops
```

This architecture ensures that every recommendation is traceable to a specific data-driven finding, every strategy can be quantitatively evaluated before investment, and the benefits are continuously verified post-implementation — transforming TechSolve's resource assignment from a largely intuitive, reactive process into a data-driven, self-improving operational capability.