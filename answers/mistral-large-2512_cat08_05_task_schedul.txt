# **Data-Driven Scheduling Optimization for Precision Parts Inc.**
*Leveraging Process Mining for Advanced Job Shop Scheduling*

## **1. Analyzing Historical Scheduling Performance and Dynamics**

Process mining provides a powerful lens to reconstruct, visualize, and quantify the *actual* execution of manufacturing processes from MES event logs. Below, I outline a structured approach to analyze Precision Parts Inc.’s scheduling performance using process mining techniques.

---

### **1.1 Process Discovery & Reconstruction**
**Objective:** Reconstruct the *as-is* process flow of jobs through the shop floor, including task sequences, resource allocations, and timing.

**Techniques:**
- **Process Discovery Algorithms:**
  - **Inductive Miner** or **Split Miner** to generate a process model (Petri net or BPMN) from event logs, capturing:
    - Job routings (sequence of tasks for each job type).
    - Parallel/concurrent task execution (e.g., multiple machines working on different jobs).
    - Loops (rework) or deviations from planned routings.
  - **Fuzzy Miner** to simplify complex models while preserving key paths.
- **Performance Spectrum Analysis:**
  - Visualize task durations, waiting times, and resource utilization over time to identify patterns (e.g., bottlenecks, idle periods).
- **Dotted Chart Analysis:**
  - Plot events over time to reveal:
    - Job arrival patterns (bursty vs. steady).
    - Machine utilization (gaps = idle time, clusters = overload).
    - Correlations between job priorities and completion times.

**Output:**
- A process map showing:
  - Average/median job flow times (from release to completion).
  - Task-level metrics (processing time, waiting time, setup time).
  - Resource utilization (productive time vs. idle/setup time).

---

### **1.2 Quantifying Key Metrics**

#### **A. Job Flow Times, Lead Times, and Makespan Distributions**
- **Metrics:**
  - **Flow Time:** `Completion Timestamp - Release Timestamp` for each job.
  - **Lead Time:** `Due Date - Release Timestamp` (planned) vs. `Completion Timestamp - Release Timestamp` (actual).
  - **Makespan:** Time to complete a batch of jobs (e.g., all jobs released in a week).
- **Process Mining Techniques:**
  - **Aggregated Performance Analysis:** Compute distributions (mean, median, 95th percentile) of flow times by job type, priority, or customer.
  - **Variant Analysis:** Compare flow times for jobs that followed "optimal" vs. "suboptimal" paths (e.g., jobs delayed by bottlenecks).
  - **Conformance Checking:** Align actual flow times with planned lead times to quantify schedule adherence.

#### **B. Task Waiting Times (Queue Times)**
- **Metrics:**
  - **Queue Time:** `Task Start Timestamp - Queue Entry Timestamp` for each task.
  - **Queue Length:** Number of jobs waiting at a machine over time.
- **Process Mining Techniques:**
  - **Social Network Analysis (SNA):** Identify machines with the longest queues (potential bottlenecks).
  - **Performance Filtering:** Isolate periods of high queue times (e.g., during shift changes or breakdowns).
  - **Root Cause Analysis:** Correlate queue times with:
    - Upstream machine utilization (e.g., a bottleneck causing starvation downstream).
    - Job priorities (e.g., high-priority jobs skipping queues).

#### **C. Resource Utilization**
- **Metrics:**
  - **Productive Time:** Time spent on actual task processing.
  - **Setup Time:** Time spent on sequence-dependent setups.
  - **Idle Time:** Time between task completion and next task start.
  - **Breakdown Time:** Time lost to unplanned maintenance.
- **Process Mining Techniques:**
  - **Resource Utilization Heatmaps:** Visualize machine/operator utilization over time (e.g., Gantt charts).
  - **Setup Time Analysis:**
    - Extract setup durations from logs (e.g., `Setup End - Setup Start`).
    - Group by `(Previous Job, Current Job)` pairs to quantify sequence-dependent setup times.
    - Build a **setup time matrix** for each machine (e.g., switching from Job A to Job B takes 30 min, but Job B to Job A takes 10 min).
  - **Operator Efficiency:** Compare task durations across operators to identify skill gaps or training needs.

#### **D. Schedule Adherence and Tardiness**
- **Metrics:**
  - **Tardiness:** `max(0, Completion Timestamp - Due Date)`.
  - **Earliness:** `max(0, Due Date - Completion Timestamp)`.
  - **On-Time Delivery Rate:** % of jobs completed by due date.
- **Process Mining Techniques:**
  - **Tardiness Heatmaps:** Plot tardiness by job priority, customer, or machine.
  - **Conformance Checking:** Compare actual completion times to due dates to identify systemic delays.
  - **Variant Analysis:** Compare paths of on-time vs. late jobs to identify common delay patterns (e.g., jobs routed through Machine X are frequently late).

#### **E. Impact of Disruptions**
- **Metrics:**
  - **Breakdown Impact:** Delay caused by unplanned downtime (e.g., `Completion Timestamp with Breakdown - Estimated Completion Timestamp without Breakdown`).
  - **Priority Change Impact:** Delay caused by "hot jobs" preempting others.
- **Process Mining Techniques:**
  - **Event Log Filtering:** Isolate periods with disruptions (e.g., `Event Type = "Breakdown Start"`).
  - **Causal Analysis:** Use **process cubes** to correlate disruptions with:
    - Increased queue times.
    - Extended flow times.
    - Higher tardiness.
  - **What-If Analysis:** Simulate the impact of removing disruptions (e.g., "How much would tardiness improve if breakdowns were reduced by 50%?").

---

## **2. Diagnosing Scheduling Pathologies**

Using the insights from process mining, we can identify key inefficiencies in Precision Parts Inc.’s current scheduling approach.

---

### **2.1 Bottleneck Identification**
**Symptoms:**
- Long queue times at specific machines (e.g., `MILL-02` in the log snippet).
- High utilization (>90%) for certain machines while others are underutilized.
- Jobs frequently delayed after passing through a specific machine.

**Process Mining Evidence:**
- **Social Network Analysis (SNA):** Machines with the highest "in-degree" (most incoming jobs) and longest queue times.
- **Performance Spectrum:** Gaps in downstream machines (starvation) caused by upstream bottlenecks.
- **Setup Time Analysis:** Bottlenecks may also have high setup times due to poor sequencing.

**Example:**
- If `MILL-02` has a utilization of 95% and an average queue time of 4 hours, while `LATHE-01` is at 60% utilization, `MILL-02` is likely a bottleneck.

---

### **2.2 Poor Task Prioritization**
**Symptoms:**
- High-priority jobs (e.g., `JOB-7005` in the log) are frequently delayed.
- Jobs with tight due dates miss deadlines despite having higher priority.
- "Hot jobs" disrupt schedules but do not always improve overall tardiness.

**Process Mining Evidence:**
- **Tardiness Analysis:** High-priority jobs have higher tardiness than low-priority jobs.
- **Variant Analysis:** Compare paths of on-time vs. late high-priority jobs to identify where delays occur.
- **Queue Time Analysis:** High-priority jobs spend excessive time waiting at bottlenecks.

**Example:**
- If `JOB-7005` (priority changed to "High") still misses its due date, the current dispatching rules (e.g., FCFS) are ineffective.

---

### **2.3 Suboptimal Sequencing and Setup Times**
**Symptoms:**
- High total setup time across machines.
- Jobs with similar requirements are not batched together.
- Setup times vary significantly based on job sequence.

**Process Mining Evidence:**
- **Setup Time Matrix:** Identify sequences with long setup times (e.g., switching from `JOB-6998` to `JOB-7001` takes 23.5 min vs. 5 min for similar jobs).
- **Process Variants:** Compare jobs with high vs. low setup times to identify common patterns (e.g., material changes, tooling requirements).
- **Utilization Analysis:** Machines spend >20% of time on setups.

**Example:**
- If `CUT-01` has a setup time of 23.5 min for `JOB-7001` after `JOB-6998`, but only 5 min if `JOB-7002` (similar material) follows `JOB-6998`, the current sequencing is suboptimal.

---

### **2.4 Starvation of Downstream Resources**
**Symptoms:**
- Some machines (e.g., `GRIND-01`) have long idle periods.
- Jobs pile up at bottlenecks, starving downstream machines.

**Process Mining Evidence:**
- **Performance Spectrum:** Gaps in downstream machines while upstream machines are overloaded.
- **Queue Time Analysis:** Downstream machines have low queue lengths despite high WIP upstream.
- **Bottleneck Propagation:** Delays at one machine cascade to others.

**Example:**
- If `MILL-02` (bottleneck) has a queue of 10 jobs, but `GRIND-01` is idle, the scheduling system is not coordinating work centers effectively.

---

### **2.5 Bullwhip Effect in WIP**
**Symptoms:**
- WIP levels fluctuate wildly over time.
- High WIP at some work centers, low at others.
- Jobs spend excessive time waiting between operations.

**Process Mining Evidence:**
- **WIP Heatmaps:** Plot WIP levels over time to identify peaks and troughs.
- **Flow Time Analysis:** Jobs with longer flow times have more WIP accumulation.
- **Queue Length Variability:** High standard deviation in queue lengths at machines.

**Example:**
- If WIP at `CUT-01` spikes every Monday due to batch releases, but `MILL-02` is idle, the scheduling system is not smoothing workload.

---

## **3. Root Cause Analysis of Scheduling Ineffectiveness**

The pathologies identified stem from fundamental limitations in Precision Parts Inc.’s current scheduling approach.

---

### **3.1 Limitations of Static Dispatching Rules**
**Problem:**
- **FCFS (First-Come-First-Served):** Ignores due dates, priorities, and downstream impacts.
- **EDD (Earliest Due Date):** May overload bottlenecks with near-due jobs, increasing setup times.
- **Local Optimization:** Rules applied at individual machines without considering the entire shop floor.

**Process Mining Evidence:**
- **Tardiness Analysis:** Jobs with earlier due dates are not always prioritized effectively.
- **Queue Time Analysis:** FCFS leads to long waits for high-priority jobs.

---

### **3.2 Lack of Real-Time Visibility**
**Problem:**
- No holistic view of shop floor status (machine availability, queue lengths, job progress).
- Schedulers rely on outdated information (e.g., MES data is not used for dynamic adjustments).

**Process Mining Evidence:**
- **Performance Spectrum:** Gaps between task completion and next task start (idle time due to lack of coordination).
- **Disruption Impact:** Breakdowns cause cascading delays because schedulers are not alerted in real time.

---

### **3.3 Inaccurate Task Duration Estimates**
**Problem:**
- Planned task durations (e.g., 60 min for `JOB-7001` cutting) often differ from actuals (66.4 min).
- Setup times are not accounted for in planning.

**Process Mining Evidence:**
- **Duration Variability:** High standard deviation in task durations (e.g., cutting varies from 50-80 min).
- **Setup Time Underestimation:** Actual setup times (23.5 min) exceed planned (20 min).

---

### **3.4 Ineffective Handling of Sequence-Dependent Setups**
**Problem:**
- Current scheduling does not consider setup time dependencies.
- Jobs are sequenced arbitrarily, leading to long setup times.

**Process Mining Evidence:**
- **Setup Time Matrix:** Some job sequences take 3x longer than others.
- **Utilization Analysis:** Machines spend >20% of time on setups.

---

### **3.5 Poor Coordination Between Work Centers**
**Problem:**
- No centralized scheduling; each machine operates independently.
- Upstream decisions (e.g., releasing a batch of jobs) do not account for downstream capacity.

**Process Mining Evidence:**
- **Starvation Analysis:** Downstream machines are idle while upstream machines are overloaded.
- **WIP Fluctuations:** Bullwhip effect due to lack of workload smoothing.

---

### **3.6 Inadequate Disruption Handling**
**Problem:**
- No proactive strategies for breakdowns or urgent jobs.
- "Hot jobs" disrupt schedules but do not always improve overall performance.

**Process Mining Evidence:**
- **Breakdown Impact:** Delays propagate to downstream machines.
- **Priority Change Impact:** High-priority jobs preempt others but still miss deadlines.

---

### **3.7 Differentiating Scheduling vs. Capacity Issues**
**Process Mining Approach:**
- **Bottleneck Analysis:** If a machine is consistently at 100% utilization, the issue is capacity, not scheduling.
- **Queue Time Analysis:** If queue times are high but utilization is low, the issue is scheduling (e.g., poor prioritization).
- **Setup Time Analysis:** If setup times are high but utilization is low, the issue is sequencing.

**Example:**
- If `MILL-02` is at 95% utilization with long queues, adding capacity (e.g., a second machine) may be needed.
- If `LATHE-01` is at 60% utilization with long queues, improving sequencing (e.g., batching similar jobs) can help.

---

## **4. Developing Advanced Data-Driven Scheduling Strategies**

To address the pathologies, I propose three sophisticated, data-driven scheduling strategies informed by process mining insights.

---

### **Strategy 1: Dynamic Multi-Factor Dispatching Rules**
**Objective:** Replace static dispatching rules (FCFS, EDD) with a dynamic, context-aware rule that considers multiple factors simultaneously.

**Core Logic:**
- **Weighted Priority Score (WPS):** Assign a score to each job in the queue based on:
  - **Due Date Proximity:** `1 / (Due Date - Current Time)` (higher for near-due jobs).
  - **Priority:** `Priority Weight` (e.g., High = 3, Medium = 2, Low = 1).
  - **Remaining Processing Time (RPT):** `Sum of Planned Durations for Remaining Tasks` (shorter RPT jobs get priority).
  - **Downstream Machine Load:** `Queue Length at Next Machine` (avoid sending jobs to overloaded machines).
  - **Sequence-Dependent Setup Time:** `Estimated Setup Time if Job is Selected Next` (lower setup time = higher priority).
- **Formula:**
  ```
  WPS = (Priority Weight * Due Date Proximity) / (RPT * (1 + Downstream Load) * (1 + Setup Time))
  ```
- **Decision Rule:** Select the job with the highest WPS.

**Process Mining Insights Used:**
- **Setup Time Matrix:** To estimate sequence-dependent setup times.
- **Queue Time Analysis:** To identify downstream bottlenecks.
- **Tardiness Analysis:** To weight due date proximity and priority.

**Expected Impact:**
| KPI               | Baseline (FCFS/EDD) | Dynamic WPS       | Improvement       |
|-------------------|---------------------|-------------------|-------------------|
| Tardiness         | High                | Medium            | 30-50% reduction  |
| WIP               | High                | Medium            | 20-40% reduction  |
| Setup Time        | High                | Low               | 40-60% reduction  |
| Machine Utilization| Imbalanced         | Balanced          | 10-20% improvement|

**Implementation:**
- Deploy as a real-time decision engine integrated with the MES.
- Continuously update weights based on process mining feedback.

---

### **Strategy 2: Predictive Scheduling with Machine Learning**
**Objective:** Generate realistic schedules by predicting task durations, setup times, and disruptions using historical data.

**Core Logic:**
1. **Predictive Models:**
   - **Task Duration Prediction:** Train a regression model (e.g., XGBoost, Random Forest) to predict actual task duration based on:
     - Job type, material, complexity.
     - Machine, operator.
     - Time of day (e.g., fatigue effects).
   - **Setup Time Prediction:** Predict setup time based on `(Previous Job, Current Job)` pairs using the setup time matrix.
   - **Breakdown Prediction:** Use survival analysis or LSTM networks to predict machine failures based on usage patterns.
2. **Schedule Generation:**
   - Use **constraint programming** or **genetic algorithms** to generate a schedule that:
     - Minimizes tardiness.
     - Balances machine loads.
     - Accounts for predicted setup times and breakdowns.
   - **Rolling Horizon:** Re-optimize the schedule every 4 hours using updated predictions.
3. **Proactive Adjustments:**
   - If a breakdown is predicted, preemptively reroute jobs.
   - If a "hot job" arrives, dynamically insert it into the schedule with minimal disruption.

**Process Mining Insights Used:**
- **Task Duration Distributions:** To train predictive models.
- **Setup Time Matrix:** To predict sequence-dependent setups.
- **Breakdown Patterns:** To train failure prediction models.

**Expected Impact:**
| KPI               | Baseline            | Predictive Scheduling | Improvement       |
|-------------------|---------------------|-----------------------|-------------------|
| Tardiness         | High                | Low                   | 50-70% reduction  |
| Lead Time Variability| High             | Low                   | 40-60% reduction  |
| Machine Utilization| Imbalanced         | Balanced              | 15-25% improvement|
| Disruption Impact | High                | Low                   | 30-50% reduction  |

**Implementation:**
- Deploy as a cloud-based scheduling engine with real-time MES integration.
- Continuously retrain models with new data.

---

### **Strategy 3: Setup Time Optimization via Intelligent Batching and Sequencing**
**Objective:** Minimize sequence-dependent setup times by intelligently batching similar jobs and optimizing job sequences at bottleneck machines.

**Core Logic:**
1. **Job Clustering:**
   - Use **hierarchical clustering** or **k-means** to group jobs with similar setup requirements (e.g., material, tooling, dimensions).
   - Example: Jobs requiring the same cutting tool can be batched together to reduce setup time.
2. **Sequence Optimization:**
   - For each machine, solve a **Traveling Salesman Problem (TSP)** to find the job sequence that minimizes total setup time.
   - Use **genetic algorithms** or **simulated annealing** to handle large job sets.
3. **Dynamic Batching:**
   - If a machine is idle, batch similar jobs from the queue to minimize future setups.
   - If a "hot job" arrives, insert it into the sequence with minimal disruption (e.g., swap with a similar job).

**Process Mining Insights Used:**
- **Setup Time Matrix:** To quantify setup time savings from batching.
- **Bottleneck Analysis:** To prioritize sequencing at critical machines.
- **Job Similarity Metrics:** Derived from historical setup patterns.

**Expected Impact:**
| KPI               | Baseline            | Setup Optimization   | Improvement       |
|-------------------|---------------------|----------------------|-------------------|
| Setup Time        | High                | Low                  | 50-80% reduction  |
| Machine Utilization| Low (due to setups) | High                 | 20-40% improvement|
| Flow Time         | High                | Medium               | 20-30% reduction  |
| Tardiness         | High                | Medium               | 15-25% reduction  |

**Implementation:**
- Deploy as a module within the MES or scheduling engine.
- Update job clusters and sequences weekly based on new data.

---

## **5. Simulation, Evaluation, and Continuous Improvement**

To ensure the proposed strategies work in practice, we must rigorously test them using simulation and establish a framework for continuous improvement.

---

### **5.1 Discrete-Event Simulation (DES) for Strategy Evaluation**
**Objective:** Compare the proposed strategies against the baseline and each other under realistic conditions.

**Simulation Setup:**
1. **Model Parameterization:**
   - **Task Durations:** Sample from historical distributions (mined from logs).
   - **Setup Times:** Use the setup time matrix.
   - **Job Arrivals:** Replay historical job release patterns or generate synthetic arrivals.
   - **Breakdowns:** Inject disruptions based on historical frequencies and durations.
   - **Priority Changes:** Simulate "hot jobs" with dynamic priority updates.
2. **Scenarios to Test:**
   - **Baseline:** Current FCFS/EDD dispatching rules.
   - **Strategy 1:** Dynamic Multi-Factor Dispatching.
   - **Strategy 2:** Predictive Scheduling.
   - **Strategy 3:** Setup Time Optimization.
   - **Hybrid:** Combine Strategies 1 and 3 (dynamic dispatching + setup optimization).
   - **Stress Tests:**
     - High job arrival rate (peak season).
     - Frequent breakdowns (worst-case scenario).
     - Many "hot jobs" (disruption-heavy scenario).
3. **KPIs to Measure:**
   - Tardiness (mean, 95th percentile).
   - WIP levels (average, peak).
   - Machine utilization (productive time, idle time, setup time).
   - Flow time (mean, variability).
   - On-time delivery rate.

**Example Simulation Results:**
| Scenario               | Tardiness (hrs) | WIP (jobs) | Utilization (%) | Flow Time (hrs) |
|------------------------|-----------------|------------|-----------------|-----------------|
| Baseline (FCFS)        | 48              | 120        | 65 (imbalanced) | 72              |
| Dynamic Dispatching    | 24              | 80         | 75 (balanced)   | 50              |
| Predictive Scheduling  | 12              | 60         | 80 (balanced)   | 40              |
| Setup Optimization     | 36              | 90         | 85 (balanced)   | 55              |
| Hybrid (1 + 3)         | 18              | 70         | 82 (balanced)   | 45              |

**Tools:**
- **SimPy** (Python) or **AnyLogic** for DES.
- **Process Mining Tools:** Celonis, Disco, or PM4Py for data extraction.

---

### **5.2 Continuous Monitoring and Adaptation Framework**
**Objective:** Ensure the scheduling strategy remains effective as conditions change (e.g., new machines, product mix shifts).

**Framework:**
1. **Real-Time Monitoring:**
   - **KPI Dashboards:** Track tardiness, WIP, utilization, and flow time in real time.
   - **Anomaly Detection:** Use statistical process control (SPC) to flag deviations (e.g., sudden increase in tardiness).
   - **Process Mining Alerts:** Automatically detect:
     - New bottlenecks (e.g., a machine’s queue time exceeds a threshold).
     - Ineffective dispatching (e.g., high-priority jobs missing deadlines).
     - Setup time drift (e.g., setup times increasing due to tool wear).
2. **Feedback Loops:**
   - **Model Retraining:** Monthly retraining of predictive models (task durations, setup times, breakdowns).
   - **Rule Adjustment:** Quarterly review of dispatching rule weights (e.g., due date proximity vs. priority).
   - **Job Clustering Updates:** Recluster jobs based on new setup time data.
3. **Root Cause Analysis for Drifts:**
   - If tardiness increases, use process mining to:
     - Compare current job paths to historical "good" paths.
     - Identify new bottlenecks or disruptions.
     - Check if setup times have changed (e.g., due to new tooling).
4. **A/B Testing:**
   - Deploy new strategies in parallel with the baseline (e.g., Strategy 1 on Machine A, baseline on Machine B).
   - Compare KPIs to validate improvements before full rollout.

**Example Workflow:**
1. **Alert:** Tardiness spikes by 20% in the last week.
2. **Diagnosis:** Process mining reveals `MILL-02` is a new bottleneck due to increased job complexity.
3. **Action:**
   - Temporarily increase the weight of `Downstream Load` in the dispatching rule for `MILL-02`.
   - Schedule preventive maintenance for `MILL-02`.
   - Retrain the predictive model to account for new job types.
4. **Validation:** Monitor KPIs to confirm tardiness returns to baseline.

---

## **Conclusion**

Precision Parts Inc.’s scheduling challenges stem from a combination of static dispatching rules, lack of real-time visibility, and ineffective handling of sequence-dependent setups and disruptions. By leveraging process mining, we can:

1. **Quantify** the current performance (tardiness, WIP, utilization) and diagnose pathologies (bottlenecks, poor prioritization, setup inefficiencies).
2. **Identify root causes** (inaccurate estimates, local optimization, lack of coordination).
3. **Develop advanced strategies** (dynamic dispatching, predictive scheduling, setup optimization) that address these issues.
4. **Validate** the strategies using simulation before deployment.
5. **Continuously improve** the system through real-time monitoring and feedback loops.

The proposed approach transforms scheduling from a reactive, rule-based process to a **proactive, data-driven, and adaptive** system, significantly improving on-time delivery, reducing WIP, and balancing resource utilization.