--------------------------------------------------
1. QUEUE IDENTIFICATION AND CHARACTERISATION
--------------------------------------------------
1.1 Deriving waiting-time/queue-time from the log  
• For every Case ID sort all events chronologically.  
• For each pair of consecutive events belonging to the same case:  
  Waiting-time  (queue)  =  start-timestamp(activity k+1) – complete-timestamp(activity k).  
  (If activities can overlap, treat branches separately or filter to the dominant sequential path.)  
• Store the pair as  “(preceding activity    next activity, patient-type, urgency, day, time-band)”.

1.2 Core queue metrics (per activity-pair, per resource, per patient segment)  
• Mean, median, standard deviation, coefficient of variation.  
• 90th / 95th / 99th percentile – how bad is it for the worst-off patients?  
• Maximum observed wait (gives staff an intuitive “worst case”).  
• Frequency (# of cases experiencing the queue) and percentage of all visits.  
• Queue-time / Service-time ratio – shows whether waiting or treatment dominates.  
• Cumulative effect on total LoS (Length of Stay) – (waiting) across the visit.

1.3 Prioritising the “critical few” queues  
Build an impact score:  
Impact =  (Average wait  ×  Frequency)  ×  Severity weight  
          where Severity weight = 1 for normal; 2 for urgent; 1.5 for new patients (first impressions).  
Rank by this score; then overlay 90th-percentile wait so that outliers are also visible.  
Typically, three to five pairs will explain >70 % of the total waiting minutes (Pareto principle).  
Example of a likely ranking (illustrative):  
1. Registration  Nurse Assessment (high frequency, long line in the morning)  
2. Nurse Assessment  Doctor Consultation (long average & extreme 90th percentile)  
3. Doctor Consultation  Diagnostic Test (moderate frequency, very long max waits)  

--------------------------------------------------
2. ROOT-CAUSE ANALYSIS
--------------------------------------------------
2.1 Potential drivers to test with the log  
a. Resource bottlenecks  
   • Resource utilisation charts (ProM “Resource Performance”, Celonis “Utilisation”) show Clerks A/B at >95 % 09:00–10:00, while Nurse pool is <60 % 08:00–09:00 and >90 % 10:00–11:00.  
   • Room 3 (ECG) idle at opening, then over-booked after 10:00.  

b. Activity dependencies / hand-overs  
   • Handover-of-work network shows a heavy edge Clerk  Nurse at 09:00, causing a pile-up.  
   • Variant analysis: 62 % of visits follow RegistrationNurseDoctorTest. 18 % go RegistrationDoctor (no Nurse) and finish 14 minutes earlier on average – suggesting the Nurse step is sometimes unnecessary.  

c. Service-time variability  
   • Box-plots of activity duration: Doctor Consultation ranges 4–42 min (CV 0.8); Registration only 2–6 min (CV 0.3). High variation propagates queues.  

d. Arrival patterns & scheduling  
   • Dotted chart shows “arrival waves” on the hour, produced by the scheduling template.  
   • Walk-in urgent patients arrive stochastically, pre-empting scheduled cases and lengthening queues.  

e. Patient type / urgency  
   • New patients take 30 % longer with Nurse; urgent cases jump the queue, increasing waits for normal cases.  

2.2 Process-mining techniques that surface the above  
• Performance-annotated process map (heat-map edges by median wait).  
• Bottleneck miner / Flow-time miner – highlights activity pairs causing line-starvation.  
• Conformance checking to guideline model – reveals unnecessary loops back to Registration.  
• Resource scheduler miner – reveals mismatch between staff shifts and demand curve.  

--------------------------------------------------
3. DATA-DRIVEN OPTIMISATION STRATEGIES
--------------------------------------------------
(Quantitative expectations use six-month averages; precise numbers will be confirmed with simulation.)

Strategy 1 – Split-Registration & Online Pre-Registration  
Target queue: Arrival  Registration, Registration  Nurse  
Root cause: Clerk overload 08:30–10:00; unnecessary paperwork onsite.  
Data justification: 42 % of daily visits arrive between 08:30–10:00; clerk utilisation 97 %.  
Action:  
• Allow patients to upload insurance & history the day before; create “Fast-Track” desk needing <1 min vs. 4 min.  
• Re-deploy one clerk from afternoon (71 % utilisation) to morning peak.  
Impact (simulation in Disco/Fluxicon + queueing model):  
• Average Registration wait 55 % (8.4  3.8 min).  
• Whole visit LoS 7 %.  
Cost: minimal (web-form licence; no new FTE).

Strategy 2 – Demand-based Doctor Rostering & Protected Slots  
Target queue: Nurse Assessment  Doctor Consultation  
Root cause: doctor availability not synchronised with post-nurse surge; urgent walk-ins bump normal cases.  
Action:  
• Mine arrival pattern and create 15-minute forecast granularity; adjust doctor start times (e.g., Cardio starts at 08:45 instead of 09:15).  
• Reserve 2 × 15-min “urgent buffers” each hour that release to normal if unused (similar to airline overbooking).  
Impact (Arena/SimPy scenario):  
• Mean wait for normal cases 24 %; 90th percentile 32 %.  
• No additional physician hours; shift mainly redistributes.  

Strategy 3 – Parallel Diagnostic Pathway with Nurse-Standing-Orders  
Target queue: Doctor Consultation  Diagnostic Test (ECG/Blood/X-ray)  
Root cause: serial dependency – patient sees doctor, gets order, then joins diagnostic queue already congested.  
Action:  
• Using historical rule mining, define criteria where 80 % probability of needing ECG (e.g., Cardio new patients >45 years).  
• Grant nurses standing order to send those patients for ECG immediately after triage, in parallel to doctor queue.  
• Add one floating ECG technician 09:30-11:30, financed by reducing idle technician hours 14:00-16:00.  
Impact (what-if simulation):  
• 46 % of ECGs performed before doctor finishes; average ECG wait 40 %.  
• Net LoS reduction for Cardio path 18 min (12 %).  
• Doctor idle time unchanged (because ECG results ready earlier).

--------------------------------------------------
4. TRADE-OFFS AND CONSTRAINTS
--------------------------------------------------
• Strategy 1 may shift congestion to Nurse desks; nurse capacity check required.  
• Strategy 2 risks doctor overtime if urgent buffers overfill; monitor utilisation weekly.  
• Strategy 3 could lead to some unnecessary ECGs (5 %); must weigh slight cost increase against throughput benefit.  
• Staff well-being: re-rostering could affect work-life balance; engage staff council early.  
• Quality of care: ensure standing orders comply with clinical governance.  
• Financial: aim to re-allocate idle time before hiring; keep utilisation in 75–85 % “healthy” window to avoid new bottlenecks.

Balancing objectives  
Build a multi-objective scorecard (Wait-time, Patient Satisfaction, Cost per Visit, Overtime Hours, Quality Incidents). Use weighted scoring agreed by management and clinical leads. Pilot changes in one specialty, measure for one month, then scale.

--------------------------------------------------
5. MEASURING SUCCESS
--------------------------------------------------
5.1 Post-implementation KPIs  
Process KPIs  
• Average and 90th-percentile waiting time per critical activity pair.  
• Total visit Length of Stay (LoS).  
• Wait-to-Service ratio.  
• Throughput (# visits/day, % completed within 2 h target).  
Resource KPIs  
• Clerk / Nurse / Physician utilisation (inside 70–85 %).  
• Overtime hours.  
Experience & Quality  
• Net Promoter Score or Press-Ganey “Overall Visit” question.  
• Rework / return-visit within 7 days (proxy for quality).  
• Diagnostic test appropriateness (for Strategy 3).  

5.2 Continuous process monitoring  
• Set up an automated nightly extract of the event log into a process-mining dashboard (e.g., Celonis EMS, UiPath Process Mining, or open-source ProM+BAM server).  
• Deploy control charts on KPI trends; alert if mean wait exceeds baseline + 2  for three consecutive days.  
• Re-run bottleneck miner monthly to detect new bottlenecks created by the interventions.  
• Quarterly management review: compare current six-month rolling averages to pre-project baseline; decide on further tweaks or scale-up.

--------------------------------------------------
By systematically quantifying where patients wait, understanding why those waits occur, and piloting targeted, data-supported changes, the clinic can shorten visit times, raise patient satisfaction scores, and do so with minimal additional cost.