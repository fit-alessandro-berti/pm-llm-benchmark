## 1) Analyzing Resource Behavior and Assignment Patterns

### 1.1 Prepare/validate the event log for resource analysis
To make resource-centric process mining reliable, I would first standardize the log into an analysis-ready schema:

- **Case ID:** Incident/Ticket ID  
- **Activity:** e.g., Ticket Created, Assign L1, Work Start/End (per tier), Escalate, Reassign, Resolve, Close  
- **Timestamp(s):** Start + Complete where available (derive durations)  
- **Resource:** Agent ID (plus “System/Dispatcher” as separate resource types)  
- **Resource attributes:** Tier (L1/L2/L3), skill set, location/shift (if available)  
- **Case attributes:** Priority, Category, Required Skill, channel, customer/CI, etc.  
- **Derived events:**  
  - “Queue wait” segments (time between assignment and work start)  
  - “Handover” markers (when resource changes)  
  - “Skill-match flag” (assigned agent has required skill Y/N; optionally proficiency level)

This enables separating **waiting vs working time**, and distinguishing **routing decisions** (Assign/Escalate/Reassign) from **execution** (Work).

---

### 1.2 Metrics for agent and tier behavior (what to measure)
I’d calculate metrics at **agent**, **tier**, **skill**, and **priority/category** slices. Key metrics:

**Workload & utilization**
- Tickets handled per agent/tier (count and weighted by priority)
- Active work time per agent (sum of work durations)
- **Utilization proxy:** active work time / available time (if schedule exists) or relative utilization vs peers
- WIP/queue load at assignment time (if inferable from timestamps)

**Flow efficiency & timeliness**
- **Queue waiting time**: Assign  Work Start (per tier, per agent)
- **Touch time**: Work Start  Work End (per agent, per activity)
- **End-to-end lead time**: Created  Resolved/Closed (per priority/category)
- **Rework/loop indicators**: number of reassignments/escalations, tier back-and-forth

**Quality/containment**
- **L1 First-Contact Resolution (FCR):** % cases resolved without escalation beyond L1 (by category/priority/channel and by L1 agent)
- **Escalation rate** L1L2, L2L3, plus “bounce-back” (L2L1) if present
- **Reassignment rate** within the same tier vs cross-tier
- **“Right-first-time assignment”**: % cases where first assigned agent had the required skill (or the eventual skill required)

**Skill alignment**
- **Skill-match rate:** assigned agent skills contain Required Skill (or nearest mapped skill family)
- **Skill underutilization:** specialist skill holders spending time on “basic” categories (e.g., password resets) or low complexity work
- **Skill scarcity pressure:** queues/waits for tickets requiring specific skills

**SLA outcomes**
- SLA compliance % by priority
- **Time-to-first-response** and **time-to-resolve** vs SLA target
- Breach probability by tier path variant (e.g., L1L2ReassignL2 vs L1L2 direct)

---

### 1.3 Process mining techniques to reveal actual assignment patterns
**a) Resource interaction / handover-of-work (social network analysis)**
- Build handover networks: edges represent “ticket passed from agent X to agent Y” (or tier-to-tier).
- Identify:
  - Heavy handover pairs (frequent reassign routes)
  - “Hub” agents who receive many escalations (potential bottleneck)  
  - “Ping-pong” patterns (ABA), often indicating unclear ownership or wrong skill routing

**b) Role discovery (organizational mining)**
- Cluster agents by activity profiles (what they *actually* do) to infer de-facto roles:
  - True L1 resolvers vs L1 “triage-only”
  - L2 generalists vs L2 specialists
  - Dispatcher behavior patterns (who they route to, and when)

Compare discovered roles to intended tier model:
- Intended: L1 handles basic troubleshooting; L2/L3 handle specialized.
- Observed: e.g., L2 specialists doing repetitive low-skill tasks; L1 escalating too early; dispatcher overriding skill logic.

**c) Variant analysis of paths (assignment/escalation variants)**
- Identify dominant routing variants by priority/category/required skill:
  - “Created  Assign L1  Work L1  Escalate L2  Work L2  Resolve”
  - vs variants with “Reassign” loops
- Measure performance per variant (lead time, SLA breach rate, reassign count).

**d) Conformance checking vs intended routing rules**
If TechSolve has documented rules (e.g., “Network-Firewall must go to L2 Networking”), we can:
- Encode them as constraints (or a reference model) and quantify deviations:
  - % cases violating skill routing
  - where deviations originate (dispatcher vs L1 self-assignment)
  - impact on SLA/lead time

---

### 1.4 Skill utilization analysis (are specialists used effectively?)
I would build a **skill-to-work matrix**:

- Rows: skills (e.g., Networking-Firewall, Database-SQL, OS-WindowsServer, Security-IAM, App-CRM)
- Columns: tiers/agents
- Cells: number of tickets, touch time, waiting time, SLA breach rate

Then measure:

- **Skill scarcity index:** average queue wait for cases requiring skill S; number of available agents with S; arrival rate of S tickets.
- **Skill mismatch cost:** cases where first assigned agent lacked S  extra reassignments/time.
- **Downward skill usage:** time spent by high-tier/high-skill agents on categories that could be standardized (e.g., Access Management resets), indicating routing or knowledge gaps.

This directly addresses the complaint “L2/L3 specialists doing L1 work.”

---

## 2) Identifying Resource-Related Bottlenecks and Issues

### 2.1 Pinpoint bottlenecks by separating waiting from working
Using the mined performance model:
- For each tier and skill group, compute **median and P90 queue wait** (Assign  Work Start).
- A true capacity bottleneck shows high waiting time *without proportionally high touch time*.

Examples of bottleneck signatures:
- **Skill bottleneck:** “Database-SQL” tickets wait 6 hours before L2 starts, while touch time is 30–60 minutes.
- **Agent bottleneck:** one agent receives 40% of “Networking-Firewall” tickets and has high WIP, while others are idle.

### 2.2 Quantify reassignment/escalation impact
For each reassignment/escalation event, compute incremental delays:
- **Reassignment delay:** time between “Reassign” and next “Work Start”
- **Escalation delay:** time between “Escalate L2” and “Work L2 Start”
- **Total “routing overhead” per case:** sum of all such waits

Then quantify:
- Average added lead time per reassignment (and by tier boundary)
- % of cases with 1 reassignment
- % of lead time attributable to routing vs execution

A typical outcome we want: “Each additional reassignment adds +X hours median lead time and increases SLA breach odds by Y%.”

### 2.3 Identify incorrect initial assignments and their consequences
Define “incorrect initial assignment” pragmatically:
- First working agent lacks Required Skill (or wrong tier for priority/category)
- Or case later requires a different skill (inferred from later resolver’s skills or reclassification events)

Measure:
- **Mismatch rate** by channel (phone/email/portal), by dispatcher vs self-assigned
- Downstream effect: extra reassignments, longer queues, higher breach rate

### 2.4 Detect overloaded/underutilized agents and uneven distribution
Use:
- Tickets/day, active minutes/day, concurrent WIP proxy
- Queue wait of tickets assigned to agent (high wait suggests agent overloaded or slow start)
- Work duration percentiles (to detect underperformance or overly complex allocation)

Also check fairness:
- Gini coefficient or coefficient of variation on workload distribution across agents in same tier/skill pool.

### 2.5 Correlate assignment patterns with SLA breaches
Model SLA breach as an outcome and link to predictors mined from the process:
- # reassignments
- # tier hops
- initial skill-match flag
- waiting time in each tier
- which agent/team handled which step
- priority/category/required skill

Tools:
- Statistical tests for differences (breached vs non-breached)
- Predictive model (logistic regression / gradient boosted trees) for interpretability:
  - “If initial mismatch + 2+ reassignments + L2 queue wait > 2h  breach risk 70%.”

This creates a measurable, defensible case for changing routing logic.

---

## 3) Root Cause Analysis for Assignment Inefficiencies

### 3.1 Likely root causes (and how the log will validate them)
**Round-robin ignoring skills/workload**
- Evidence: low skill-match rate on first assignment, high reassign rate, high variance in queue wait by agent.

**Inaccurate/incomplete skill profiles**
- Evidence: agents frequently resolving tickets outside their documented skills (or failing those inside); repeated reassignments to “the same few people” despite “many listed.”

**Poor initial categorization / required skill identification**
- Evidence: category/required skill changes mid-case; early escalation notes like “wrong queue”; high mismatch rate in specific channels (email free text often misclassified).

**Lack of real-time workload visibility**
- Evidence: assignments made to agents with high WIP leading to long “Assign  Start” delays, while others start quickly.

**L1 training/empowerment gaps**
- Evidence: low FCR in categories where peers have higher FCR; escalations happening very early with minimal work time (“Work L1 duration < 5 min” then escalate).

---

### 3.2 Variant analysis: “good” vs “bad” cases
Split cases into cohorts:
- **Smooth routing:** 0 reassignments, 1 escalation, SLA met
- **Problematic routing:** 2 reassignments and/or SLA breached

Compare:
- ticket types (category/required skill), channels, time-of-day
- which dispatcher/triage agent assigned them
- whether initial skill match occurred
- queue wait contributions by tier

This usually surfaces very specific patterns (e.g., “P2 Network tickets created 08:00–10:00 are routed to general L2 pool instead of Firewall specialists”).

---

### 3.3 Decision mining: what drives bad assignment decisions
Apply decision mining at key routing points:
- **Assign L1  Escalate L2?** (predict escalation likelihood from category, priority, channel, agent, time)
- **Assign L2 to which agent?** (actual historical decision patterns)
- **Reassign reason** (from notes) vs measurable predictors

Outputs:
- Decision rules or feature importances that reveal:
  - misrouting drivers (e.g., specific categories or ambiguous required skill labels)
  - dispatcher-specific biases (always sending to a favorite agent)
  - conditions where L1 succeeds vs fails (to refine L1 scope)

---

## 4) Developing Data-Driven Resource Assignment Strategies (3+ concrete strategies)

### Strategy A — Skill-based routing with proficiency + “right-first-time” governance
**Issue addressed:** skill mismatch, reassignments, specialist time waste.

**What to implement**
- Route tickets to agents whose skill matrix matches **Required Skill** (or skill family) with weights:
  - proficiency level
  - recency (have solved similar tickets recently)
  - quality history (lower reopen rate / faster resolution for that skill)

**Process mining insight leveraged**
- Empirical skill-to-resolution mapping: which agents actually resolve which skills fastest with lowest reassignments.
- Quantified mismatch cost: added delay and breach probability when mismatched.

**Data required**
- Agent skill profiles (and proficiency rating if possible)
- Historical “resolver skill” ground truth from event logs
- Ticket required skill (or predicted skill; see Strategy C)

**Expected benefits**
- Reduced reassignments and tier bouncing
- Lower queue waits for scarce skills by distributing to *all* capable agents
- Improved SLA for P2/P3 by reducing routing overhead

---

### Strategy B — Workload-aware assignment (WIP/queue-time aware routing)
**Issue addressed:** uneven distribution, long “Assign  Start” waits, overloaded agents.

**What to implement**
- Replace round-robin with **capacity-sensitive dispatching**:
  - only assign to agents below WIP threshold
  - use shortest expected completion time: (current queue + estimated handling time)
  - include shift schedules/availability to avoid assigning to “about to log off”

**Process mining insight leveraged**
- Measured queue wait by agent and time-of-day (identifies when and where capacity breaks)
- Historical touch times by agent/skill (gives expected handling time)

**Data required**
- Real-time WIP per agent (open assigned tickets not completed)
- Work calendars / presence status (if available)
- Historical service times by skill/category/agent

**Expected benefits**
- Lower waiting time (often the largest component of lead time)
- Improved fairness and reduced burnout
- Better SLA performance without adding headcount (if true underutilization exists)

---

### Strategy C — Predictive triage: infer required skill/complexity at creation and route accordingly
**Issue addressed:** poor categorization/required-skill identification; wrong first assignment from ambiguous tickets.

**What to implement**
- A model that predicts:
  - likely Required Skill (multi-class)
  - likely escalation need (L1-resolvable vs needs L2/L3)
- Inputs: category, subcategory, channel, keywords from description, CI/application, requester org, historical patterns.

Then:
- Auto-route to the right L1 subgroup (e.g., “L1-App” vs “L1-Access”) or directly to L2 for certain high-confidence cases (especially P2).

**Process mining insight leveraged**
- Decision mining shows which attributes correlate with escalations/reassignments
- Variant analysis identifies ticket profiles that systematically fail at L1

**Data required**
- Ticket text fields (subject/description), category, CI/app tags
- Historical outcomes: who resolved, # escalations, lead time, SLA
- A controlled feedback loop: re-label required skill when resolved to improve training data

**Expected benefits**
- Higher L1 FCR where appropriate (and faster direct-to-specialist routing where not)
- Fewer “false starts” and reassignments
- Reduced time-to-start for urgent P2s

---

### Strategy D — Refine escalation criteria + create L1 “guided resolution” playbooks for top escalated types
**Issue addressed:** excessive escalations; specialists doing avoidable work.

**What to implement**
- Use mined data to identify:
  - top 10 category/skill combinations escalated from L1
  - which of those are frequently resolved quickly at L2 (suggesting they might be L1-trainable)
- Build:
  - L1 checklists/scripts
  - knowledge articles
  - decision gates: “Do X, Y, Z before escalating”
- Add a “minimum diagnostic package” requirement before escalation to reduce back-and-forth.

**Process mining insight leveraged**
- Short L2 touch times after escalation + high volume = prime candidates for L1 enablement
- Compare FCR rates among L1 agents to identify best practices to standardize

**Data required**
- Event log durations, resolution notes, KB usage (if tracked)
- Categorized outcomes (resolved at L1 vs escalated)

**Expected benefits**
- Reduced L2/L3 load, freeing specialists for true complex work
- Fewer escalations and faster resolutions for P3s

---

### Strategy E — Dynamic tier/skill pooling for peak demand (cross-skilling + temporary reallocation)
**Issue addressed:** skill scarcity bottlenecks and time-of-day SLA breaches.

**What to implement**
- From demand patterns (arrival rate by skill/time), create “flex pools”:
  - certain L2 generalists temporarily cover a bottleneck skill queue during peaks
  - designate “surge coverage” windows
- Cross-train targeted L1/L2 agents for the 2–3 highest-bottleneck skills.

**Process mining insight leveraged**
- Time-series of arrivals, queue waits, and SLA breaches by skill and hour/day
- Identified bottleneck skills with chronic waiting

**Data required**
- Ticket arrival timestamps and required skills
- Agent schedules
- Training/certification tracking

**Expected benefits**
- Reduced peak-driven SLA breaches
- Less reliance on a few specialists (risk reduction)

---

## 5) Simulation, Implementation, and Monitoring

### 5.1 Use simulation to test strategies before rollout
Build a **discrete-event simulation** using parameters mined from the log:

- Arrival distributions by priority/category/required skill (time-of-day, day-of-week seasonality)
- Service time distributions by tier, skill, and (optionally) agent
- Routing probabilities (current vs proposed)
- Resource calendars and capacity (agents per tier, shift patterns)
- Rework probabilities (reassign/escalate likelihoods) as a function of mismatch

Simulate scenarios:
- Baseline (current round-robin + manual escalation)
- Strategy A only (skill-based)
- Strategy A+B (skill + workload aware)
- Strategy A+B+C (plus predictive triage)
- With/without dynamic pooling (Strategy E)

Outputs to compare:
- SLA compliance per priority (especially P2/P3)
- Average/median/P90 lead time
- Reassignment counts
- Queue wait per skill and tier
- Specialist utilization vs low-skill workload

This de-risks changes and helps choose the best combination.

---

### 5.2 Implementation plan (practical rollout)
- **Phase 1 (4–6 weeks):** measurement + dashboards + quick wins  
  - baseline KPIs, skill-match calculation, reassignment hotspots  
  - fix obvious data issues (skill taxonomy, category mapping)
- **Phase 2 (6–10 weeks):** introduce workload-aware + skill-based routing in a subset (pilot)  
  - pick 1–2 categories (e.g., Network + Access)
  - A/B compare pilot vs control
- **Phase 3:** predictive triage + escalation policy refinement  
  - start with “assistive” recommendations before full automation
- **Phase 4:** dynamic pooling/cross-training driven by measured bottlenecks

---

### 5.3 Continuous monitoring via process mining dashboards (post-implementation)
I would deploy dashboards with drill-down from SLA breaches to routing causes.

**Core KPIs**
- SLA compliance % by priority, category, required skill
- Median/P90 end-to-end resolution time
- Median/P90 queue wait by tier and by skill
- Reassignments per ticket (avg, P90) and % tickets with 1 reassignment
- L1 FCR % (overall and by category/channel/agent)
- Right-first-time assignment % (skill-match on first working assignment)
- Specialist “low-skill load” % (time spent on tasks classified as L1-capable)

**Key process views**
- Variant explorer: top 10 routing variants and their SLA performance
- Handover network: identify new bottlenecks or ping-pong after changes
- Capacity heatmaps: workload and queue wait by hour/day and by skill
- Conformance view: violations of routing rules (e.g., “Firewall tickets assigned outside Networking group”)

**Governance triggers (alerts)**
- Skill queue wait exceeds threshold (e.g., P2 Firewall wait > 30 min)
- Spike in reassignment rate for a category (possible misclassification or new issue)
- Drift detection: predictive triage accuracy dropping, suggesting taxonomy or environment changes

---

If you can share (even anonymized) the actual activity list, SLA targets per priority, and how “Required Skill” is currently determined (manual vs inferred), I can propose a concrete KPI dictionary and a minimal set of routing rules/models to pilot first (usually the fastest route to measurable P2/P3 SLA improvement).