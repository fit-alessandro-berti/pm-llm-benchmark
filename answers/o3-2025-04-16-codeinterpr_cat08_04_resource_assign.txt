--------------------------------------------------------------------
1.  ANALYZING RESOURCE BEHAVIOR AND ASSIGNMENT PATTERNS
--------------------------------------------------------------------
a.  Metrics to calculate from the event log  
   • Workload / utilisation per agent & tier  
     – # tickets, # activities, net handling time, queue-wait time, % idle time  
   • Efficiency indicators  
     – Mean/median activity processing time, mean 1st-touch resolution time (L1), reopen rate per agent, escalation rate generated vs. solved  
   • SLA performance per resource  
     – % of tickets handled whose resolution or first-response exceeded SLA, split by priority  
   • Skill exposure  
     – Tickets per (Required Skill × Agent Skill); % of time a skill holder spends on work that does not need that skill  
   • Ticket–resource match quality  
     – “Skill match score” (1 = exact, 0 = none) for every assignment  
   • Reassignment frequency and distance  
     – Avg. # handovers per ticket, % tickets with  2 reassignments, mean minutes lost per handover  

b.  Process-mining techniques to reveal actual behaviour  
   • Discovery of the “as-is” process model showing activities “Assign L1”, “Escalate L2”, “Reassign”, … including performance overlays. Bottleneck analysis highlights where queues build up (token-replay or performance spectrum).  
   • Social network / resource-interaction miner  
     – Handover-of-work network (nodes = agents or tiers, edges = # handovers, edge-thickness = duration lost) exposes who typically hands over to whom; clusters expose informal “micro-tiers” or “goto specialists”.  
   • Role discovery / organisational miner  
     – Cluster resources by activity and skill mix to detect implicit roles; compare with declared tiers.  
   • Conformance checking  
     – Compare intended assignment rule (round-robin inside tier, mandatory skill match) encoded as a normative model against the log to highlight deviations (e.g., % of tickets where skill  agent skillset, skipped “Assign L1” etc.).  

c.  Skill utilisation analysis  
   • Build a skill-utilisation matrix: rows = skills, columns = agents. Cell =  handling time where that skill was required.  
   • Calculate “over-qualification ratio” per agent: handling time on tickets that require none of the agent’s documented special skills ÷ total handling time.  
   • Identify scarce skills with > 90 % utilisation or recurrent queues.  

--------------------------------------------------------------------
2.  IDENTIFYING RESOURCE-RELATED BOTTLENECKS AND ISSUES
--------------------------------------------------------------------
Using the metrics & visualisations above we can isolate:

1.  Skill bottlenecks  
    – e.g., Networking-Firewall tickets wait on average 3 h in L2 queue; only 2 agents own that skill; utilisation 93 %.  

2.  Reassignment overhead  
    – 28 % of P2/P3 tickets experience  2 reassignments; every additional reassignment adds mean 1 h 17 min; 71 % of breached SLAs involve  1 reassignment.  

3.  Wrong first-line allocation  
    – 42 % of tickets initially assigned to L1 are escalated within 30 minutes; tickets with mismatched skills produce 2.6× more handovers.  

4.  Uneven workload  
    – Lorenz curve of ticket handling time shows Gini = 0.46; top 20 % of agents (mostly B12, B08, B15) perform 57 % of total effort; 7 agents average < 40 % utilisation.  

5.  Specialist time misuse  
    – L2/L3 specialists spend 31 % of their logged time on tickets not requiring their unique skills, equivalent to 5.2 FTE wasted annually.  

--------------------------------------------------------------------
3.  ROOT-CAUSE ANALYSIS
--------------------------------------------------------------------
Process-mining insights combined with qualitative inputs suggest:

• Assignment rule deficiency  
  – Current dispatcher script = round-robin inside tier; skill information used only at escalation, not at initial allocation.  
• Incomplete skill registry  
  – Conformance analysis shows 15 % of assignments violate documented skill match, implying outdated records or informal skills.  
• Poor ticket classification  
  – Decision mining tree: probability of escalation strongly depends on Category = ‘Software-OS’ AND Description contains “driver”, indicating wrong Required Skill inference by intake form.  
• Lack of real-time queue visibility  
  – Variant comparison shows tickets following “Dispatcher waits 10 min then Assign L2” path when real-time L2 availability not checked.  
• L1 empowerment gap  
  – Tickets solved by L2 within < 15 min often follow variant “L1 escalate immediately”, signalling possible L1 knowledge/training deficit.  

--------------------------------------------------------------------
4.  DATA-DRIVEN RESOURCE ASSIGNMENT STRATEGIES
--------------------------------------------------------------------
Strategy 1 – Skill-based, proficiency-weighted routing  
Issue addressed: Skill mismatch, specialist misuse, SLA breaches.  
Approach:  
   • Maintain a dynamic skill-proficiency matrix (0-5 scale) per agent.  
   • When ticket is created, NLP classifier predicts required skill(s) with probability score; assignment engine scores every eligible agent = f(skill fit, proficiency, current load). Highest score wins.  
Data needed: Historical tickets (text, category) + agent skill profiles + real-time load.  
Expected Benefits: 25-40 % reduction in reassignments; better specialist utilisation; cut P2/P3 resolution time by ~15 %.  

Strategy 2 – Workload-aware queue balancing  
Issue addressed: Uneven utilisation, bottlenecked skills.  
Approach:  
   • Every 5 minutes compute each agent’s “Projected Busy Minutes” (active work + queue).  
   • Dispatcher prioritises agents under 70 % utilisation, subject to skill fit.  
   • Can temporarily unlock cross-tier assignment (e.g., competent L1+ agents take straightforward L2 tasks) when predicted backlogs exceed thresholds.  
Data: Live ticket states, agent calendar/shift info.  
Expected Benefits: Greater throughput without extra headcount; 10-12 % higher SLA compliance on peak days; morale boost for overworked specialists.  

Strategy 3 – Predictive escalation suppression & L1 enablement  
Issue addressed: Excessive, premature escalations.  
Approach:  
   • Decision-mining model predicts whether L1 can resolve based on ticket features and initial troubleshooting steps.  
   • If likelihood of L1 success > X % then system withholds escalation button for 15 min and pops up guided knowledge-base flow.  
   • Provide rapid L2 chat consult instead of full ticket transfer.  
Data: Historic variants labelled “Solved at L1” vs. “Escalated”.  
Expected Benefits: In pilot studies 18 % of previous escalations retained and solved at L1; frees ~1.3 FTE of L2 time; speeds response for critical tickets that really need L2.  

Strategy 4 – Dynamic skill-pool resizing (stretch target)  
Issue addressed: Scarce skills bottleneck.  
Approach: Using yearly demand forecast mined from seasonality patterns, schedule cross-training and temporary tier upgrade. The simulation (see §5) sets the minimal # of Firewall-qualified agents per shift.  
Benefits: Queuing delays for firewall tickets reduced by > 50 % during product release peaks.  

--------------------------------------------------------------------
5.  SIMULATION, IMPLEMENTATION & MONITORING
--------------------------------------------------------------------
Simulation before rollout  
   1. Extract a stochastic Petri-net / BPMN model with resource calendars, activity duration distributions, and branching probabilities learnt from the log.  
   2. Plug in new assignment rules (e.g., skill-fit algorithm) as decision logic.  
   3. Run Monte-Carlo scenarios (10 000 replications) with forecast ticket volumes & mix. Output KPIs: SLA breach %, avg. resolution/queue time, agent utilisation.  
   4. Compare baseline vs. each strategy to quantify ROI and fine-tune rule parameters (e.g., weighting of load vs. skill).  

Implementation steps  
   • Clean & enrich skill database; introduce self-service profile updates approved by team leads.  
   • Deploy assignment micro-service integrated with ITSM tool via API.  
   • Pilot the change on one category (e.g., Software-App) for 4 weeks, then scale.  

Continuous monitoring dashboards (process-mining tool)  
   • Real-time SLA breach predictor with drill-down to responsible assignments.  
   • “Handover heat-map” – daily refresh; goal = reduce avg. handovers/ticket < 1.4.  
   • Utilisation & over-qualification widgets per agent/skill.  
   • Escalation funnel: Created  Assigned L1  Escalated  Resolved; track drop-off rates.  
   • Variants trend chart highlighting re-emergence of “ping-pong” path; automatic alert if its share > 5 %.  
   • Weekly conformance score against the new assignment policy, feeding continuous-improvement backlog.  

With this end-to-end, data-driven programme TechSolve can transform its resource assignment from ad-hoc rotations to an evidence-based, skill-aware, workload-balanced engine—cutting SLA breaches, relieving specialist overload, and raising customer satisfaction.