# Comprehensive Process Mining Analysis for Speedy Parcels: Delivery Operations Optimization

---

## 1. Process Discovery and Conformance Checking

### 1.1 Data Preprocessing and Integration

#### **Data Source Challenges and Integration Strategy**

Integrating multi-source event data requires careful preprocessing to create a unified, reliable event log:

**Challenge 1: Temporal Synchronization**
- **Problem:** GPS trackers, scanner devices, and dispatch systems may operate on different clock systems or have time drift.
- **Solution:** Implement clock synchronization verification as a first preprocessing step. Cross-reference timestamps across systems using the Case ID (Vehicle-Day) to identify and correct systematic time offsets. Flag records with timestamp inconsistencies (e.g., "Arrive Customer" before "Depart Depot").

**Challenge 2: Event Granularity and Source-Specific Terminology**
- **Problem:** Different sources use different event naming conventions. GPS events ("Moving," "Idle") differ from scanner events ("Delivery Success," "Depart Customer").
- **Solution:** Create a standardized event taxonomy mapping:
  - GPS "Ignition On" + "Moving"  "Depart Location"
  - Scanner "Arrive Customer"  "Service Start"
  - GPS "Speed = 0" + duration > 2 min  "Stop/Dwell"
  - Maintenance logs "Start Repair"  "Maintenance Activity"

**Challenge 3: Event Completeness and Missing Data**
- **Problem:** GPS coordinates might be missing for depot locations; scanner events may not fire if device battery dies or signal is lost.
- **Solution:**
  - Impute missing GPS coordinates using last-known location for short gaps (< 5 minutes).
  - Flag incomplete delivery cycles (missing "Depart Customer" after "Delivery Success") as data quality issues; analyze their frequency and impact.
  - Implement logic to reconstruct inferred events: if "Arrive Customer" is recorded but no "Depart," infer departure time from next vehicle movement.

**Challenge 4: Multi-Level Event Hierarchy**
- **Problem:** Events relate to different entities (vehicles, drivers, packages, locations) with varying cardinality.
- **Solution:** Use a hierarchical event log structure where:
  - Primary case is "Vehicle-Day" (V12-20241205)
  - Sub-cases are delivery stops (identified by package or customer location)
  - Events have attributes linking to all relevant entities (Vehicle ID, Driver ID, Package ID, Location)

**Challenge 5: Outlier Detection and Data Quality**
- **Problem:** GPS noise, sensor failures, or manual entry errors create implausible events (e.g., speed > vehicle max, impossible coordinates).
- **Solution:** Apply statistical filtering:
  - Remove GPS points with implausible speed changes (acceleration > vehicle capability).
  - Cross-validate GPS location changes with dispatch system knowledge (is the vehicle traveling to a known customer location?).
  - Flag and analyze anomalies (unscheduled stops, extreme dwell times) separately.

#### **Integrated Event Log Structure**

After preprocessing, structure the unified event log with:

```
Case_ID | Timestamp | Activity | Resource_Type | Resource_ID | Package_ID | 
Customer_Location | Planned_Location | Time_Window | Travel_Distance | 
Dwell_Time | Service_Time | Status | Deviation_Flag | Data_Quality_Score
```

**Data Quality Scoring:**
Assign each event a confidence score (0-1) based on:
- Source reliability (GPS accuracy ±5m typically high; manual scanner entries medium; inferred events lower)
- Temporal consistency
- Logical consistency (does event sequence make operational sense?)

This allows filtering low-confidence events in analysis or weighting them lower in discovery algorithms.

---

### 1.2 Process Discovery: Visualizing the Actual Delivery Process

#### **Discovery Algorithm Selection and Application**

For Speedy Parcels' large, complex event log with significant variability, I recommend a **hybrid discovery approach**:

**Primary Algorithm: Fuzzy Miner or Inductive Miner**

1. **Fuzzy Miner** advantages for logistics:
   - Handles high-frequency, noisy data (GPS traces have thousands of redundant "Moving" events)
   - Uses significance and correlation thresholds to abstract lower-frequency deviations
   - Naturally represents optional activities and loops (re-delivery attempts, unplanned stops)
   - Good for understanding dominant process flows vs. edge cases

2. **Inductive Miner** advantages:
   - Produces acyclic process trees, avoiding "spaghetti" models
   - Cleaner handling of concurrency (multiple packages delivered in one stop)
   - Better for identifying structured sub-processes

**Applied Discovery Process:**

**Step 1: Event Abstraction and Activity Clustering**

Rather than mining on raw GPS events, abstract into meaningful delivery activities:

```
Raw Events                           Abstraction/Activity
GPS: Speed=15 km/h, moving           "En Route"
GPS: Speed=0, dwell > 2 min          "Stop"
Scanner: Arrive Customer             "Service Start"
Scanner: Delivery Success            "Delivery Complete"
Maintenance: Start Repair            "Maintenance Break"
GPS: Idle at Depot > 30 min          "Admin/Break"
```

This reduces event log from millions of GPS pings to thousands of meaningful activities.

**Step 2: Route Segmentation**

Segment each vehicle-day into logical delivery "routes":
- **Route Segment** = Series of delivery stops between two depot returns or maintenance stops
- Each segment has: start time, end time, sequence of stops, total distance, total service time

**Step 3: Process Model Discovery**

Apply Fuzzy Miner with parameters tuned for logistics:
- **Edge Significance Threshold:** 10% (retain only activities occurring in >10% of routes to avoid clutter)
- **Node Significance Threshold:** 5%
- **Correlation coefficient threshold:** 0.5 (moderate correlation between activities)

**Expected Process Model Output:**

```
[Start Shift] 
     {Depart Depot}
         [Loop: En Route  Service Stop  Delivery (Success or Failed)]
         {Unplanned Stop} [conditional—traffic/maintenance]
         [Loop repeats until all planned stops or time window exceeded]
     {Return to Depot}
     [End Shift]

Where:
- {Activity} = always occurs
- [Loop] = iteration structure
- [conditional] = may occur
```

**Step 4: Hierarchical Sub-Process Modeling**

Zoom in on "Service Stop" activity using event data from scanner logs to detail:

```
Service Stop Detail:
[Arrive at Location] 
     {Find Parking / Approach Customer} [variable time]
     {Customer Interaction} [varies by delivery type: signature, payment, re-attempt]
     {Delivery Success | Delivery Failed}
     {Depart Location}
```

This reveals that high variability often concentrates in customer interaction and parking phases.

#### **Visualization Approach**

Use **process mining dashboards** showing:

1. **Sankey Diagram:** Flow of vehicles through activities, with width representing volume. Highlight rare paths (e.g., unplanned maintenance detours) in different color.

2. **Dotted Chart:** X-axis = time of day, Y-axis = individual vehicle-day cases, dots = activities. Reveals whether delays concentrate in peak hours.

3. **Process Map:** Standard flowchart with activity durations (average, 95th percentile) labeled. Thick edges = frequent transitions; thin = occasional.

---

### 1.3 Conformance Checking: Comparing Actual vs. Planned Operations

#### **Conformance Analysis Objectives**

Compare the discovered **actual process** against the **planned process** from dispatch system to identify:
- Sequence deviations (stops visited in wrong order)
- Temporal deviations (late arrivals at stops)
- Structural deviations (unplanned stops, skipped stops)
- Route-level deviations (assignment changed mid-day)

#### **Conformance Checking Methodology**

**Step 1: Create Planned Process Model**

From dispatch system data, construct the "ground truth" planned process for each vehicle-day:

```
Planned Route for V12-20241205:
Depot  Stop1 (P9876, 08:00-08:30)  Stop2 (P9877, 08:45-09:15)  
Stop3 (P9878, 09:30-10:00)  [35 stops total]  Depot (17:00 latest)
```

This becomes the baseline.

**Step 2: Alignment and Trace Matching**

For each actual vehicle-day trace (sequence of events), attempt to align it with the planned route:

```
Alignment Algorithm (Simplified A* Search):
1. Start: Vehicle at Depot
2. For each actual event:
   - If matches next planned stop in sequence  aligned (advance)
   - If matches a future planned stop  sequence deviation (skip intermediate)
   - If no match in planned stops  unplanned stop (anomaly)
3. Track fitness: (# aligned events) / (total planned events)
```

**Conformance Metrics:**

| Metric | Definition | Calculation |
|--------|------------|-------------|
| **Fitness** | Fraction of planned activities executed | Aligned stops / Total planned stops |
| **Precision** | Fraction of actual activities that were planned | Planned stops in actual trace / Total actual stops |
| **Generalization** | Model's ability to capture variation | 1 - (# rare paths / total paths) [higher = more stable] |
| **Simplicity** | Model complexity | Inverse of avg. branching factor per node |

#### **Types of Deviations Investigated**

**Deviation Type 1: Sequence Deviation**

```
Planned:  Depot  Stop1  Stop2  Stop3  Depot
Actual:   Depot  Stop2  Stop1  Stop3  Depot  [Stops reordered]

Impact: Increased travel distance if optimal sequence wasn't followed.
Cause: Late customer availability, traffic re-routing, or dispatch error.
```

**Analysis:** Calculate impact on tour distance by comparing actual route sequence vs. planned. If actual distance >> planned, suggests dispatcher didn't optimize well or dynamic conditions required re-sequencing.

**Deviation Type 2: Temporal Deviation**

```
Planned Arrival at Stop: 08:00
Actual Arrival: 08:45 [45-min delay]

Possible causes: Traffic, parking difficulty, longer service time at previous stop, 
maintenance detour, dispatcher schedule error
```

**Analysis:** 
- Categorize delays into segments: pre-stop travel delay, service delay, post-stop delay
- Use GPS time-distance data to isolate travel vs. service delays
- Compare against baseline (same stop, same time of day, same driver on other days)

**Deviation Type 3: Structural Deviation—Unplanned Stops**

```
Planned Stops: 35
Actual Stops: 33 [2 planned stops skipped]
Also: 2 unplanned stops recorded (maintenance, unrelated location)

Result: Failed delivery rate spike, customer complaints.
```

**Analysis:** 
- Investigate why stops were skipped (capacity issue, customer not ready, address wrong)
- Track consequences (re-delivery attempts, cost impact)

**Deviation Type 4: Structural Deviation—Failed Deliveries**

```
Package P9879 delivery attempt at 09:15  Failed (Customer Not Home)
Retry opportunity: Yes (Same day later) / No (Next-day re-delivery)

Patterns: Does this customer always have failed deliveries? Specific time window issues?
```

**Analysis:** Aggregate failed deliveries and identify patterns (chronic customers, time windows, drivers).

#### **Conformance Dashboard Outputs**

```
Conformance Report (per vehicle-day):

Vehicle ID: V12              Date: 2024-12-05
Planned Stops: 35            Actual Stops Completed: 33    Fitness: 94.3%
Planned Distance: 87.5 km    Actual Distance: 102.3 km     Efficiency: 85.5%
Planned Duration: 9.5 hours  Actual Duration: 10.5 hours   [+1 hour overtime]

Deviations Detected:
1. Sequence Deviation: Stops 5 & 6 reordered (+2.3 km extra travel)
2. Unplanned Stop: Maintenance intervention at 11:05 (-45 min productive time)
3. Failed Deliveries: 1 (Stop 5, P9879 - Customer Not Home)
4. Temporal Deviation: Average 8.2 min late per stop vs. planned window

Data Quality: 92% (some GPS gaps, all scanner events present)
```

This conformance analysis highlights that V12 on 2024-12-05 had significant inefficiencies linked to unplanned maintenance and sequence reordering—prime targets for investigation.

---

## 2. Performance Analysis and Bottleneck Identification

### 2.1 KPI Definition and Calculation from Event Log

Define operational KPIs across three categories: **Delivery Performance, Operational Efficiency, and Asset Utilization.**

#### **Delivery Performance KPIs**

**1. On-Time Delivery Rate (OTDR)**

```
Formula: (# Deliveries completed within customer time window) / (# Total delivery attempts) × 100%

Calculation from Event Log:
For each "Delivery Success" event:
  - Extract Customer_Time_Window from dispatch attributes
  - Compare "Delivery Success" timestamp vs. window end time
  - Count as on-time if timestamp  window end + small buffer (e.g., 5 min grace)

Example from log:
Stop 1: Window 08:00-08:30, Success at 08:28  On-time 
Stop 5: Window 09:00-09:30, Failed at 09:15  Not counted (failed)
```

**Target:** > 95%
**Drivers:** Late stop times, traffic delays, sequencing issues.

**2. First-Time Delivery Success Rate (FTDSR)**

```
Formula: (# Successful deliveries on first attempt) / (# Total delivery attempts) × 100%

Calculation:
For each package, count delivery attempt sequences until success or abandon:
  - One "Delivery Success" only = FTDS 
  - Multiple "Delivery Failed" followed by "Delivery Success" = Not FTDS 
  - Multiple "Delivery Failed" with no success = Failure

Aggregate across fleet.
```

**Target:** > 90%
**Impact:** High failure rates trigger costly re-deliveries, extending delivery cycles and increasing fleet utilization.

**3. Failed Delivery Rate (FDR)**

```
Formula: (# Delivery attempts ending in "Delivery Failed") / (# Total delivery attempts) × 100%

Breakdown by failure reason:
  - Customer Not Home: Extract from scanner "Notes"
  - Access Denied / Security Issue
  - Address Not Found
  - Refused by Customer
  
Segment analysis:
  - FDR by Time of Day: Peak hours vs. off-peak
  - FDR by Route / Geographic Area: Zones with chronic issues
  - FDR by Driver: Performance variance
```

**Target:** < 8%
**Root Causes:** Poor time window estimation, inaccurate customer contact info, unsafe neighborhoods, customer availability issues.

---

#### **Operational Efficiency KPIs**

**4. Average Time per Delivery Stop (ATDS)**

```
Formula: Average(Delivery_Time) where Delivery_Time = "Depart Customer" timestamp - "Arrive Customer" timestamp

Breakdown:
  - Service_Time = "Delivery Success" - "Arrive Customer" (interaction time)
  - Parking_Time = "Arrive Customer" - GPS arrival (finding parking, approach)
  - Administrative_Time = "Depart Customer" - "Delivery Success" (scanning return, etc.)

Example from log:
Stop 1: Arrive 08:25, Delivery Success 08:28, Depart 08:30  ATDS = 5 min
  - Service Time: 3 min
  - Admin Time: 2 min
  - Parking: embedded in "Arrive" event

Analyze variation:
  - Within-stop variance: Different customer types (residential, business)
  - Cross-driver variance: Efficiency differences
  - Temporal variance: Morning vs. afternoon stops
```

**Target:** 5-7 min per stop (including parking, service, admin)
**Insight:** High variance indicates training opportunities or unrealistic time estimates.

**5. Travel Time vs. Service Time Ratio (TSR)**

```
Formula: TSR = Total_Travel_Time / Total_Service_Time

Travel_Time = Sum of time intervals where vehicle moving (GPS speed > threshold)
Service_Time = Sum of ATDS across all stops

Calculation:
For vehicle-day V12-20241205:
  - Depart Depot 07:45, Arrive Depot 16:50  Total Shift: 9h 5min
  - Service Time (33 stops × avg 5 min): ~165 min
  - Admin/Break Time: 30 min (logged in scanner/GPS idle at non-customer location)
  - Travel Time: 545 - 165 - 30 = 350 min (5h 50min)
  - TSR = 350 / 165  2.1

Benchmark: Typical urban last-mile TSR = 1.5–2.5 (varies by density)
```

**Interpretation:**
- TSR = 2.1 suggests driver spends 2.1 hours traveling per hour of service. 
- Urban benchmark is 1.5–2.0, so V12 at 2.1 is slightly inefficient.
- Likely causes: Suboptimal routing, traffic congestion, parking difficulty.

**Target:** < 2.0 for dense urban; < 2.5 for suburban
**Optimization:** Reduce through better route sequencing and traffic prediction.

**6. Fuel Consumption Efficiency (FCE)**

```
Formula: FCE = Total_Fuel_Consumed / Total_Packages_Delivered (liters per package)
         or FCE = Total_Distance_Traveled / Total_Fuel_Consumed (km per liter)

Data Source: GPS distance calculation + Fleet fuel consumption logs (if available)

If direct fuel log unavailable, estimate from:
  - Vehicle type (fuel type, engine size from vehicle master data)
  - Distance traveled (GPS cumulative distance per vehicle-day)
  - Speed profile (aggressive acceleration / braking = higher consumption)
  - Idle time and traffic congestion (increases consumption without distance gain)

Example:
Vehicle V12 (assumed 6.5 L/100km in normal conditions):
  - Actual Distance: 102.3 km
  - Idle + Congestion Penalty: +15% fuel increase
  - Estimated Consumption: 102.3 × (6.5 + 0.975) / 100  7.12 liters
  - Packages Delivered: 33
  - FCE  0.216 liters/package
```

**Target:** 0.15–0.20 liters/package (depends on vehicle, area density)
**Drivers:** Route optimization, traffic patterns, vehicle maintenance condition.

**7. Average Travel Speed (ATS)**

```
Formula: ATS = Total_Travel_Distance / Total_Travel_Time

Example:
V12 traveled 102.3 km in 350 min (5h 50min) of moving time
ATS = 102.3 / (350/60)  17.5 km/h

Segmentation:
  - ATS by Time of Day: Rush hour (08:00-10:00) vs. off-peak (10:00-15:00)
  - ATS by Route / Area: Urban core vs. suburban
  - ATS by Traffic Condition: GPS speed fluctuation analysis

Interpretation: 17.5 km/h is slow for a logistics route (suggests dense urban area with 
frequent stops, parking constraints, and traffic). Compare to route-specific baseline.
```

**Variance Analysis:** High variance indicates traffic sensitivity; low ATS in specific time windows or areas suggests consistent congestion.

---

#### **Asset Utilization & Cost KPIs**

**8. Vehicle Utilization Rate (VUR)**

```
Formula: VUR = (# Packages Delivered) / (Vehicle Capacity) × 100%
         or VUR = (Productive Time) / (Total Available Time) × 100%

Calculation 1 (Capacity-based):
Vehicle V12 capacity: 120 packages
Packages delivered on 2024-12-05: 33
VUR = 33/120 = 27.5%
   Vehicle severely underutilized; capacity waste.

Calculation 2 (Time-based):
Total shift time: 545 min
  - Service time: 165 min
  - Travel time: 350 min
  - Productive time: 515 min
  - Idle/Break: 30 min (included as productive)
VUR (time) = 515/545 = 94.5%
   Time is used, but package capacity is wasted; indicates imbalance.

Interpretation: V12 is busy all day but doesn't deliver many packages. Likely causes:
  - Large, bulky packages taking space
  - Unplanned stops (maintenance) reducing delivery count
  - Inefficient route (long travel, few stops)
```

**Target:** > 85% (time-based); > 70% (capacity-based for cost-effectiveness)
**Optimization Opportunity:** Right-size vehicle fleet or consolidate routes.

**9. Maintenance Event Frequency and Impact (MEF/I)**

```
Formula: MEF = (# Unscheduled maintenance events per vehicle per month)
         Impact_Hours = Sum of downtime hours from unplanned maintenance per vehicle per month

Calculation from maintenance logs:
For V12 over six-month period:
  - Scheduled maintenance (expected): 2 events, avg 0.5 hours each  Planned, budgeted
  - Unscheduled repairs: 8 events, avg 1.2 hours each  Unpredictable, disruptive

MEF_V12 = 8 / 6  1.33 events/month
Impact_V12 = 8 × 1.2 = 9.6 hours/month ( 1.6% of operating hours if V12 works 600 hours/month)

Correlation analysis: 
  - Does V12 have higher MEF than fleet average?
  - Is downtime proportional to vehicle age, mileage?
  - Do specific failure types recur (transmission, engine, tire)?

Example from event log:
2024-12-05: Unplanned Stop at 11:05 due to Engine Warning Light
  - Downtime: 45 minutes
  - Deliveries unfinished: 2 (rescheduled/failed)
  - Immediate cost: 45 min × (hourly cost + fuel + driver overtime) + customer penalty
```

**Target:** < 1 unscheduled event per month per vehicle; impact < 2% of operating hours
**Root Cause Analysis:** Age/mileage data + failure logs reveal predictive maintenance opportunities.

**10. Driver Performance Score (DPS)**

```
Formula: DPS = Weighted aggregate of driver KPIs

Components (example weighting):
  - FTDSR: First-time delivery success rate (30%)  Reduces re-deliveries
  - OTDR: On-time delivery rate (25%)  Customer satisfaction
  - Fuel Efficiency Rank: vs. peers (20%)  Cost efficiency
  - Service Time Efficiency: (15%)  Productivity
  - Safety: (10%)  Incidents, speeding events, harsh braking

Calculation:
Driver D105 scores:
  - FTDSR: 88% (target 90%)  0.88 × 0.30 = 0.264
  - OTDR: 92% (target 95%)  0.92 × 0.25 = 0.230
  - Fuel Efficiency: 85th percentile vs. peers  0.85 × 0.20 = 0.170
  - Service Time: 5.2 min avg (target 5.0)  0.95 × 0.15 = 0.143
  - Safety: 2 harsh braking events detected  0.80 × 0.10 = 0.080

DPS_D105 = 0.887 (on a 0-1 scale)  88.7% overall performance

Comparison: Rank drivers; top 20% vs. bottom 20% performance differential identifies
best practices and training needs.
```

**Target:** > 90% for all drivers; identify bottom quartile for intervention.

---

### 2.2 Bottleneck Identification Techniques

#### **Methodology: Multi-Dimensional Bottleneck Analysis**

**Technique 1: Activity-Level Performance Bottleneck Analysis**

```
For each activity in the process model, calculate:

Activity_Cycle_Time = Median(Duration of activity across all instances)
Activity_Frequency = # times activity occurs in log
Activity_Variance = Std_Dev(Duration) / Mean(Duration)  Coefficient of Variation

Identify bottlenecks by:
  1. High frequency + Long duration  Major time sink (e.g., "Service Stop")
  2. High variance  Unpredictable, suggests underlying variability (e.g., "Find Parking")
  3. Frequency × Duration  Total impact on overall cycle time

Example Bottleneck Analysis:

Activity              | Frequency | Avg Duration | Variance | Total Impact
Service Stop          | 33        | 5.2 min      | 0.65     | 171.6 min (High)
Travel to Stop        | 33        | 10.6 min     | 0.52     | 349.8 min (Very High)
Return to Depot       | 1         | 15 min       | 0.30     | 15 min (Medium)
Unplanned Maintenance | 1         | 45 min       | 1.20     | 45 min (High, unpredictable)
```

**Interpretation:** 
- **Travel time dominates** (349.8 min = 58% of total cycle time). This is the primary bottleneck.
- Service stops show moderate variance (0.65), indicating some customer interaction unpredictability.
- Unplanned maintenance, while rare, has high impact when it occurs (45 min + disruption).

**Action:** Route optimization and traffic prediction (reduce travel) should be primary focus.

---

**Technique 2: Routing & Time-Based Bottleneck Analysis**

Segment the event log by **route characteristics** and **time of day** to isolate where delays concentrate:

```
Bottleneck Dimension 1: By Time of Day

Time Window | Route Count | Avg On-Time Delivery % | Avg Travel Speed | Notes
08:00-10:00 | 15 (morning peak) | 91% | 15.2 km/h | Morning rush hour
10:00-12:00 | 18 (mid-morning) | 94% | 18.3 km/h | Better flow
12:00-14:00 | 12 (lunch) | 93% | 17.5 km/h | Moderate
14:00-16:00 | 16 (afternoon) | 89% | 14.8 km/h | Afternoon congestion
16:00-17:00 | 8 (end-of-day) | 85% | 13.5 km/h | Peak outbound traffic

Bottleneck Identified: Morning (08-10) and afternoon (14-16) peak hours show 
lowest on-time rates and travel speeds.

Root Cause Hypothesis: Traffic congestion during commute windows.

Action: Avoid scheduling time-sensitive deliveries in peak hours, or pre-position 
vehicles to reduce travel distance during congested windows.
```

```
Bottleneck Dimension 2: By Geographic Route / Area

Area            | Routes | Avg Tour Length | Service Stops | Avg On-Time % | Notes
Urban Core      | 12     | 68 km          | 42 stops      | 88%           | Dense, lots of stops
Suburban Ring   | 18     | 95 km          | 28 stops      | 94%           | More travel, fewer stops
Industrial Zone | 8      | 112 km         | 15 stops      | 97%           | Long travel, simple stops

Bottleneck Identified: Urban Core has lowest on-time rate despite fewer km but more stops.

Root Causes (hypothesis):
  - Dense stops = more parking difficulty + navigation challenges
  - Congestion in urban area
  - Variable customer availability in residential area
  - Address ambiguity / missed addresses more common

Action: Specific interventions for urban core (mobile parking apps, dynamic routing, 
customer time window refinement).
```

---

**Technique 3: Variant Analysis—Comparing High vs. Low Performers**

Compare delivery processes of top-performing routes/drivers vs. struggling ones:

```
Case Study: Route V12 (Low Performer) vs. V08 (High Performer)
Both routes on same date, same area, similar size.

Metric                          | V08 (High)  | V12 (Low)   | Difference
Planned Stops                   | 35          | 35          | —
Completed Stops                 | 34 (97%)    | 33 (94%)    | V12 missed 1
On-Time Delivery Rate           | 96%         | 92%         | V12 4% lower
Avg Travel Speed                | 18.5 km/h   | 17.5 km/h   | V12 slower
Avg Service Time per Stop       | 4.8 min     | 5.2 min     | V12 5% slower service
Unplanned Stops                 | 0           | 1 (maintenance) | V12 disrupted
Failed Deliveries               | 1 (3%)      | 1 (3%)      | Same
Total Shift Time                | 9h 15m      | 10h 5m      | V12 50 min longer
Fuel Efficiency (est.)          | 5.95 L/100km| 6.42 L/100km| V12 8% worse

Variant Analysis (Process Comparison):
V08 Route Sequence:  Depot  [Loop: Travel~9min, Service~4.8min] × 34  Depot
V12 Route Sequence:  Depot  [Loop: Travel~10.6min, Service~5.2min] × 33  
                     Unplanned Stop (Maintenance 45min)  Depot

Driver Profile:
V08: Driver D101 (3 years experience, consistent performer)
V12: Driver D105 (1 year experience, variable performance)

Insights:
1. Process Difference: V12's routes have longer travel segments and service times
2. Disruption: V12 suffered unplanned maintenance; V08 did not
3. Efficiency Gap: Travel time 18% longer for V12, suggesting either:
   - V12 assigned harder/less-optimized route, or
   - D105 (driver) navigates less efficiently than D101
4. Service Time: V12 8% slower per stop; could indicate:
   - Less familiarity with area, or
   - Assigned difficult delivery types (businesses requiring paperwork), or
   - Customer interaction issues (language barrier, accessibility challenges)

Root Cause: Likely combination of
  - Suboptimal route assignment (distance/sequencing)
  - Driver experience/skill gap
  - Vehicle reliability issue (maintenance event)

Recommendation:
  1. Analyze route assignment algorithm—is V12's route genuinely harder?
  2. Pair D105 with D101 for training on navigation/efficiency
  3. Implement preventive maintenance for V12 (engine warning light recurred)
  4. Adjust time windows for V12's routes if customer expectations are unrealistic
```

---

**Technique 4: Traffic & Congestion Impact Analysis**

Correlate GPS speed data with external traffic patterns to quantify congestion impact:

```
Traffic Analysis for V12's "Low Speed Detected" event on 2024-12-05 at 08:10:55

GPS Data (raw):
  Timestamp: 08:10:55
  Location: 50.8N, 6.1E (urban intersection area)
  Speed: 5 km/h
  Note: Possible Traffic Jam

Historical Baseline (same location, time of day):
  Other vehicle-days at 08:15 (±15 min window) at this location:
    - V08: 16.2 km/h
    - V15: 14.8 km/h
    - V22: 17.1 km/h
    - Average: 16.0 km/h

V12's speed (5 km/h) vs. baseline (16 km/h)  69% speed reduction

Impact Calculation:
  Assume travel segment between Stop 1 and Stop 2 is 2.5 km:
    - At baseline speed (16 km/h): 2.5 / 16 × 60  9.4 min
    - At actual speed (5 km/h): 2.5 / 5 × 60 = 30 min
    - Delay: 20.6 min

Frequency of Similar Congestion Events:
  Scan entire log for 08:00-10:00 morning peak, urban core area:
    - "Low Speed Detected" events: 47 instances
    - Average duration when speed < 10 km/h: 8.2 min
    - Total congestion impact on morning peak routes: 47 × 8.2  385 min (6.4 hours fleet-wide)

This represents ~15% efficiency loss during morning peak in urban core.

Impact on On-Time Delivery:
  Routes with congestion delays:
    - Without delay: OTD rate 95%
    - With average congestion delay (8.2 min): OTD rate 89%
    - Differece: 6 percentage point impact

Recommendation:
  1. Shift some urban core routes to off-peak windows (10:00-12:00 or 14:00-16:00)
  2. Implement real-time traffic routing to dynamically re-sequence stops during congestion
  3. Build traffic buffer into time window estimates for 08:00-10:00 deliveries
```

---

**Technique 5: Dwell Time and Activity Duration Variability Analysis**

High variance in service times indicates underlying inefficiency:

```
Service Time Variance by Stop Type:

Stop Type (derived from customer attributes) | Avg Service Time | Std Dev | CV (Coeff. Var.)
Residential Single Package                   | 3.2 min         | 0.8    | 0.25 (Low)
Residential Multiple Packages                | 5.1 min         | 1.6    | 0.31 (Moderate)
Business/Office                              | 6.8 min         | 2.4    | 0.35 (High)
Restaurant/Food Service                      | 4.5 min         | 2.1    | 0.47 (High)
Require Signature/Proof                      | 7.2 min         | 3.1    | 0.43 (High)

Analysis:
  - Residential single: Low variance  predictable, efficient
  - Business/Office: High variance  customer delays, paperwork, verification issues
  - Signature required: Highest variance  signature process disruption

Root Causes for Variability:
  1. Business stops: Customer busy, need to locate receiving person, security checks
  2. Signature stops: Manual process, unclear requirements, customer questions
  3. Food/Restaurant: Special handling, time-sensitive goods, specific receiving times

Opportunities to Reduce Variance:
  1. Pre-notification: Text customer 30 min before arrival  customer ready, reduce waiting
  2. Signature digitalization: Replace paper with mobile app  faster, consistent ~2 min
  3. Business outreach: Establish preferred delivery times / contacts  predictability
  4. Training: Drivers trained on quick problem-solving  reduce customer delay time
```

---

**Bottleneck Summary Dashboard:**

```
PRIMARY BOTTLENECK: Travel Time (58% of cycle time)
  - Root Cause: Route design not optimized; traffic congestion in peak hours
  - Impact: Extends shift duration 45+ min/day; increases fuel costs; reduces delivery count
  - Geographic Hotspot: Urban core, 08:00-10:00 and 14:00-16:00 windows
  - Financial Impact: ~€250/vehicle/month in excess costs (fuel, overtime)

SECONDARY BOTTLENECK: Service Time Variability (esp. Business/Signature stops)
  - Root Cause: Unpredictable customer processes; manual signature handling
  - Impact: 2-3 min variance per stop × 35 stops = 70-105 min cumulative impact
  - Affected: 25-30% of stops (business, signature-required)
  - Financial Impact: ~€100/vehicle/month in efficiency loss

TERTIARY BOTTLENECK: Unplanned Maintenance Events
  - Root Cause: Vehicle age/condition; predictive maintenance gaps
  - Impact: 45-90 min disruption per event; cascading delivery failures
  - Frequency: ~1.3 events/vehicle/month (V12 example)
  - Financial Impact: ~€150/vehicle/month (disruption, re-delivery, penalties)

TOTAL QUANTIFIED OPPORTUNITY: ~€500/vehicle/month in efficiency gains
```

---

## 3. Root Cause Analysis for Inefficiencies

Building on the bottleneck identification, this section digs deeper into **why** inefficiencies occur and how process mining can validate underlying causes.

### 3.1 Hypothesized Root Causes and Process Mining Investigation

#### **Root Cause Category 1: Suboptimal Route Planning & Sequencing**

**Hypothesis:**
Dispatch system assigns routes based on static (overnight) optimization without real-time adaptation to traffic or demand changes. Route sequences may not minimize travel distance.

**Process Mining Investigation:**

1. **Travel Distance vs. Optimal Analysis:**

```
For each route, calculate:
  - Actual distance traveled (GPS track sum)
  - Planned distance (from dispatch system if available)
  - Theoretical optimal distance (Traveling Salesman Problem solution for same stops)
  
If GPS-based map software unavailable, estimate theoretical optimal by:
  - Calculating straight-line distances between consecutive stops
  - Applying urban routing multiplier (1.3-1.5x) for actual street distance
  - Using Christofides approximation: Optimal TSP  Actual distance  1.5 × Optimal

Example:
Route V12-20241205:
  - Actual distance traveled: 102.3 km (from GPS)
  - Planned distance from dispatch: 87.5 km [Discrepancy: +14.8 km, +17%]
  - Estimated optimal (rough): 82 km
  - Efficiency gap: (102.3 - 82) / 82 = 24.8% above optimal
  
Breakdown of excess distance:
  - Route sequence suboptimality: 8.2 km (stops not visited in optimal order)
  - Traffic-forced re-routing: 3.1 km (driver took alternate routes due to congestion)
  - Parking/navigation: 3.5 km (circling, false starts)
  - Unaccounted deviations: 1.9 km
  
Insight: Route sequence is largest single factor (8.2 km). Dispatch system could improve.
```

**2. Compare Static vs. Dynamic Route Segments:**

```
Analyze routes deployed in dynamic vs. static conditions:

Morning (08:00-10:00): Traffic unknown at dispatch time, route planned statically
  - Deviation from planned route: 15.2% (sequence changed mid-route)
  - Unplanned stops: 12% of routes
  - OTD rate: 91%

Afternoon (14:00-16:00): Real-time traffic data available (drivers have GPS nav)
  - Deviation from planned route: 8.3% (sequence adjusted dynamically)
  - Unplanned stops: 6% of routes
  - OTD rate: 89% (lower despite better routing  likely caused by other factors)
  
Interpretation: When drivers/system adapt dynamically, route sequences improve (7% reduction 
in deviation) but OTD doesn't follow. Suggests dynamic re-routing is happening *after* 
delays occur (reactive) rather than preventing them (proactive).

Root Cause: Lack of predictive traffic model at dispatch time. Static routes assumed 
average traffic, but morning peak is consistently congested.
```

**3. Pattern Analysis: High-Variability Routes:**

```
Identify routes with highest sequence deviation:

Routes with >20% sequence deviation:
  - Urban core routes (density: 40+ stops in small area)
  - Rush hour deployment (08:00-10:00, 14:00-16:00 windows)
  - Routes crossing major congestion corridors
  - Routes assigned to less experienced drivers (implies sub-optimal sequence execution)

Correlation matrix (Spearman rank):
  - Sequence deviation  Urban density: +0.72 (strong correlation)
  - Sequence deviation  Rush hour: +0.68
  - Sequence deviation  Driver experience: -0.55 (experienced drivers deviate less)

Interpretation: Urban density is the primary driver of sequence deviation, not routing 
algorithm per se. Dispatcher may use simplified heuristics for complex urban problems.

Recommendation:
  1. Invest in advanced routing optimization (e.g., Vroom, OSRM) for urban dense areas
  2. Use traffic prediction models (Google Maps API, historical patterns) at dispatch time
  3. Train dispatch team on complex route optimization techniques
```

**Impact Quantification:**
- 8.2 km excess distance per urban route × 15 urban routes/day × 250 working days/year = 30,750 km/year excess
- At 6.5 L/100km: ~2,000 liters excess fuel/year = ~€2,400 excess fuel cost
- Plus 45+ min vehicle time per day × fleet = significant opportunity

---

#### **Root Cause Category 2: Inaccurate Travel Time Estimation**

**Hypothesis:**
Dispatch system's time estimates for travel between stops are too optimistic, not accounting for:
- Parking time (searching for legal parking in dense areas)
- Navigation/finding address
- Traffic congestion patterns

**Process Mining Investigation:**

```
1. Analyze Travel Time Prediction Error:

For each segment (stop i  stop i+1):
  - Extract GPS travel start time (last position at stop i, speed > 0)
  - Extract GPS travel end time (first position at stop i+1, speed  0)
  - Calculate actual travel time (including parking, navigation)
  - Compare to planned travel time (if dispatch system has estimates)
  
Example:
Segment: Stop 1 (50.81N, 6.12E)  Stop 2 (50.82N, 6.14E)
  - Distance (GPS): 2.8 km
  - Straight-line distance: 2.3 km
  - Dispatch planned time: 12 min (assuming 11.5 km/h average urban speed)
  - Actual time:
    * Departure from Stop 1: 08:30:05
    * Arrival at Stop 2: 08:45:10
    * Actual travel time: 15 min 5 sec
    * Error: +3 min (+25% over estimate)

2. Aggregate Analysis: Travel Time Prediction Error by Segment Characteristics:

Segment Type           | Avg Planned Time | Avg Actual Time | Error    | % Error
Urban, 1-3 km         | 11 min          | 14.2 min        | +3.2 min | +29%
Urban, 3-5 km         | 18 min          | 22.1 min        | +4.1 min | +23%
Suburban, 5-10 km     | 28 min          | 29.5 min        | +1.5 min | +5%
Suburban, 10+ km      | 35 min          | 35.8 min        | +0.8 min | +2%

Insight: Urban short-distance segments have huge prediction errors (+20-30%), while 
suburban longer segments are quite accurate (+2-5%).

Root Cause: Dispatch time estimates use simplified formula (distance / average speed) 
without factoring in:
  - Parking search time (urban adds 3-5 min per stop)
  - Navigation/address finding (urban adds 1-2 min)
  - Dense stop-cluster effects (stopping frequently reduces effective average speed)

3. Parking Time Explicit Analysis:

Parking time = Time from arrival at location to "Deliver" event start
For urban stops: Extract GPS location data to infer parking activity

Example stop analysis:
  - GPS shows arrival at 08:25 near address (50.81N, 6.12E)
  - GPS movement stops (speed  0)
  - Next event: "Arrive Customer" at scanner: 08:25:10
  - "Delivery Success" at 08:28:30
  - Gap between GPS arrival and scanner "Arrive": 10 seconds (minimal)
  - But GPS shows circling/movement before settling:
    * 08:23: First approach to neighborhood (2.5 km away)
    * 08:24:30: Circling around block
    * 08:25:00: Stops moving (finally found spot)
    * Implied parking search: ~2 min

Aggregate parking time analysis (urban areas):
  - Stops with immediate parking (found on first pass): 35%  avg 0.5 min search
  - Stops requiring circling (1-2 passes): 50%  avg 2.1 min search
  - Stops with prolonged search (3+ passes or use of alternate parking): 15%  avg 4.5 min search
  - Average parking time: 0.35×0.5 + 0.50×2.1 + 0.15×4.5 = 2.0 min per urban stop

Note: Many logistics time estimates use 3-5 min for urban stops already, but if planning 
assumes 12 min per segment includes only 1 min parking, vs. reality of 2 min parking 
+ 1 min navigation = shortfall.
```

**Impact on Service:**

```
If dispatch time window for "Service from 08:00-09:00" assumes:
  - 12 min travel to stop + 3 min service + 12 min travel to next = 27 min
  - Can fit 2 stops per hour, 4 stops per 2-hour window
  
But reality:
  - 15 min travel (incl. parking) + 5.2 min service + 15 min travel = 35.2 min
  - Can fit only 1.7 stops per hour, ~3 stops per 2-hour window
  
Result: Driver attempts to meet schedule by rushing (reducing service quality or making 
mistakes), leading to failed deliveries, or by working overtime.

On-Time Delivery impact:
  - Window planned for 09:00 arrival
  - Actual arrival: 09:03 (3 min late due to travel underestimate)
  - Cumulative effect: multiple stops × 2-3 min each = 20+ min cumulative lateness by mid-afternoon
```

**Recommendation:**
1. Audit dispatch system's travel time estimates; rebuild using actual historical data
2. Use machine learning to predict travel time including traffic, parking variability
3. Add 15-20% buffer to urban short-distance segments in planning
4. Implement real-time travel time updates to dispatch system

---

#### **Root Cause Category 3: Failed Delivery Root Causes & Re-delivery Cascades**

**Hypothesis:**
High failed delivery rate (8% in data) indicates time window accuracy issues, customer contact failures, or systemic problems at certain locations.

**Process Mining Investigation:**

```
1. Failure Mode Breakdown:

From failed delivery logs (scanner notes):

Failure Reason           | Frequency | % of Failed | Example Impact
Customer Not Home        | 62%       | 62%         | Re-delivery next day (~€15 cost)
Access Denied/Security   | 18%       | 18%         | Failed; customer retrieves from depot
Address Not Found        | 12%       | 12%         | Driver navigated to wrong building
Refused by Customer      | 5%        | 5%          | Customer rejected after seeing delivery
Incorrect Contact Info   | 3%        | 3%          | Can't reach customer to confirm

Insight: "Customer Not Home" dominates. This suggests either:
  - Time window is not matching customer availability
  - Inadequate pre-notification to customer
  - Customer intentionally not home (dissatisfaction signal)

2. Detailed Analysis: "Customer Not Home" Failure Mode

Segment failures by time of day and customer type:

Time Window | Customer Type | Failure Rate | Notes
08:00-10:00 | Residential   | 14%          | Many customers at work
10:00-12:00 | Residential   | 9%           | Some home
12:00-14:00 | Residential   | 5%           | Lunch time, higher availability
14:00-16:00 | Residential   | 8%           | School pickup, errands
16:00-17:00 | Residential   | 4%           | Evening, home preparation

Insight: Residential customers have highly variable availability. 08:00-10:00 window 
has 14% failure rate—potentially because 60-70% of residential customers work during 
these hours.

Correlation with customer attributes (from dispatch data):
  - Full-time employment status (if available): Employed customers 12% failure; 
    Unemployed/Retired 3% failure
  - Previous failed deliveries: Customers with history of failures 22% re-fail rate 
    (vs. 6% for first-attempt customers)

Root Cause: 
  1. Time windows not matched to customer availability patterns
  2. Customers with previous bad experiences don't prepare for re-delivery
  3. Pre-notification system (if exists) not effective

3. Failed Delivery Cascade Analysis:

When a delivery fails, what happens?

Failed Delivery P9879 at Stop 5 on 2024-12-05 (example):
  - Initial attempt: 09:15, Customer Not Home
  - Scanner flag: "Try next day"
  - Dispatch system: Schedules re-delivery for 2024-12-06
  - Re-delivery date: Package appears on new route (V08) on 2024-12-06
  - 2024-12-06 Re-attempt: 10:30, Success

Cascade impact:
  - Original delivery cost: ~€2.00 (driver time, fuel)
  - Re-delivery cost: ~€2.00
  - Total cost per failed delivery: ~€4.00
  - For 8% failure rate on ~200 packages/day: 16 failed × €4 = €64/day × 250 days = €16,000/year

Analysis of re-delivery success:
  - 1st attempt success (on-time window): 92%
  - Re-delivery success (next day, less constraint): 97%
  - Suggests: If time window is more flexible or customer availability better understood, 
    initial success rate could be higher.

Segment chronic failure customers:
  - Address not found failures: Always at same location? 
     Possible data issue (wrong address in system)
  - Refused after seeing delivery: Specific customer type or product?
     Possible buyer's remorse or wrong product delivered

Example:
Address "123 Main Street" shows 8 failed deliveries (address not found) over 6 months, 
all at same location. Investigation: Address building number changed; dispatch system 
has old number. Solution: Update address database.

4. Pre-notification Effectiveness Analysis:

If dispatch system has pre-notification capability (SMS/email to customer):

Routes with pre-notification: Failed delivery rate 5.2%
Routes without pre-notification: Failed delivery rate 10.1%

Effectiveness: Pre-notification reduces failure by ~4.9 percentage points (almost 50% reduction).

However, cost-benefit:
  - SMS cost: €0.05-0.10 per message
  - Fleet size: 80 vehicles × 30 stops/day × 250 days = 600,000 deliveries/year
  - Cost of universal pre-notification: 600,000 × €0.075 = €45,000/year
  - Savings from reduced failed deliveries: 600,000 × 5% reduction × €4 per failed = €120,000/year
  - Net benefit: €75,000/year

Recommendation:
  1. Implement universal SMS pre-notification 30 min before driver arrival
  2. Segment customers by availability (work/home status)  tailor time windows
  3. Audit address database; correct chronic failure addresses
  4. Introduce evening/weekend delivery windows for employed customers (opt-in)
  5. Implement customer feedback system: Ask failed deliveries why (system or customer issue?)
```

---

#### **Root Cause Category 4: Traffic Congestion & Temporal Variability**

**Hypothesis:**
Delivery performance is sensitive to traffic patterns and time-of-day effects, but dispatch system treats all times equally.

**Process Mining Investigation:**

```
1. Traffic-Delay Correlation Analysis:

Combine GPS speed data with external traffic indices (if available, e.g., Google traffic API 
historical data, or derived from fleet GPS patterns):

Time Period         | Avg GPS Speed | Std Dev Speed | Low-Speed Events (< 10 km/h) | OTD Rate
08:00-09:00 (peak)  | 14.8 km/h     | 6.2 km/h      | 47 per 100 routes (47%)      | 89%
09:00-10:00         | 15.5 km/h     | 5.8 km/h      | 41 per 100 routes (41%)      | 91%
10:00-11:00         | 17.2 km/h     | 4.5 km/h      | 18 per 100 routes (18%)      | 96%
11:00-12:00         | 16.8 km/h     | 4.2 km/h      | 16 per 100 routes (16%)      | 97%
12:00-13:00         | 17.5 km/h     | 4.1 km/h      | 14 per 100 routes (14%)      | 95%
13:00-14:00         | 17.1 km/h     | 4.3 km/h      | 17 per 100 routes (17%)      | 94%
14:00-15:00         | 14.5 km/h     | 6.8 km/h      | 45 per 100 routes (45%)      | 90%
15:00-16:00         | 14.9 km/h     | 6.5 km/h      | 43 per 100 routes (43%)      | 88%
16:00-17:00         | 15.2 km/h     | 5.9 km/h      | 39 per 100 routes (39%)      | 87%
17:00-18:00         | 16.1 km/h     | 5.2 km/h      | 24 per 100 routes (24%)      | 93%

Key Insights:
  - Speed variability (std dev) highest in morning (8-9 am) and afternoon (2-3 pm) peaks
  - Low-speed events peak at 08:00-09:00 (47%) and 14:00-15:00 (45%)
  - OTD inversely correlated with congestion: 89% (rush) vs. 97% (off-peak) = 8% swing

2. Geographic Traffic Hotspot Analysis:

Identify locations/routes with consistent congestion:

Congestion Corridor: Main City Boulevard (North-South artery)
  - Routes crossing this corridor during 08:00-10:00: Speed drops from 18 km/h (off-peak) 
    to 12 km/h (on-peak)
  - Impact on routes: 60% of morning routes cross this corridor
  - Time loss per route: ~8 minutes per crossing
  - Total fleet impact: 60% × (# routes) × 8 min = significant daily loss

Alternative routes exist but bypass this corridor?
  - Bypass route: +2.5 km distance but 15% faster during peak
  - Trade-off: Additional distance burn more fuel than time savings save
  - However: Improved OTD rate (on-time advantage worth it for customer satisfaction)

Recommendation: Pre-route vehicles around bottleneck corridor during 08:00-10:00 peak, 
even at cost of slight distance increase, to improve OTD.

3. Day-of-Week Variation:

Aggregate KPIs by day of week:

Day        | Avg OTD Rate | Failed Deliveries | Traffic Delays | Notes
Monday     | 92%          | 7.2%              | High           | Post-weekend catch-up?
Tuesday    | 94%          | 6.1%              | Moderate       | Stable
Wednesday  | 95%          | 5.8%              | Moderate       | Best day
Thursday   | 93%          | 6.9%              | Moderate       | Slight degradation
Friday     | 89%          | 8.2%              | Very High       | Pre-weekend rush traffic
Saturday   | 96%          | 4.1%              | Low            | Weekend light traffic
Sunday     | 94%          | 5.3%              | Very Low        | Minimal traffic

Pattern: Friday = worst performer (89% OTD). Root cause: Pre-weekend traffic surge.

Opportunity: Marketing angle—"Saturday delivery guaranteed" (leverage weekend advantage).
Operational: Potentially overload Friday routes; redistribute to Saturday if possible.
```

**Impact Quantification:**
- Congestion costs: ~€0.15/vehicle/minute of delay × 8 min average peak delay × 60 vehicles × 250 working days = ~€18,000/year
- OTD impact: 6-8% swing during peak vs. off-peak  significant customer satisfaction variance

---

#### **Root Cause Category 5: Vehicle Maintenance & Reliability Issues**

**Hypothesis:**
Unplanned maintenance events disrupt routes and increase operational costs; lack of predictive maintenance enables breakdowns.

**Process Mining Investigation:**

```
1. Maintenance Event Pattern Analysis:

From maintenance logs and GPS "Unscheduled Stop" events:

Vehicle | Age (years) | Mileage (km) | Scheduled Maintenance/Month | Unscheduled Events/Month | Mean Time to Repair (hours)
V01     | 1.2        | 42,000      | 1.0                        | 0.1                     | 0.4
V08     | 2.3        | 78,000      | 1.2                        | 0.3                     | 0.6
V12     | 3.8        | 128,000     | 1.5                        | 1.8                     | 1.2
V15     | 4.5        | 152,000     | 1.8                        | 2.1                     | 1.5
V22     | 5.2        | 168,000     | 2.0                        | 2.8                     | 1.8

Correlation Analysis:
  - Unscheduled events  Vehicle age: r = 0.91 (strong positive correlation)
  - Unscheduled events  Mileage: r = 0.88
  - Mean repair time  Vehicle age: r = 0.87

Interpretation: Vehicles > 3.5 years old experience ~1.5 unscheduled events/month, 
whereas newer fleet (< 2 years) < 0.3 events/month.

Implication: Fleet has aging problem; vehicles should be replaced or put on 
intensive maintenance schedule.

2. Failure Type and Seasonality:

From maintenance logs, categorize failure types:

Failure Type       | Frequency | Seasonal Pattern | Cost per Incident | Preventable?
Engine-related     | 45%       | Summer-peak      | €250-500          | Yes (maintenance)
Transmission       | 18%       | Year-round       | €500-1200         | Partial
Tire/Brake         | 22%       | Winter-peak      | €150-300          | Yes (inspection)
Electrical         | 12%       | No pattern       | €100-400          | Partial
Other              | 3%        | Variable         | €200-600          | Varies

Insights:
  - Engine failures peak in summer (high load, heat stress); preventable with coolant 
    checks and airfilter maintenance
  - Tire/brake failures peak in winter (moisture, salt, thermal stress); preventable 
    with seasonal inspection
  - Transmission failures are year-round and less preventable without early warning indicators

3. Predictive Maintenance Opportunity:

Cross-reference failure dates with vehicle telemetry data (if available) leading up to failure:

Example: Vehicle V12, Failure Date 2024-12-05, 11:05 (Engine Warning Light)

Days prior to failure:
  - 2024-12-03: Engine speed variance increased 8% vs. normal baseline
  - 2024-12-04: Fuel consumption efficiency dropped 12% (engine working harder)
  - 2024-12-04 PM: Driver reported vibration, but didn't flag formally
  - 2024-12-05 early: GPS data shows hesitation/jerking motion at traffic light
  - 2024-12-05 11:05: Warning light illuminated (confirmed failure)

Pattern: Warning signs appeared 1-2 days before failure.

Predictive Model Opportunity:
Build a machine learning model using:
  - Inputs: Engine speed variance, fuel efficiency trend, acceleration jerk patterns, 
    vehicle age, maintenance history
  - Output: Risk of failure (0-1 probability)
  
If V12's model predicted 0.85 probability of engine failure on 2024-12-04, dispatcher 
could have:
  - Reduced load on V12's route
  - Scheduled maintenance before peak delivery day
  - Prevented 45-min disruption and re-delivery cost

4. Maintenance Cost-Benefit Analysis:

Current scenario (reactive maintenance):
  - Unscheduled event frequency: 1.8/month (old fleet average)
  - Cost per event: €0.5k (replacement vehicle, re-delivery, loss of productivity)
  - Monthly cost (old fleet vehicles): €900/vehicle
  - Annual cost (old fleet): 20 vehicles × €900 × 12 = €216,000

Proposed scenario (predictive maintenance):
  - Additional scheduled maintenance: 2 events/month  €200-300 cost (regular service)
  - Unscheduled event frequency reduced to 0.3/month
  - Cost per event: Same, but fewer incidents
  - Monthly cost: (2 × €250) + (0.3 × €500) = €650/vehicle
  - Annual cost: 20 × €650 × 12 = €156,000

Savings: €216,000 - €156,000 = €60,000/year (28% cost reduction)

Recommendation:
  1. Implement fleet telemetry system to track health indicators (engine vibration, 
     fuel efficiency, electrical voltage)
  2. Build predictive model for failure risk (or use vendor-provided diagnostic)
  3. Trigger maintenance alerts when risk exceeds threshold (e.g., 0.70 probability)
  4. Shift old fleet to intensive maintenance schedule or accelerate replacement schedule
```

---

#### **Root Cause Category 6: Driver Performance & Skill Variance**

**Hypothesis:**
Driver performance varies significantly; some drivers are more efficient and have better on-time rates.

**Process Mining Investigation:**

```
1. Driver Performance Stratification:

Rank drivers by composite KPI (example weighting: FTDSR 30%, OTDR 25%, Fuel Efficiency 20%, 
Service Time 15%, Safety 10%):

Driver  | Experience | DPS Score | FTDSR | OTDR | Avg Service Time | Incidents
D101    | 3 years    | 0.94      | 94%   | 96%  | 4.8 min         | 1 (safe)
D105    | 1 year     | 0.85      | 87%   | 92%  | 5.4 min         | 3 (speeding alerts)
D110    | 5 years    | 0.91      | 92%   | 94%  | 4.9 min         | 2 (harsh braking)
D115    | 0.5 year   | 0.78      | 79%   | 88%  | 5.8 min         | 5 (multiple)
D120    | 2 years    | 0.88      | 89%   | 93%  | 5.1 min         | 2 (normal)

Performance Distribution:
  - Top quartile (DPS > 0.90): 4 drivers, avg OTDR 95%
  - Mid-high quartile (0.85-0.90): 6 drivers, avg OTDR 92%
  - Mid-low quartile (0.80-0.85): 5 drivers, avg OTDR 89%
  - Low quartile (< 0.80): 3 drivers, avg OTDR 85%

Variance: Top-to-bottom OTDR swing = 10 percentage points (95% vs. 85%).
With ~150 deliveries/driver/month, difference = 15 extra successful deliveries/month 
for top drivers. Over fleet, this is ~900 additional successful deliveries/month.

2. Route Assignment Bias Analysis:

Do dispatch systems systematically assign easier/harder routes to certain drivers?

Driver | Avg Route Stops | Avg Route Distance | Avg Route Complexity (*)  | Assigned Vehicle Age
D101   | 32              | 85 km              | 3.2 (Moderate-High)       | 1.8 years (new)
D105   | 31              | 93 km              | 3.0 (Moderate-High)       | 3.2 years (old)
D115   | 29              | 88 km              | 3.5 (Complex Urban)        | 4.1 years (very old)

(*) Complexity score: Combination of area density, address difficulty, customer type

Finding: Newer drivers (D105, D115) are assigned to older vehicles and complex routes.
This confounds driver performance with vehicle/route difficulty.

To isolate driver skill, analyze same-route performance by different drivers:
  
Route 27 (same route, different drivers on different days):
  - Driver D101: 32 stops, completed in 8h 45m, OTDR 96%, Avg Service: 4.8 min
  - Driver D105: 32 stops, completed in 9h 30m, OTDR 91%, Avg Service: 5.4 min
  - Driver D120: 32 stops, completed in 8h 50m, OTDR 94%, Avg Service: 5.0 min

Isolated driver efficiency:
  - D101: Baseline (100%)
  - D105: 92% of D101 (extra 45 min for same route)
  - D120: 98% of D101 (extra 5 min for same route)

Insight: D101 is genuinely more efficient; D105 is slower on same route.
Possible causes for D105's slower performance:
  - Less familiarity with route (newer hire)
  - Navigation skill (use of GPS vs. memory)
  - Customer interaction style (friendly but slower)
  - Attention to safe driving (fewer incidents, but takes more time)

3. Best Practice Analysis: What do Top Performers Do Differently?

Compare D101 (top performer) activity sequences with D105 (bottom performer):

D101 Approach (observed from events):
  - Route planning: Reviews route map before shift (implied by quick turnarounds)
  - Navigation: Familiar with area, takes direct routes
  - Stop sequencing: Executes planned sequence (sequence deviation 2%)
  - Service interaction: Efficient delivery (avg 4.8 min = rapid but complete)
  - Parking: Finds spot quickly (few re-circles observed in GPS)
  - Problem-solving: Rare unplanned stops or diversions

D105 Approach:
  - Route planning: Less organized (implied by late starts, GPS searching)
  - Navigation: Relies on turn-by-turn GPS (more overhead)
  - Stop sequencing: Deviates from plan (sequence deviation 14%)
  - Service interaction: Longer conversations (5.4 min avg; possibly more thorough or friendly)
  - Parking: GPS shows more circling, searching
  - Problem-solving: More unplanned stops, calls to dispatch for guidance

Training Opportunity:
  - D101 practices memorization/spatial planning  Teach to D105
  - D101 minimizes interaction time  Possible training for D105 (without sacrificing service)
  - D101 parking strategy  Share tips with D105
  - D105 has more "incidents" (speeding alerts)  Safety training needed

Recommendation:
  1. Pair new drivers (D105, D115) with top performers (D101, D110) for ride-alongs (4-5 days)
  2. Formalize best practices: Route familiarization, parking strategies, efficient service protocols
  3. Implement driver-specific KPI dashboards; provide weekly feedback on performance gaps
  4. Incentivize top quartile performance (bonuses for OTDR > 95%, FTDSR > 92%)
  5. Provide coaching for struggling drivers; set 90-day improvement targets or performance plan
```

**Impact:**
- Improving bottom quartile drivers to mid-quartile level: ~0.07 OTDR improvement × ~1,800 deliveries/month = ~125 additional on-time deliveries/month = 7% efficiency gain
- Projected value: 125 × €4 (per successful delivery value, reduced re-delivery cost) = €500/month per driver = €18,000/month fleet-wide if 3 drivers improve

---

## 4. Data-Driven Optimization Strategies

Based on the root cause analysis, I propose three distinct, concrete optimization strategies:

---

### **Strategy 1: Dynamic Route Optimization with Real-Time Traffic Prediction**

#### **Problem Statement:**
- Travel time accounts for 58% of cycle time and is the primary bottleneck
- Route sequencing suboptimality adds 8.2 km per route (17% excess distance)
- Morning and afternoon peak hours have 47% low-speed events and 89% OTDR (vs. 97% off-peak)
- Static dispatch optimization at night doesn't account for real-time traffic or demand shifts

#### **Proposed Solution:**
Implement a **dynamic routing engine** that:
1. Uses historical traffic patterns + real-time GPS data to predict travel times at dispatch time (06:00 am)
2. Optimizes routes considering predicted traffic, not average traffic
3. Re-optimizes mid-route if conditions deviate significantly (congestion, failed delivery)
4. Integrates with driver GPS devices to provide real-time turn-by-turn guidance optimized for time windows

#### **Implementation Roadmap:**

**Phase 1: Historical Traffic Model (Months 1-2)**
- Aggregate GPS speed data by (location corridor, hour of day, day of week) to build historical traffic profiles
- Example output: "Main Boulevard corridor, 08:00-09:00 weekday: Expected 14.8 km/h speed with 47% probability of <10 km/h segments"
- Validate model against test period data (hold-out test set)

**Phase 2: Predictive Travel Time Estimation (Months 3-4)**
- For each route-segment, calculate predicted travel time = (distance / predicted_speed) + (parking + navigation overhead)
- Parking overhead: 2 min urban, 0.5 min suburban (derived from data)
- Navigation overhead: 1 min dense area, 0.3 min sparse area (derived from data)
- Integrate with third-party API (Google Maps, HERE) for real-time traffic feed

**Phase 3: Route Optimization Integration (Months 5-6)**
- Connect optimization solver (e.g., Vroom, OSRM, or commercial TSP solver) to predictive travel time model
- Objective function: Minimize total time while respecting time windows (hard constraint) and vehicle capacity (hard constraint)
- Constraints:
  - Each stop visited exactly once within time window [t_earliest, t_latest]
  - Vehicle capacity not exceeded
  - Driver shift ends by 17:00
  - Vehicle must return to depot
- Run optimization at 05:30 am each day using predicted traffic; dispatch routes to drivers by 06:30 am

**Phase 4: Real-Time Re-optimization (Months 7-8)**
- Monitor route execution via GPS telemetry
- If actual travel time to next stop deviates >15% from prediction, recalculate remaining stops
- Send re-optimized route sequence to driver's device if sequence change saves >10 min
- Alert driver to unplanned traffic situations (e.g., accident, lane closure)

#### **Expected Outcomes:**

| KPI | Current | Target | Methodology |
|-----|---------|--------|-------------|
| Travel Time (avg route) | 350 min | 310 min (-11%) | Better sequencing + traffic prediction |
| Excess Distance vs. Optimal | 24.8% | 12% | Optimized vs. ad-hoc sequencing |
| Urban Peak OTDR | 89% | 94% | Traffic-aware planning + parking buffer |
| Overall OTDR | 92% | 96% | Cumulative improvement |
| TSR (Travel:Service) | 2.1 | 1.8 | Reduced travel time |
| Fuel Consumption | 6.42 L/100km | 6.05 L/100km (-6%) | Shorter, optimized routes |
| Cost Impact | — | €250/vehicle/month savings | Fuel + time savings |

#### **Data Requirements & Quality:**
- Historical GPS traces (6 months)  Already collected
- Current traffic API (Google Maps or similar)  New subscription (~€500/month)
- Route optimization software  License or custom build (€5,000-10,000 initial)
- Real-time data integration infrastructure  IT effort (~2 weeks)

#### **Risks & Mitigation:**
| Risk | Mitigation |
|------|-----------|
| Driver resistance to dynamic routing | Pilot with top performers first; emphasize workload reduction |
| GPS data quality/accuracy | Validate API predictions against logged data; fallback to historical if poor |
| Edge cases (closed roads, events) | Manual override capability; dispatch team monitoring |
| Optimization solver computational time | Pre-compute using parallelization; aim for <5 min solve time |

---

### **Strategy 2: Targeted Failed Delivery Reduction Program with Time Window Optimization & Pre-notification**

#### **Problem Statement:**
- 8% overall failed delivery rate with "Customer Not Home" = 62% of failures
- Morning peak (08:00-10:00) has 14% failure rate for residential customers (most have full-time jobs)
- Each failed delivery costs €4 in re-delivery; 8% of ~200 packages/day = 16 failures/day × €4 = €64/day = €16,000/year cost
- Pre-notification shows 49% failure reduction but not universally deployed

#### **Proposed Solution:**
Implement a multi-faceted **failed delivery prevention program**:

1. **Customer Availability Profiling:**
   - Segment customers into "Work-Home" profiles (full-time employed, work-from-home, retired)
   - Use customer delivery history, address type (residential vs. business), and optional intake survey
   - Assign suitable time windows (employed: 18:00-20:00 evening; home-based: 10:00-14:00 daytime; flexible: any)

2. **Universal Pre-notification with Flexibility:**
   - Send SMS 30 min before scheduled delivery with ETA window and option to reschedule
   - Offer flexible 2-hour windows (customer chooses within available slots)
   - Cost: €0.075/SMS

3. **Chronic Failure Address Audit:**
   - Identify addresses with >3 failed deliveries in 6 months
   - Investigate & correct in dispatch system (address errors, building access issues)
   - Train drivers on problem locations

4. **Evening & Weekend Service Expansion:**
   - Introduce opt-in evening (17:00-20:00) and Saturday delivery options
   - Pricing premium: +€2 per delivery for premium time slot
   - Targets working professionals with high failure rates

#### **Implementation Roadmap:**

**Phase 1: Customer Segmentation & Profiling (Weeks 1-4)**
- Analyze delivery history for each customer: Which time windows = high success?
- Classify into 3 segments: (A) Employed professionals, (B) Home-based/flexible, (C) Inconvenient
- Deploy optional survey ("When are you typically home?") for new/unclear customers
- Target: Segment 100% of customer base in 4 weeks

**Phase 2: SMS Pre-notification System (Weeks 5-8)**
- Procure SMS gateway API (e.g., Twilio, Amazon SNS)
- Integrate with dispatch system to auto-send SMS 30 min before ETA
- Format: "Your delivery arriving 14:30-14:45. Reply YES to confirm or RESCHEDULE to choose new time"
- Implement response handling (customer replies  system offers 3 alternative slots)
- Test with 25% of fleet (pilot) for 2 weeks; expand if successful

**Phase 3: Evening & Weekend Service Rollout (Weeks 9-14)**
- Survey demand for premium time slots among high-failure customers
- Assess operational feasibility: Shift staffing, vehicle availability
- Launch opt-in program; market to enrolled customers
- Start with 10 evening delivery slots/day (17:00-20:00); scale if demand

**Phase 4: Address Audit & Correction (Weeks 8-12, parallel)**
- Flag addresses with 3 failed deliveries
- Dispatch team to manually investigate (street view, driver notes, customer contact)
- Correct address database or add special handling notes
- Re-test with corrected addresses

#### **Expected Outcomes:**

| Metric | Current | Target | Method |
|--------|---------|--------|--------|
| Failed Delivery Rate | 8.0% | 4.5% | Pre-notification + time window optimization |
| "Customer Not Home" failures | 62% of 8% = 4.96% | <2% | Customer profiling + opt-in evening service |
| Residential Customer (08-10) Failure | 14% | 6% | Shift to 10-14 or evening windows |
| First-Time Delivery Success Rate | 90% | 94% | Fewer repeats due to reduced failures |
| Customer Satisfaction (NPS proxy) | — | +5 points | Flexible scheduling, better communication |
| Cost Impact | — | €36,000/year savings | 8%  4.5% failure rate × €4 per failure × 16/day × 250 days |

#### **Budget & Resource Requirements:**
- SMS gateway: €500/month × 12 = €6,000/year
- Survey & intake system: €2,000 initial + €200/month = €4,400 total
- Evening/weekend staffing premium: ~€15,000/year (if 10 slots/day at +€10/slot labor cost)
- IT integration: 1 developer × 3 weeks = ~€4,500
- **Total cost: ~€25,000 year 1, ~€12,000 ongoing years 2+**
- **ROI: €36,000 savings - €25,000 cost = €11,000 net benefit year 1**

#### **Risks & Mitigation:**
| Risk | Mitigation |
|------|-----------|
| Low SMS engagement rate | A/B test messaging; use concise, benefit-focused copy |
| Evening staffing challenges | Contract local courier partners for evening slots; pilot before expanding |
| Premium pricing adoption | Market to high-failure customers first; offer first month free trial |
| Address audit resource drain | Automate using Google Maps API to verify; manual override only for unclear cases |

---

### **Strategy 3: Predictive Vehicle Maintenance with Fleet Health Monitoring Dashboard**

#### **Problem Statement:**
- Old fleet (age > 3.5 years) experiences 1.8 unscheduled maintenance events/month vs. 0.1 for new fleet
- Unplanned maintenance disrupts routes: 45-90 min downtime per incident × 1.3 incidents/month = ~1 hour/month per old vehicle lost
- Example 2024-12-05: V12 engine warning light at 11:05 disrupted route, cascading failures
- Cost of reactive maintenance: €900/vehicle/month for old fleet; predictive can reduce to €650/month (28% savings)

#### **Proposed Solution:**
Implement a **predictive maintenance system** using vehicle telemetry and machine learning:

1. **Telemetry Data Streams:**
   - OBD-II (On-Board Diagnostics) vehicle diagnostic codes (engine RPM, fuel efficiency, error codes)
   - GPS speed & acceleration profiles (harsh braking, unusual vibrations)
   - Environmental sensors (temperature, battery voltage if available)
   - Maintenance history and fault codes

2. **Predictive Models:**
   - Build ML models for common failures: Engine (45%), Transmission (18%), Tire/Brake (22%)
   - Inputs: Vehicle age, mileage, operational hours, seasonal factors, recent fault codes
   - Output: Failure probability (0-1) for next 7 days
   - Threshold: Alert maintenance team if probability > 0.70

3. **Maintenance Dashboard & Alerts:**
   - Display fleet health with color-coded risk (green=low, yellow=medium, red=high)
   - Predictive alerts: "Vehicle V12 has 0.78 probability of engine failure in next 3 days"
   - Recommended action: Schedule maintenance by [date] or reduce load
   - Historical track record: Show model accuracy over time

#### **Implementation Roadmap:**

**Phase 1: Telemetry Infrastructure (Months 1-2)**
- Retrofit fleet with OBD-II readers (Bluetooth, WiFi enabled) that log to cloud
- Connect to fleet management system (FMS) or build new data pipeline
- Cost: ~€100-150 per vehicle × 80 vehicles = €8,000-12,000 hardware + €50-100/month cloud storage
- Test on 20% of fleet (pilot) to validate data quality

**Phase 2: Historical Data Analysis & Model Building (Months 2-4)**
- Aggregate existing maintenance logs with GPS/OBD data (if available retrospectively)
- Identify failure patterns: Vehicle age/mileage leading up to failures
- Engineer features:
  - Engine speed variance (indicator of misfiring)
  - Fuel efficiency trend (drop suggests engine stress)
  - Acceleration/braking patterns (harsh patterns correlate with wear)
  - Days since last maintenance
  - Seasonal factor (summer heat stress for engines)
- Build ML model (e.g., Random Forest, Gradient Boosting) with 6 months historical data
- Cross-validate on held-out test set; target 75%+ precision (avoid false alarms)

**Phase 3: Pilot Deployment (Months 5-6)**
- Deploy model on pilot 20 vehicles
- Generate daily failure risk scores
- Compare predicted failures vs. actual failures over 4-week pilot period
- Refine model based on pilot results; retrain if needed
- Achieve 70%+ recall (catch 70% of actual failures before they occur)

**Phase 4: Full Fleet Rollout (Months 7-8)**
- Deploy to 100% of fleet
- Integrate alerts into dispatch system and maintenance scheduling
- Establish SOP: When alert triggered (probability > 0.70), dispatcher schedules maintenance within 48 hours
- Build training program for maintenance team on interpreting predictions

#### **Expected Outcomes:**

| Metric | Current | Target | Method |
|--------|---------|--------|--------|
| Unplanned Maintenance Events (old fleet) | 1.8/month | 0.4/month (-78%) | Predictive alerts trigger preventive action |
| Mean Time to Repair | 1.2 hours | 0.6 hours (-50%) | Issues caught early, repairs simpler |
| Maintenance Cost (old fleet) | €900/vehicle/month | €650/vehicle/month | Preventive vs. reactive |
| Unplanned Route Disruptions | 1.3/month/vehicle | 0.3/month/vehicle (-77%) | Fewer breakdowns mid-route |
| Downtime Hours/Month | ~2.5 hours | ~0.7 hours | Planned maintenance avoids delivery hours |
| Fleet Availability | 94% | 97% | More vehicles available for dispatch |
| Cost Impact | — | €60,000/year savings (20 old vehicles × €3,000/year) | Fewer unplanned events |

#### **Budget & Resource Requirements:**
- OBD-II hardware retrofit: €8,000-12,000 one-time
- Cloud infrastructure & storage: €1,000/year
- ML model development (consulting or internal): €15,000-20,000 (3-4 months)
- Maintenance dashboard software: €2,000-5,000 (commercial or custom)
- Training & change management: €2,000
- **Total year 1: €40,000-50,000; Ongoing: €3,000-5,000/year**
- **ROI: €60,000 savings - €45,000 cost = €15,000 net benefit year 1; Break-even within 1 year**

#### **Risks & Mitigation:**
| Risk | Mitigation |
|------|-----------|
| Poor data quality from OBD-II devices | Test devices in pilot; filter erroneous readings; use data validation rules |
| Model false positives (predicted failure that doesn't occur) | Tune threshold to balance precision/recall; use conservative threshold initially; refine over time |
| Maintenance team resistance | Show model track record; frame as workload reduction (fewer emergency calls) |
| Complex vehicle types (different OBD protocols) | Standardize on compatible devices; some vehicles may require vendor-specific adapters |
| Privacy/liability concerns (OBD data) | Implement data governance; use for maintenance only; not for driver evaluation |

---

## 5. Operational Constraints & Continuous Monitoring

### 5.1 Accounting for Operational Constraints

#### **Constraint 1: Driver Working Hours & Labor Laws**

**Regulation:** In most EU jurisdictions (including Germany where urban logistics often operates), drivers cannot work > 10 hours per day with mandatory breaks.

**Current Situation from Data:**
- V12 on 2024-12-05: Shift 07:01-17:05 = 10h 4m (within limits, but tight)
- Overtime logged: Indicates frequent overtime usage

**How Strategies Account for This:**

1. **Dynamic Route Optimization (Strategy 1):**
   - Hard constraint in optimizer: shift_duration  10 hours
   - If route cannot complete within 10 hours, system flags for dispatch review
   - Recommended action: Assign additional vehicle or reduce stop count
   - Prevents over-loading single driver

2. **Failed Delivery Reduction (Strategy 2):**
   - Reduces unproductive time (re-delivery attempts, rework)
   - Allows more stops within 10-hour window
   - Indirect constraint relief: Fewer failures = fewer time-consuming corrective actions

3. **Predictive Maintenance (Strategy 3):**
   - Prevents unscheduled downtime that "steals" time from productive deliveries
   - Example: V12 lost 45 min to maintenance; if predicted and scheduled overnight, 10-hour window available for productive work

**Monitoring for Compliance:**
- Daily report: Driver hours vs. threshold; flag if > 9.5 hours (advance warning)
- Weekly report: Overtime hours and distribution (identify chronic overloaded drivers)
- Alert if single driver > 50 hours/week (indicates understaffing)

#### **Constraint 2: Vehicle Capacity (Package Count & Weight)**

**Typical constraint:** Delivery vans 120-150 package equivalents or 1,500-2,000 kg

**Current Situation from Data:**
- V12 capacity: 120 packages
- Packages delivered 2024-12-05: 33 (27.5% utilization = severely underutilized)
- Likely cause: Large, bulky packages taking disproportionate space

**How Strategies Account for This:**

1. **Dynamic Route Optimization:**
   - Hard constraint: total_weight  vehicle_capacity and total_volume  vehicle_space
   - Optimizer respects package dimensions, not just count
   - If overweight, system either:
     - Assigns larger vehicle, or
     - Splits stops across multiple vehicles
   - Prevents overloading; improves safety and reliability

2. **Failed Delivery Reduction:**
   - Doesn't directly affect capacity constraints
   - However, by reducing failed deliveries, more packages delivered with same capacity

3. **Predictive Maintenance:**
   - Indirectly helps: Prevents breakdowns of overloaded vehicles
   - Well-maintained vehicles safer under load

**Monitoring for Compliance:**
- Per-route capacity check: Alert if 100%+ utilized (impossible; indicates data error or overload)
- Utilization report: If avg utilization < 70%, consider vehicle right-sizing or route consolidation
- Weight distribution: Monitor if heavy packages concentrated on certain routes (unbalanced)

#### **Constraint 3: Customer Time Windows**

**Hard constraint:** Delivery must occur within [t_earliest, t_latest] or customer not satisfied

**Current Situation:**
- OTDR = 92% (8% outside window)
- Impact: Customer dissatisfaction, failed delivery, re-delivery cost

**How Strategies Account for This:**

1. **Dynamic Route Optimization:**
   - Hard constraint: For each stop i, arrival_time[i] must be within [time_window_earliest[i], time_window_latest[i]]
   - Optimizer ensures feasible solution respects all time windows
   - If infeasible (no valid sequence), system alerts (need to reduce stops or widen windows)

2. **Failed Delivery Reduction:**
   - Expands time window offerings (evening, weekend options)
   - Enables better matching of delivery time to customer availability
   - Reduces "Customer Not Home" failures by matching windows to actual needs

3. **Predictive Maintenance:**
   - Prevents breakdowns that would miss time windows
   - Better asset reliability = more predictable time windows

**Monitoring for Compliance:**
- Real-time tracking: For each vehicle, compare current position/time to next time window
- Alert if vehicle will miss window by >15 min (give dispatch time to intervene)
- Post-delivery analysis: Which time windows most frequently missed? (Suggests unrealistic estimation)

#### **Constraint 4: Balanced Workload & Fairness**

**Operational constraint (not regulatory, but business practice):** Avoid over-relying on top drivers; fairly distribute workload

**Current Situation:**
- Top driver (D101): 96% OTDR, efficient
- Bottom driver (D115): 85% OTDR, less efficient
- Risk: Over-assigning D101 routes while under-utilizing D115 (burnout, fairness issues)

**How Strategies Account for This:**

1. **Driver Training (from Strategy 1 analysis):**
   - Implement ride-alongs to bring bottom performers to mid-level
   - Reduce skill variance; enable more balanced load distribution

2. **Predictive routing:**
   - Avoid assigning hardest routes exclusively to best drivers
   - Instead, optimize routes to be more "medium difficulty" across the board
   - Ensures fairness and reduces burnout

3. **KPI-based incentives:**
   - Reward top performers but also progress incentives for improving drivers
   - Example: Bottom quartile driver improves OTDR by 5 points = €50 bonus

**Monitoring for Compliance:**
- Weekly workload report: Stops/distance/time per driver; flag if >20% variance
- Fatigue tracking: Monitor overtime hours per driver; flag if >10 hours/week
- Fairness dashboard: Ensure high-difficulty routes distributed across multiple drivers

---

### 5.2 Continuous Monitoring Plan Using Process Mining

After implementing the three strategies, establish an ongoing monitoring system to:
1. Track KPI improvements and validate expected outcomes
2. Detect new emerging issues early
3. Ensure sustainability of improvements

#### **Tier 1: Real-Time Operational Dashboard (Daily)**

**Dashboard Purpose:** Immediate visibility into fleet operations for dispatch team

**Key Metrics & Views:**

| Metric | Update Frequency | Alert Threshold | Action |
|--------|------------------|-----------------|--------|
| **Fleet On-Time Delivery Rate (Today)** | Hourly | <90% | Dispatch reviews problem routes; escalates if <85% |
| **Failed Delivery Rate (Today)** | Hourly | >10% | Investigate root cause (traffic, customer, system?) |
| **Average Tour Cycle Time** | Hourly | >550 min | Too slow; review traffic, vehicle issues |
| **Vehicle Utilization (per vehicle)** | Real-time | <50% capacity | Re-dispatch packages if possible; prevent waste |
| **Predictive Maintenance Alerts** | Real-time | Vehicle health score <0.5 | Schedule maintenance by end of shift if safe; otherwise assign backup vehicle |
| **Driver Shift Hours** | Real-time | >9.5 hours worked | Alert; ensure compliance with labor laws |

**Dashboard Visualization:**
- Sankey flow: Active vehicles  destinations  status (on-time, at risk, delayed)
- Heat map: Geographic coverage; highlight congested zones in real-time
- KPI gauges: OTDR, FDR, utilization (green/yellow/red zones)
- Exception list: Sorted by severity (missed time windows, failed deliveries, maintenance alerts)

---

#### **Tier 2: Weekly Performance Review (Every Monday)**

**Purpose:** Identify trends; assess strategy impact; plan corrective actions

**Key Views & Analysis:**

**1. Strategy Effectiveness Scorecard:**

```
Strategy 1: Dynamic Route Optimization
  Target KPI: Reduce travel time by 11% (350  310 min avg)
  Current (Last Week): 332 min avg (-5.1% progress)
  Trend: Improving week-on-week 
  Status: On track
  
  Supporting metrics:
    - Route sequence deviation: 8.2% (target <6%) — slightly worse; review algorithm
    - Excess distance vs. optimal: 22% (target <12%) — needs improvement
    - Traffic prediction accuracy: 82% (goal >85%) — good, need slight refinement
  
  Issues identified: Algorithm predicting lower speeds than actual in 14:00-16:00 window
  Action: Retrain traffic model with more recent data; weekend traffic patterns may differ
  
Strategy 2: Failed Delivery Reduction
  Target KPI: Reduce FDR from 8.0% to 4.5%
  Current (Last Week): 6.1% 
  Progress: -2.4 percentage points in first 3 weeks  Strong improvement
  
  Supporting metrics:
    - SMS pre-notification adoption: 76% of eligible customers (target >80%)
    - "Customer Not Home" failures: 48% of total (was 62%)  Improving
    - Time window misses vs. customer unavailability: 82% of failures due to unavailability 
      (vs. 62% previously) — suggests SMS increasing accuracy of "real" issues
    - Evening delivery uptake: 12 slots/day out of 10 planned capacity — demand exists
  
  Issues identified: Some customers ignore SMS; may need phone call follow-up
  Action: A/B test follow-up call for non-responders; measure impact
  
Strategy 3: Predictive Maintenance
  Target KPI: Reduce unplanned maintenance events by 78% (1.8  0.4/month)
  Current (First 3 weeks): 1.2 events/month (33% reduction)
  Progress: On track for 50% reduction by month 1 (ramp-up phase expected)
  
  Supporting metrics:
    - Model accuracy (precision/recall): 78% precision, 65% recall (target >75%, >70%)
    - False positive rate: 18% (alerts triggered, no failure) — acceptable, slight refinement needed
    - Maintenance scheduled proactively: 60% of maintenance now scheduled vs. unplanned (was 20%)
    - Cost tracking: €650/vehicle/month (on track for target)
  
  Issues identified: Recall slightly low (missing 35% of actual failures)
  Action: Lower probability threshold from 0.70  0.65 to catch more failures; accept more false positives
```

**2. Variance & Performance Leakage Analysis:**

```
Identify routes/drivers with worse-than-expected performance despite strategies:

Route Performance Surprises:
  - Route 27 (Urban Core): Expected 94% OTDR with new optimization, achieved 89% 
    Root cause: Construction on planned alternate route; static optimization didn't account
    Action: Real-time re-routing when construction detected
    
  - Route 15 (Suburban): Expected 96%, achieved 98%  Exceeding expectations
    Learning: This route characteristics are ideal for dynamic optimization
    Action: Use as template for similar routes

Driver Performance Surprises:
  - Driver D105: Expected improvement to 88% OTDR after training, achieved 90%  Exceeding target
    Insight: Training was effective; D105 responding well
    Action: Recognize improvement in bonus; consider advanced roles
    
  - Driver D120: Expected 93%, achieved 87% (underperforming)
    Root cause: Assigned to high-complexity urban area during peak hours; not ideal match
    Action: Rotate D120 to suburban routes; assign D101 to high-complexity slots
```

**3. Process Conformance Drift:**

Check if actual process still matches planned process:

```
Conformance Checking (Weekly):
  - Fitness (actual vs. planned): 94.0% (week 1), 92.8% (week 2), 91.5% (week 3) — Declining
  - Deviation type: Increase in sequence deviations (vehicles re-ordering stops despite optimization)
  - Root cause hypothesis: Real-time traffic forcing dynamic re-routing not yet fully integrated
  - Action: Assess whether dynamic re-routing is legitimate (better) or indicating algorithm issues

Expected if optimization working: Fitness might initially drop (routes changed), then stabilize. 
Trend shows concerning drift. Investigate.
```

---

#### **Tier 3: Monthly Strategic Review (Month-end)**

**Purpose:** Assess overall impact; adjust strategies; plan next quarter

**Key Analysis:**

**1. Strategy ROI & Business Impact:**

```
Strategy 1: Dynamic Route Optimization

Budget Invested (Month 1):
  - Traffic API: €500
  - Optimization software: €1,250 (amortized)
  - Integration dev time: €3,000
  - Total: €4,750

Quantified Benefits (Month 1):
  - Travel time reduction: 350  335 min avg (-4.3%) = 15 min/route
  - Fleet size: 80 vehicles × 20 routes/month each = 1,600 routes
  - Total time saved: 1,600 × 15 min = 24,000 min = 400 hours
  - Value at €50/hour (driver + vehicle): €20,000
  
  - Fuel savings: 6.42  6.20 L/100km (-3.4%)
  - Avg distance/day: 85 km × 80 vehicles × 20 days = 136,000 km/month
  - Fuel saved: 136,000 × 0.022 = 2,992 liters = €3,588
  
  - On-time delivery improvement: 92%  93.5% (+1.5%)
  - Additional on-time deliveries: 1.5% × 200 packages/day × 80 vehicles × 20 days = 48,000 packages
  - Value (reduced re-delivery cost): 48,000 × €4 = ... 
  [Note: This is wrong calculation; re-do]
  
  Actually: Improvement of 1.5% OTDR means 1.5% of failed deliveries avoided
  Failed deliveries: 8% × 200 × 80 × 20 = 25,600 failed/month baseline
  Avoided: 25,600 × 1.5% / (100% - 92%) = — [Complex; simpler: (93.5-92)/8 × 25,600 = 5,120 fewer failures]
  [Actually: 8% baseline × 80 vehicles × 20 days × 200 packages... complexity]
  
  Simpler approach: 
    Total deliveries/month: ~320,000
    Current failed rate: 8% = 25,600 failed
    Improvement: 1.5%  22.4% of current failed = 5,760 failures prevented
    Value: 5,760 × €4 = €23,040
  
  Total monthly benefit: €20,000 (time) + €3,588 (fuel) + €23,040 (reduced failures) = €46,628
  Month 1 net ROI: (€46,628 - €4,750) / €4,750 = 880%  Strong

  However: Month 1 is honeymoon phase. Sustain into Month 2, 3 to validate.
  Ongoing monthly cost: €1,750 (api + software)  Ongoing benefit should > €20,000 for positive ROI
```

**2. Emerging Issues & Adjustments:**

```
Issue 1: GPS data loss in underground parking areas (city centers)
  Impact: Route optimization loses vehicle location for 2-3 min; can't verify delivery
  Solution: Implement cellular/WiFi backup triangulation; or use scanner location as ground truth
  Owner: IT team; timeline: 2-week fix

Issue 2: Customer SMS opt-out rate higher than expected (15% vs. 5% baseline)
  Impact: Pre-notification strategy not reaching 15% of customers; OTDR doesn't improve for them
  Solution: A/B test messaging (clearer benefit statement); also offer WhatsApp as alternative
  Owner: Marketing; timeline: Week 2 test results

Issue 3: Maintenance team overwhelmed by predictive alerts
  Impact: 47 alerts generated first week; only 12 meaningful (30% false positive rate)
  Solution: Raise alert threshold to >0.80 probability (vs. current 0.70); rebalance precision/recall
  Owner: Data science team; timeline: Immediate threshold adjustment

Overall Assessment: Strategies showing promise but need refinement. Recommend continuing with 
adjustments; expect break-even at Month 2, strong positive ROI by Month 3.
```

---

#### **Tier 4: Quarterly Deep-Dive Analysis (Every 90 Days)**

**Purpose:** Validate long-term sustainability; identify systemic improvements

**Key Activities:**

**1. Root Cause Re-analysis:**

After 3 months, re-run root cause analysis from Section 3 to see if categories have shifted:

```
Q1 Bottleneck Summary (Baseline from Section 2):
  1. Travel Time: 58% of cycle time (PRIMARY BOTTLENECK)
  2. Service Time Variability: 2-3 min per stop (SECONDARY)
  3. Unplanned Maintenance: 1.3 events/month (TERTIARY)

Q1 Bottleneck Summary (After 3-month implementation):
  Expected:
    1. Travel Time: 52% of cycle time (reduced from 58%; Strategy 1 impact)
    2. Service Time Variability: 2.0 min per stop (reduced; better routing reduces wait)
    3. Unplanned Maintenance: 0.5 events/month (reduced; Strategy 3 impact)
  
  If actual >> expected: Strategies not working as planned; troubleshoot
  If actual < expected: Overperforming; double down on winning strategies; 
                       explore secondary optimizations
  
  New emergent bottleneck: If travel time well-controlled, service time variability becomes 
  proportionally more important. May now focus on Strategy 2 enhancements (customer service 
  time reduction, automation).
```

**2. Fleet Comparison & Best Practices:**

```
Compare old vehicles (age 3.8+ years) vs. new vehicles (age < 2 years):

Old Fleet (20 vehicles):
  - OTDR: 91% (vs. 96% new)
  - Failed deliveries: 8.5% (vs. 6% new)
  - Unplanned maintenance: 0.8 events/month (vs. 0.1 new)
  - Cost per delivery: €12 (vs. €9.50 new)

Analysis: Age-related performance gap persists despite strategies. Predictive maintenance helping, 
but old fleet still underperforming.

Recommendation: Accelerate fleet replacement. Old vehicles reaching end-of-life; ROI of continued 
investment low. Lease or buy 20 new vehicles; retire old fleet. 

Break-even analysis:
  - Cost of 20 new vehicles (lease): €3,000/month/vehicle = €60,000/month
  - Savings from improved OTDR, reduced maintenance: €40,000/month
  - Net: €20,000/month additional cost, but customer satisfaction & brand value improve

Decision: Phased replacement over 18-24 months; retire 2-3 oldest vehicles per quarter.
```

**3. Process Mining Model Refresh:**

Periodically refresh process discovery models to account for new data patterns:

```
Every 90 days:
  1. Re-discover process model using latest 3 months of data
  2. Compare to previous quarter's model:
     - Same main process structure? (indicates strategy is working)
     - New rare paths emerging? (indicates emerging issues or edge cases)
     - Activity durations trending lower/higher? (efficiency trend)
  
  Example comparison:
    Q4 Model (baseline):  [Depart]  [Travel: 10.6 min]  [Service: 5.2 min]  [Depart] (loop)
    Q1 Model (3 months):  [Depart]  [Travel: 10.0 min]  [Service: 5.1 min]  [Depart] (loop)
    
    Improvement: Travel time down 0.6 min (5.7% reduction)  Validates Strategy 1
    
    New rare path detected: [Service]  [Re-deliver immediately] (2% of stops in Q1 vs. 0.5% Q4)
    Interpretation: Possibly customers requesting repeat delivery same day (new phenomenon?)
    Action: Investigate; possible opportunity for same-day delivery service
```

**4. Process Variance Analysis:**

```
High-variance routes (OTDR ±15%) suggest:
  - Route design issues (some inherently harder than others)
  - Driver skill variance
  - Traffic/environmental unpredictability

Deep-dive analysis:
  - Compare route characteristics (stops, density, time window width, vehicle type)
  - Identify if variance due to inherent route difficulty or driver
  - Recommendation: Route-specific training or re-sequencing

Example:
  Route 27 high variance (OTDR 88-98% depending on day)
  Root cause: Mix of CBD and residential; traffic highly variable 08-10 window
  Solution: Split Route 27 into 2 sub-routes; assign best driver to high-variability portion; 
           ensure one route avoids peak window
```

---

#### **Dashboard Architecture: Technical Implementation**

**Data Pipeline:**
```
Event Sources (GPS, Scanner, Dispatch) 
  
Data Lake (Cloud storage: S3, GCS, or on-prem)
  
ETL Process (daily): Clean, transform, integrate event logs
  
Process Mining Database: 
  - Processed event log (standardized schema)
  - Derived KPIs (daily refresh)
  - Route/driver performance tables
  - Predictive maintenance scores
  
BI Dashboard Tools (Tableau, Power BI, Grafana, or custom)
  - Real-time widgets (Tier 1)
  - Weekly summary reports (Tier 2)
  - Monthly analysis (Tier 3)
  - Quarterly deep-dives (Tier 4)
```

**Key Dashboard Screens:**

**Screen 1: Real-Time Fleet Operations (Tier 1)**
- Map view: Vehicle locations, delivery status (green/yellow/red)
- KPI cards: Today's OTDR (target 95%), FDR (target <8%), avg cycle time (target 480 min)
- Exception alerts: Vehicles with predicted delays, maintenance flags

**Screen 2: Weekly Performance Summary (Tier 2)**
- Chart 1: OTDR trend (7-day line chart; target band highlighted)
- Chart 2: FDR by reason (pie chart; drill into "Customer Not Home" if high)
- Chart 3: Travel time vs. service time (dual bar chart; show trend)
- Table: Top/bottom 5 drivers by OTDR score

**Screen 3: Route Performance & Conformance (Tier 2)**
- Heatmap: Routes grid (x-axis route ID, y-axis week); color = OTDR
- Scatter plot: Route distance vs. on-time rate; identify "hard" routes
- Conformance metrics: Fitness, precision per route

**Screen 4: Predictive Maintenance Status (Tier 3)**
- Fleet health gauge: % of vehicles in green/yellow/red health state
- Alerts log: Upcoming maintenance by vehicle; predicted failure reason
- Historical: Past 12 months of unplanned events; trend over time

**Screen 5: Strategy KPI Dashboard (Tier 3)**
- 3 strategy cards, each showing: Target, Current, Progress, Status (on-track/at-risk/off-track)
- Monthly comparison: Benefits realized vs. benefits planned

---

#### **Alert Rules & Escalation**

```
Real-Time Alerts (immediate notification):

Alert: Vehicle will miss delivery time window by >15 min
  Trigger: Current position + predicted travel time  ETA > time_window_end + 15 min
  Recipients: Dispatch supervisor, driver
  Action: Offer customer alternative time slot (if SMS capable); consider dynamic re-route
  SLA: Alert within 30 min of issue detection

Alert: Vehicle health score drops to <0.40 (high maintenance risk)
  Trigger: Predictive maintenance model probability > 0.75
  Recipients: Maintenance coordinator, vehicle manager
  Action: Schedule maintenance within 24 hours; assign backup vehicle if urgent route
  SLA: Alert immediately upon threshold cross

Alert: Failed delivery rate > 10% today
  Trigger: Daily FDR calculation
  Recipients: Dispatch manager, operations director
  Action: Investigate root cause; identify if customer unavailability, system issue, or driver issue
  SLA: Alert by 14:00 (end of delivery day)

Weekly Alerts (sent Monday morning):

Alert: Driver shift > 50 hours in prior week
  Trigger: Weekly hours calculation
  Recipients: HR, operations manager
  Action: Assess workload; consider adding staffing if recurring
  Recommendation: Review driver wellness; ensure compliance with labor law

Alert: Route utilization <60% or >95%
  Trigger: Weekly utilization calculation
  Recipients: Dispatch manager
  Action: Rebalance routes; <60% suggests over-sizing; >95% suggests overload risk
```

---

## Summary & Conclusion

This comprehensive analysis outlines a data-driven optimization program for Speedy Parcels' delivery operations using process mining as the central analytical tool. 

**Key Findings:**

1. **Primary Bottleneck:** Travel time (58% of cycle time), driven by suboptimal route sequencing and traffic congestion, not inherent to logistics.

2. **Root Causes:** 
   - Suboptimal route planning (static, not real-time)
   - Underestimated travel times (+20-30% in urban areas due to parking/navigation)
   - High failed delivery rate (8%), especially "Customer Not Home" (62% of failures)
   - Vehicle maintenance unpredictability (old fleet: 1.8 unplanned events/month)
   - Driver skill variance (95% OTDR top performers vs. 85% bottom performers)

3. **Recommended Interventions:**
   - **Strategy 1:** Dynamic route optimization with real-time traffic prediction  11% travel time reduction, 96% OTDR target
   - **Strategy 2:** Failed delivery reduction via customer profiling and pre-notification  55% FDR reduction (8%  4.5%)
   - **Strategy 3:** Predictive vehicle maintenance  78% reduction in unplanned events, 28% maintenance cost reduction

4. **Expected Overall Impact:**
   - €500/vehicle/month operational cost savings (~€40,000/month fleet-wide for 80 vehicles)
   - 96% on-time delivery rate (vs. current 92%)
   - 94% first-time delivery success rate (vs. current 90%)
   - Improved driver retention (better working conditions, incentives)

5. **Implementation Approach:**
   - Phased 8-month rollout with pilot testing
   - Total investment: ~€100,000 year 1; ongoing €30,000/year
   - Break-even within 3-4 months; strong ROI thereafter

6. **Monitoring & Sustainability:**
   - Multi-tier dashboard system (real-time, weekly, monthly, quarterly)
   - Continuous process mining to detect drift and emerging issues
   - Quarterly strategy review and adjustments
   - Long-term vision: Fleet modernization and shifting from reactive to predictive operations

This approach transforms Speedy Parcels from cost-reactive to data-driven strategic optimization, leveraging process mining to unlock hidden inefficiencies and drive sustainable competitive advantage.