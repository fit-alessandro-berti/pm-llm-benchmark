### 1. Queue Identification and Characterization

In queue mining, waiting time for a patient (case) is defined as the **idle time between the completion of one activity and the start of the subsequent activity** in the patient's sequence. Using the event log's start and complete timestamps per case ID, waiting time can be calculated as:

\[ \text{Waiting Time}_{i \to j} = \text{Start Timestamp}_j - \text{Complete Timestamp}_i \]

where \(i\) and \(j\) are consecutive activities for the same case. Only positive differences (actual waits) are considered waits; zero or negative values indicate seamless handovers or overlaps (rare in serial flows). Aggregating across all cases and activity pairs yields queue profiles.

Key metrics to characterize queues:
- **Average waiting time**: Mean wait across all instances of a queue (e.g., Registration  Nurse Assessment).
- **Median waiting time**: Robust to outliers, showing typical experience.
- **Maximum waiting time**: Identifies worst-case scenarios.
- **90th percentile waiting time**: Captures 90% of cases, highlighting service level failures (e.g., >30 min for 10% of patients).
- **Queue frequency**: Number/percentage of cases experiencing the queue (e.g., % of visits with >15 min wait post-Registration).
- **Number of cases with excessive waits**: E.g., waits >45 min, segmented by patient type (New/Follow-up) or urgency.

To identify **most critical queues**:
- Prioritize by **composite score**: (Average wait × Frequency × Impact weight), where impact weights prioritize high-volume patient types (e.g., New patients) or urgency (Urgent weighted 2x). Criteria:
  - **Longest average wait** (>20 min threshold).
  - **Highest frequency** (>70% of cases affected).
  - **Patient-specific impact** (e.g., queues disproportionately affecting New patients, who have longer flows).
- Example: If Nurse Assessment  Doctor Consultation averages 25 min (90th %ile 50 min), affects 85% of cases, and delays New patients by 30%, it ranks critical over a low-frequency but long max-wait queue.

Process mining tools (e.g., Celonis, ProM) would visualize this via **queue charts** (waiting time distributions per transition) and **dotted charts** (timeline views per case).

### 2. Root Cause Analysis

Critical queues often stem from systemic issues beyond surface-level waits. Using the event log:

- **Resource bottlenecks**: Analyze resource (staff/room) utilization via **resource calendars**—compute % busy time (\(\frac{\sum \text{Service Time}}{\text{Available Time}}\)). High utilization (>80%) on Nurse 1 or Room 3 indicates scarcity. **Bottleneck analysis** in process mining highlights activities with long service times blocking queues.
  
- **Activity dependencies/handovers**: **Process discovery** (e.g., BPMN/Heuristic Miner) maps flows; **transition matrices** show handover delays (e.g., Clerk A to Nurse 1). Dotted charts reveal clustering of completes/starts.

- **Variability in service times**: Calculate service time (\(\text{Complete} - \text{Start}\)) distributions per activity/resource. High variance (e.g., Doctor Consultation std. dev. >20 min) causes unpredictable queues. **Variant analysis** segments logs by patient type/urgency (filter New vs. Follow-up).

- **Appointment scheduling**: Infer arrival patterns from Registration starts; cluster analysis on timestamps detects peaks (e.g., 9-10 AM overload). Correlate with queues.

- **Patient type/urgency differences**: **Filtering and aggregation**: Split logs (e.g., New patients have longer Doctor queues due to Specialist Review).

Techniques:
- **Performance spectra**: Heatmaps of service/wait times over time-of-day/weekdays.
- **Social network analysis**: Staff handovers (e.g., Clerk B overload).
- **Root cause mining**: Correlation analysis (e.g., high ECG waits link to Dr. Smith overload).
- **Conformance checking**: Against ideal flow to spot deviations.

This pinpoints, e.g., Nurse bottlenecks from high New patient volume or poor scheduling causing post-Registration pile-ups.

### 3. Data-Driven Optimization Strategies

**Strategy 1: Dynamic Resource Cross-Training and Allocation**
- **Targeted queue(s)**: Nurse Assessment  Doctor Consultation; Doctor Consultation  Diagnostic Tests (e.g., ECG).
- **Root cause addressed**: Resource bottlenecks (e.g., Nurse 1/Dr. Smith >85% utilization for New patients).
- **Data support**: Resource analysis shows top 20% staff handle 60% load; variant analysis reveals New patient peaks post-9 AM.
- **Implementation**: Cross-train 2 clerks as nurse aides during peaks; allocate via real-time dashboard (e.g., prioritize Urgent). Expected: Reduce avg. wait by 40% (from 2515 min, based on simulation from log variances).

**Strategy 2: Tiered Appointment Scheduling with Buffer Zones**
- **Targeted queue(s)**: Registration  Nurse Assessment; overall flow for Follow-up patients.
- **Root cause addressed**: Patient arrival patterns and scheduling policies (e.g., 9 AM clusters cause 30-min Registration queues).
- **Data support**: Timestamp clustering shows 40% arrivals 9-10 AM; 90th %ile Registration wait 20 min for Normal urgency.
- **Implementation**: Slot New/Urgent earlier with 15-min buffers; Follow-up in waves with staggered slots. Use log-derived demand forecasts (e.g., Poisson from historical volumes). Expected: Cut Registration queue frequency by 50%, overall visit duration by 20% (e.g., 12096 min avg.).

**Strategy 3: Parallel Processing for Diagnostics**
- **Targeted queue(s)**: Doctor Consultation  ECG/Blood Test.
- **Root cause addressed**: Sequential dependencies and equipment variability (e.g., Tech X/Room 3 queues).
- **Data support**: Bottleneck analysis flags 35-min avg. wait; service time variance high for ECG (10-40 min).
- **Implementation**: Doctor flags diagnostics post-consult; techs pull queued patients via app (bypassing full serial wait). Pre-allocate rooms based on specialty variants. Expected: 90th %ile wait reduction by 60% (5020 min), without new hires.

### 4. Consideration of Trade-offs and Constraints

- **Trade-offs**:
  - **Strategy 1**: Cross-training increases initial staff training costs (~$5K) and short-term productivity dips; may overload clerks, raising burnout (monitor via future logs).
  - **Strategy 2**: Buffers reduce daily slots (10-15% throughput drop), shifting bottlenecks to afternoons; unequal for Follow-up (perceived unfairness).
  - **Strategy 3**: Parallelization risks errors (e.g., incomplete consults); equipment overuse could increase maintenance costs 10-20%.

- **Balancing objectives**: Use **multi-objective simulation** (e.g., Discrete Event Simulation from log) to model scenarios, optimizing wait reduction vs. cost (<5% budget hike) and quality (no service time increase). Prioritize low-cost/high-impact (Strategy 2 first). Maintain care quality via conformance checks (e.g., ensure Nurse Assessment completes fully). Pilot on subsets (e.g., Cardio specialty) with A/B testing. Involve stakeholders (doctors/staff) for buy-in, using log visualizations.

### 5. Measuring Success

**KPIs** (tracked pre/post via updated event logs):
- **Primary**: Avg./90th %ile waiting time per queue (<20 min target); overall visit duration (Complete Check-out - Start Registration; <90 min target).
- **Secondary**: Throughput (patients/hour; >95% baseline); Queue frequency (% cases >15 min wait; <30%); Patient satisfaction proxy (infer from reduced abandons, if logged).
- **Quality/Cost**: Service time stability (no >10% increase); Utilization (<85%); Cost per visit (stable).

**Ongoing monitoring**: Deploy **process mining dashboard** (e.g., Celonis) ingesting real-time logs. Weekly **conformance checking** against optimized model; anomaly detection for drifts (e.g., rising waits). Monthly **cohort analysis** (New vs. Follow-up). If KPIs regress >10%, trigger root cause re-analysis. Quarterly simulations validate sustained gains, ensuring adaptive improvements.