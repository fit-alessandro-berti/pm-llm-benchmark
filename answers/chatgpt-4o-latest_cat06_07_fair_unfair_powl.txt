Here are the two POWL models that describe the hiring process at GlobalTeq Solutions, constructed to reflect potential bias (in the first) and the removal of such bias (in the second).

---

##  1. POWL Model with Potential Unfairness

This model introduces **potential unfairness** by applying an XOR (exclusive choice) after the skill assessment. One branch performs a standard CulturalFitCheck, while the other performs a **CommunityAffiliationCheck**, which could favor certain applicants — causing unfair advantage.

```python
from pm4py.objects.powl.obj import StrictPartialOrder, OperatorPOWL, Transition, SilentTransition
from pm4py.objects.process_tree.obj import Operator

# Define activities
receive_application = Transition(label="ReceiveApplication")
data_check = Transition(label="DataCompletenessCheck")
request_info = Transition(label="RequestMoreInfo")
skill_assessment = Transition(label="SkillAssessment")
cultural_fit_check = Transition(label="CulturalFitCheck")
community_affiliation_check = Transition(label="CommunityAffiliationCheck")
managerial_review = Transition(label="ManagerialReview")
final_decision = Transition(label="FinalDecision")

# Loop for data completeness
loop_data = OperatorPOWL(operator=Operator.LOOP, children=[data_check, request_info])

# XOR between cultural fit path and community-affiliated path
xor_cultural_eval = OperatorPOWL(operator=Operator.XOR, children=[cultural_fit_check, community_affiliation_check])

# Combine all in sequence using partial order
root_with_bias = StrictPartialOrder(nodes=[
    receive_application,
    loop_data,
    skill_assessment,
    xor_cultural_eval,
    managerial_review,
    final_decision
])

# Define partial order
root_with_bias.order.add_edge(receive_application, loop_data)
root_with_bias.order.add_edge(loop_data, skill_assessment)
root_with_bias.order.add_edge(skill_assessment, xor_cultural_eval)
root_with_bias.order.add_edge(xor_cultural_eval, managerial_review)
root_with_bias.order.add_edge(managerial_review, final_decision)
```

---

##  2. POWL Model Without Unfairness

This model ensures **fairness** by using a single **CulturalFitCheck** for all applicants. There is no XOR splitting based on community affiliation. Everyone follows the same path through cultural evaluation.

```python
from pm4py.objects.powl.obj import StrictPartialOrder, OperatorPOWL, Transition, SilentTransition
from pm4py.objects.process_tree.obj import Operator

# Define activities
receive_application = Transition(label="ReceiveApplication")
data_check = Transition(label="DataCompletenessCheck")
request_info = Transition(label="RequestMoreInfo")
skill_assessment = Transition(label="SkillAssessment")
cultural_fit_check = Transition(label="CulturalFitCheck")
managerial_review = Transition(label="ManagerialReview")
final_decision = Transition(label="FinalDecision")

# Loop for data completeness
loop_data = OperatorPOWL(operator=Operator.LOOP, children=[data_check, request_info])

# Combine all in sequence using partial order
root_without_bias = StrictPartialOrder(nodes=[
    receive_application,
    loop_data,
    skill_assessment,
    cultural_fit_check,
    managerial_review,
    final_decision
])

# Define partial order
root_without_bias.order.add_edge(receive_application, loop_data)
root_without_bias.order.add_edge(loop_data, skill_assessment)
root_without_bias.order.add_edge(skill_assessment, cultural_fit_check)
root_without_bias.order.add_edge(cultural_fit_check, managerial_review)
root_without_bias.order.add_edge(managerial_review, final_decision)
```

---

###  Key Difference Summary:

| Step                                 | Model with Unfairness                        | Model Without Unfairness             |
|--------------------------------------|----------------------------------------------|--------------------------------------|
| Cultural Evaluation Method           | XOR: cultural fit OR community affiliation   | Single path: cultural fit only       |
| Potential Bias Introduced?           |  Yes                                        |  No                                 |
| Fairness Assurance                   |  No, some applicants get advantage          |  Yes, all treated equally           |
| Suitable for Bias Auditing & Ethics? | Not ideal                                     | Preferable for fairness/compliance   |

Let me know if you’d like these models serialized or visualized!