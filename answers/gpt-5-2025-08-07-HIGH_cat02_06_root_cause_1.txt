Here’s a concise analysis of the event log, focusing on resolution times, likely drivers of delay, and actionable recommendations.

1) Cases with significantly longer resolution times
- 101: 2h15m (fast)
- 103: 1h20m (fast)
- 104: 24h10m (slow)
- 102: 25h10m (slow)
- 105: 49h05m (very slow)

Notes:
- Overall average  20h24m, but that average is skewed by long cases. The “normal” baseline (cases 101, 103) is ~1–2 hours. Cases 102, 104, and 105 are 12–30x slower than the fast baseline; 105 is the clear outlier.

2) Likely root causes (with evidence)
- Escalation to Level-2 is highly correlated with long cycle times.
  - Case 102: Escalate at 11:30  L2 begins investigating only at 14:00 (+2h30m). Resolution follows the next day (+19h from start of investigation).
  - Case 105: Escalate at 10:00  L2 begins investigating next day at 14:00 (+28h). Another +19h to resolution. This single L2 queue delay drives almost the entire 49h cycle time.
- Cross-day/overnight waits after investigation are a recurring pattern.
  - 102, 104, 105 each have ~19h between “Investigate Issue” and “Resolve Ticket,” suggesting work paused across a shift boundary or pending dependencies (maintenance windows, third-party/customer input), exacerbated by weekends.
- Late start of investigation at Level-1 (capacity/queueing).
  - Case 104: Assign to L1 at 09:30  L1 Investigate at 13:00 (+3h30m), far longer than the 10–40m seen in fast cases.
- Longer triage in one case (minor contributor).
  - Case 104: 40m receivetriage vs 5–25m in others; small relative to the day-long waits.
- Process labeling limits visibility.
  - “Investigate Issue” is used for both L1 and L2 (e.g., case 105 has two separate investigations). This obscures where delays actually occur and complicates queue management.

3) Why these factors inflate cycle time and what to do about it
- L2 queue delays and limited coverage
  - Impact: Hours-to-day waits before L2 even starts, plus overnight holds, dominate total cycle time.
  - Actions:
    - Set and monitor an SLA for “Escalation to L2  first response” (e.g., 1h within business hours, with on-call for off-hours).
    - Add or reallocate L2 capacity during peak times and weekends, or introduce an expedited lane for escalations.
    - Introduce automatic alerts if an escalated ticket has no L2 activity within 60 minutes.
- Cross-day handoffs and shift boundaries
  - Impact: ~19h gaps after “Investigate” indicate work stops at end-of-day and resumes next morning/weekend, dramatically increasing cycle time.
  - Actions:
    - Implement a “finish same day” policy for tickets entering investigation before a cut-off time (e.g., 2pm), or require a formal handover checklist to prevent idle overnight.
    - If resolution needs a window, schedule earlier or provide limited after-hours change windows for high-priority issues.
- L1 investigation start delays
  - Impact: Case 104 shows a 3.5h queue before L1 starts investigating, adding same-day delay that pushes work past end-of-day.
  - Actions:
    - WIP limits and queue discipline for L1; auto-reassign if not touched within 30–60 minutes.
    - Balance staffing around morning intake spikes; consider staggered start times to reduce mid-day backlog.
- Escalation timing and criteria
  - Impact: Prolonged L1 attempts before escalating (e.g., 2h30m in case 102) can push tickets into the next day.
  - Actions:
    - Clear rules for early escalation on defined patterns; decision support in triage to flag likely L2 issues.
- Measurement and visibility
  - Impact: Using a single “Investigate Issue” label hides whether delays are at L1 vs L2.
  - Actions:
    - Split activities into “Investigate (L1)” and “Investigate (L2)” and log “Waiting on Customer/3rd Party/Maintenance Window” explicitly. Analyze wait time by reason and team.
    - Track performance in working-time and clock-time to distinguish true bottlenecks from expected off-hours.

Bottom line
- Outliers: 102, 104, 105, with 105 being the extreme.
- Main drivers: L2 escalation delays, cross-day/overnight pauses, and late start of L1 investigation (especially case 104).
- Highest-impact fixes: tighten L2 first-response SLAs with capacity/coverage adjustments, enforce earlier escalations and L1 touch-time limits, and address end-of-day handoffs to avoid overnight idle time.