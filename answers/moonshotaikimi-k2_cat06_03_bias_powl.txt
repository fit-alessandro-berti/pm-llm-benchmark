The seemingly-innocuous pair  

PreliminaryScoring  (LocalAffiliationCheck  **XOR**  skip)  ManualReview  

is exactly where the bias is injected.  
In data-science terms it is equivalent to adding an engineered, categorical feature  

`LOCAL_AFFILIATION = ( D already happened ) ? 1 : 0`

into every applicant’s scoring vector **after** the first credit score has already been computed.  
The manual-review stage receives this flag and can unconsciously—or deliberately—raise (“uplift”) the effective score whenever it is positive.

1. **Definition of the privileged group**  
   The condition “local resident **and** member of a known community group” correlates strongly with,
   • geography (neighbourhood A vs. B),  
   • age/longevity in location,  
   • ethnicity/language (community centres, churches, mosques, etc.),  
   • even gender (women often participate in parent-teacher associations).  

   Yet none of these correlations map cleanly to legally-protected attributes given by anti-discrimination law (race, national origin, gender, religion, etc.). Thus the rule is omitted from protected-feature lists and remains invisible to most fairness audits.

2. **Incremental advantage mechanism**  
   • In a manual-review step people routinely use mental heuristics: “Anna’s file looks weak, but she’s a respected member of the Rotary – probably okay”.  
   • Even when uplift is statistically small (say +5 points on a 250-point scale), it is enough to push borderline applicants into the “Approve” bucket while superficially identical applicants that never executed D continue to be rejected.  
   • Over a portfolio this thin edge compounds: the group is rejected 2–3 % less often, receives 0.1 % better interest rates, and creates a positive feedback loop of local anecdotes and social proof that the lender is “good to people like us”.

3. **Immediate fairness implications**  
   • **Disparate impact without disparate treatment**: the eventual acceptance rates between demographic groups will diverge even though the same underwriting rules are technically applied to every file.  
   • **Exploitability**: the process can be gamed once outsiders realise that joining a local association dramatically improves their odds, producing a new inequality between informed and uninformed applicants.  
   • **Audit resistance**: the lender could truthfully say “local affiliation is not used in the model,” because the variable never appears in the formulas executed by algorithmic steps—it is introduced only in ad-hoc handwritten notes.

4. **Longer-term effects on equity**  
   • **Credit-feedback loop**: marginal applicants who receive the uplift build a repayment history, which in turn improves their future credit scores, snow-balling the advantage.  
   • **Red-lining by association**: conversely, applicants just outside every “recognised community group” (new migrants, ethnic minorities without a formal group, remote rural residents) may find themselves systematically at the back of the queue.  
   • **Regulatory risk**: regulators discover divergence in outcomes, trigger fair-lending investigations, and eventually force the bank to drop the feature retroactively—jeopardising the legitimacy of thousands of already-granted loans.

Remedies therefore go beyond technical fixes; they require **documenting and separating** the effect of D, performing **fairness stress-tests** on non-protected group definitions, and either removing the uplift entirely or transforming it into an explicitly monitored, fully transparent bonus during pre- rather than post-scoring.