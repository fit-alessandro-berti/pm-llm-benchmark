### **1. Identification of Cases with Significantly Longer Resolution Times**

First, let’s calculate the **total resolution time** (from “Receive Ticket” to “Close Ticket”) for each case:

- **Case 101**:  
  Receive: 2024-03-01 08:00  
  Close: 2024-03-01 10:15  
   **Duration: 2h 15m**

- **Case 102**:  
  Receive: 2024-03-01 08:05  
  Close: 2024-03-02 09:15  
   **Duration: 25h 10m**

- **Case 103**:  
  Receive: 2024-03-01 08:10  
  Close: 2024-03-01 09:30  
   **Duration: 1h 20m**

- **Case 104**:  
  Receive: 2024-03-01 08:20  
  Close: 2024-03-02 08:30  
   **Duration: 24h 10m**

- **Case 105**:  
  Receive: 2024-03-01 08:25  
  Close: 2024-03-03 09:30  
   **Duration: 49h 5m**

#### **Summary of Resolution Times**:
| Case ID | Total Resolution Time |
|---------|------------------------|
| 101     | 2h 15m                 |
| 102     | 25h 10m                |
| 103     | 1h 20m                 |
| 104     | 24h 10m                |
| 105     | 49h 5m                 |

>  **Significantly longer cases**: **Case 105 (49h 5m)** and **Case 102 & 104 (~24–25h)**  
> — These are **10–20x longer** than the average of the faster cases (101 and 103, averaging ~1h 48m).

---

### **2. Root Causes of Performance Issues**

#### **Pattern 1: Escalation to Level-2 Agents Correlates with Massive Delays**
- **Case 102**: Escalated at 11:30  Next activity (Investigate Issue) at 14:00 (2.5h later), then **no activity until next day at 09:00**  **19h gap**.
- **Case 105**:  
  - Escalated at 2024-03-01 10:00  
  - Next activity: Investigate Issue at **2024-03-02 14:00**  **28h delay**  
  - Then Resolve at 2024-03-03 09:00  **19h delay after investigation starts**

>  **Observation**: The **escalation step is followed by extremely long waiting periods** before the next activity. This suggests **Level-2 teams are overloaded, under-resourced, or have poor handoff protocols**.

#### **Pattern 2: Long Delays Between Triage and Assignment**
- **Case 104**:  
  Triage: 09:00  Assignment: 09:30 (30m)  then **no activity for 3.5h** until investigation starts at 13:00  
   **3h 30m idle time** after assignment, before investigation begins.

- **Case 102**:  
  Triage: 08:30  Assignment: 09:00 (30m)  then **2.5h gap** until escalation  then **19h gap** until investigation.

>  **Observation**: Even **non-escalated cases** like 104 show long gaps between assignment and investigation, suggesting **Level-1 agents are overloaded or lack clear priorities**.

#### **Pattern 3: Overnight and Weekend Gaps**
- All long cases (102, 104, 105) have **gaps spanning overnight or into the next day**.
- For example:
  - Case 105: No activity between 10:00 Mar 1 and 14:00 Mar 2  **entire night + next day**.
  - Case 104: No activity between 13:00 Mar 1 and 08:00 Mar 2  **19h overnight gap**.

>  **Observation**: The support process **lacks 24/7 coverage**, and **escalated tickets are not prioritized** during off-hours. Level-2 teams likely operate on standard business hours (e.g., 9–5), causing tickets to “pile up” and wait.

#### **Pattern 4: Multiple Escalations = Exponential Delays**
- Case 105 was escalated **once**, but then took **49+ hours** — longer than Case 102, which escalated once and took 25h.
- Why? Because after escalation, **Case 105 had a 28h gap** before investigation even started, whereas Case 102 had a 2.5h gap after escalation.

>  **Insight**: The **delay after escalation** is not consistent — suggesting **inconsistent workload distribution or lack of SLA enforcement** for Level-2 teams.

---

### **3. Root Cause Summary & Impact on Cycle Time**

| Root Cause | Impact on Cycle Time |
|-----------|----------------------|
| **Escalation to Level-2 without SLA or prioritization** | Causes massive delays (19–28h) due to unmonitored queues; tickets sit unattended. |
| **Level-1 agents idle after assignment** | Delays in starting investigation (e.g., Case 104: 3.5h) indicate poor task management or lack of training. |
| **No off-hours coverage** | Overnight gaps (12–19h) add significant unproductive time. Escalated tickets are stuck until next business day. |
| **Lack of visibility or tracking for escalated tickets** | No evidence of alerts, notifications, or dashboards for Level-2 teams — tickets are “lost” in transition. |

>  **Critical Insight**:  
> **The primary bottleneck is not the complexity of the issue, but the process after escalation.**  
> The **transition from Level-1 to Level-2** is a **black box** with no accountability or time tracking.  
> Even non-escalated tickets (Case 104) suffer from long delays — suggesting **systemic inefficiencies across the entire workflow**, not just escalation.

---

### **4. Recommendations to Address Bottlenecks**

####  **Immediate Recommendations**

1. **Enforce SLAs for Escalated Tickets**  
   - Define and monitor **maximum wait time** between escalation and Level-2 investigation (e.g.,  4 hours).  
   - Implement **automated alerts** if escalation sits unattended beyond SLA (e.g., Slack/email alert to Level-2 manager).

2. **Implement 24/7 Tiered Support or On-Call Rotation for Level-2**  
   - Critical tickets (e.g., high-priority customers, repeated issues) should be routed to **on-call Level-2 agents** during off-hours.  
   - Even a 4-hour coverage window (e.g., 6 PM – 8 AM) can cut 12–19h delays in half.

3. **Reduce “Assignment to Investigation” Delays**  
   - Train Level-1 agents to **start investigation within 1 hour of assignment**.  
   - Use **ticket dashboards** with color-coded status (e.g., red if >2h since assignment) to prompt action.

4. **Introduce a “First Response SLA” for All Tickets**  
   - Example: “All tickets must be assigned within 1 hour of triage.”  
   - Case 104: Triage at 09:00  assigned at 09:30 (ok), but investigation started at 13:00 — **this is unacceptable**.  
   - Track and publish team-level metrics on “Time from Assignment to First Action.”

5. **Analyze Escalation Triggers**  
   - Are certain issue types or customer segments disproportionately escalating?  
   - If 80% of escalations come from 2–3 issue types, consider **creating knowledge base articles or Level-1 training** to reduce escalations.

6. **Implement a “Handoff Dashboard” for Escalations**  
   - When a ticket is escalated, it should auto-create a **priority task** in Level-2’s queue with:  
     - Customer context  
     - Previous investigation notes  
     - SLA timer  
   - Prevents “lost tickets” and ensures continuity.

####  Long-Term Recommendation: **Process Mining & Continuous Monitoring**
- Use process mining tools (e.g., Celonis, Disco) to automatically detect:
  - Bottleneck activities
  - Frequent delays
  - Cases deviating from the “fast path”
- Set up **real-time alerts** for tickets exceeding median time per stage.

---

### **Conclusion**

The **primary cause of prolonged resolution times** is **inefficient handling of escalated tickets** combined with **lack of SLAs, off-hours coverage, and poor task visibility**. Cases 102, 104, and especially 105 are symptomatic of a **broken handoff between Level-1 and Level-2 teams**. 

>  **Key Takeaway**:  
> **The ticket doesn’t slow down because the problem is hard — it slows down because the process is broken.**  
> Fixing the handoff, enforcing SLAs, and enabling 24/7 coverage for critical escalations will reduce average resolution time by **60–70%** and dramatically improve customer satisfaction.

By implementing these changes, the support team can transform from a reactive, delay-prone system into a responsive, predictable, and customer-centric operation.