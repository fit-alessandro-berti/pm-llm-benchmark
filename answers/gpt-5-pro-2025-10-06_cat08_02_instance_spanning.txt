Section 1 — Identifying instance-spanning constraints and quantifying their impact

Approach overview
- Build a “stateful” view of the process from the event log by reconstructing activity intervals (start–complete), resource calendars, and case attributes (Order Type, Region, Cold, Hazardous). This allows us to track, over time, which orders are waiting, which resources are busy, how batches form, and how many hazardous orders are active simultaneously.
- Use process discovery for control-flow transparency (e.g., Inductive Miner/Heuristics Miner) and performance enhancement overlays for time and resource views. Then apply queue mining and time-slicing to attribute waiting to specific instance-spanning constraints.

A. Shared Cold-Packing stations (capacity constraint)
- Formal identification:
  - Define resource pools: Cold-Packing = {C1..C5}, Standard-Packing = {S1..Sn}.
  - For each Packing activity instance with Requires Cold Packing = TRUE, create an interval [start, complete] with associated station.
  - Construct a time series of Cold-Packing utilization: at any time t, utilization U_cold(t) = busy_cold_stations(t) / 5.
- Impact metrics:
  - Waiting-to-start at Packing (cold orders only): w_pack_cold = start(Packing)  complete(Item Picking).
  - Resource-queue attribution: For each cold order’s ready time r (end of previous step), compute the earliest time a cold station becomes free t_free. Resource wait = max(0, min(start, t_free)  r). This isolates waiting caused by all cold stations being busy.
  - Queue length profile: L_cold(t) = number of cold orders ready but not yet started at t.
  - Time-at-capacity: proportion of operating time with U_cold(t) = 1.0.
  - Overtake rate (priority interaction proxy): share of times an express cold order starts before at least one earlier ready standard cold order.
  - Throughput bottleneck index: correlation between cold-station utilization and end-to-end cycle time.
- Differentiating within-instance vs between-instance waiting:
  - Within-instance: long processing times (start-to-complete) on Packing.
  - Between-instance: long ready-to-start intervals coinciding with U_cold(t) ~ 1 and L_cold(t) > 0.

B. Batching for Shipping Label Generation (synchronization constraint)
- Formal identification:
  - Identify Shipping Label Generation as a batch-triggered activity. From logs, derive a batch ID, region, and batch timestamp; if not explicit, infer batches by grouping Shipping Label Gen. events with the same Region and near-identical timestamps.
  - For each batch k in region R: first_ready_time = min completion time of QC among batch members; batch_release_time = timestamp of Shipping Label Gen. for that batch; batch dwell = batch_release_time  first_ready_time.
- Impact metrics:
  - Per order batch-wait: w_batch_i = start(Shipping Label Gen.)  complete(Quality Check).
  - Batch formation metrics per region: average batch size, average dwell time (first-to-last QC completion to batch release), tail percentiles (P90/P95 batch-wait), orders missing delivery cut-off due to batching.
  - Missed consolidation benefit vs time penalty: model the observed trade-off between route density (batch size) and additional lead time.
- Differentiation:
  - If at QC completion time a batch for that region exists but its release time is later and no non-batch prerequisite is needed, attribute waiting to batching (between-instance). If the Shipping Label Gen. processing time itself is long once started, that’s within-instance.

C. Priority Order handling (preemption/priority constraint)
- Formal identification:
  - Tag Express orders. At each step with shared resources (e.g., Packing), detect:
    - Head-of-line priority: express order starts before standard orders that were ready earlier.
    - Preemption evidence (if logged): SUSPEND/RESUME or two Packing start–complete intervals for the same order interrupted by another order on the same station. If explicit preemption events are not available, approximate by identifying unusually split or bimodal durations on stations and overlapping station assignments that imply a pause.
- Impact metrics:
  - Priority gain: average reduction in express ready-to-start vs standard ready-to-start when both are queued together.
  - Displacement cost: average added waiting time of standard orders in time windows when an express order arrives, compared to similar windows without express arrivals.
  - Preemption overhead: total extra setup/handling time attributable to interruptions (from split durations or station changeovers).
  - SLA adherence: share of express orders meeting delivery targets compared to counterfactual (no priority) estimated via queue simulation on historical data.
- Differentiation:
  - Between-instance effect when standard orders’ ready-to-start is delayed due to express taking capacity or preempting; within-instance effect when a standard order’s actual processing time is long independent of other cases.

D. Hazardous Material limit (global concurrency constraint)
- Formal identification:
  - Construct a hazard concurrency signal H(t) = count of orders flagged Hazardous = TRUE that are active in Packing or Quality Check at time t.
  - Regulatory conformance: check H(t)  10 at all times.
- Impact metrics:
  - Token-constraint wait time: for any hazardous order ready to start Packing or QC at time r, if H(r) = 10, measure waiting until H(t) drops below 10; attribute this wait to the regulatory cap.
  - Time-at-cap: proportion of time H(t) = 10.
  - Spillover delay: waiting of non-hazardous orders if stations are idle but blocked by hazardous limit policies (if such policies exist; often the cap applies only to hazardous instances).
  - Throughput reduction: compare observed throughput to a counterfactual model without the cap (simulation-based).
- Differentiation:
  - Between-instance: waiting because H(t) = 10 even when stations are technically available. Within-instance: long activity durations for hazardous orders once started.

How to separate waiting causes when multiple constraints overlap
- Order the causes based on precedence logic:
  1) Regulatory gating (hazard cap). If cap is binding at r, attribute the first portion of waiting to cap until it releases.
  2) Batch gating (for Shipping Label Gen.). If batching is required and batch not released, attribute to batching.
  3) Resource capacity (e.g., cold-station busy). Attribute remaining waiting to capacity if no station free.
  4) Operational/within-instance reasons (e.g., manual staging, travel, preparation).
- Use time-slicing to apportion waiting segments to each active constraint and produce additive root-cause labels for each order’s waiting time.

Section 2 — Analyzing interactions between constraints

Key interactions to investigate
- Express x Cold-Packing:
  - Express orders requiring cold-packing can preempt or head-of-line jump at a scarce resource, increasing queue length and variability for standard cold orders. Expect higher time-at-capacity, more overtakes, and longer tails of waiting for standard cold orders during express arrival bursts.
- Batching x Hazardous cap:
  - If many hazardous orders to the same region are processed, the hazard cap throttles Packing/QC throughput, prolonging completion times and delaying batch readiness. This increases batch dwell times for that region and can push batch release past dispatch cut-offs.
- Express x Hazardous cap:
  - Express hazardous orders consume tokens in the cap-limited set. Prioritizing them can starve standard hazardous orders, causing alternating bursts and idle patches (inefficient token turnover).
- Cold-Packing x Batching:
  - Prolonged cold-packing queues delay downstream QC and therefore postpone batch readiness for regions with a high share of cold orders. Regions with interdependent SKUs may repeatedly incur batch wait due to upstream cold capacity bottlenecks.
- Priority preemption x Setup/handling overhead:
  - Frequent preemption introduces changeover or rework time, effectively reducing net capacity of stations, which feeds back into longer queues everywhere.

Why this matters
- Optimization must be global. A local policy (e.g., always preempt for express) may reduce express lead time but inflate standard cycle-time variance and degrade overall throughput. Understanding interaction effects helps set guardrails (e.g., only preempt when predicted tardiness risk crosses a threshold) and coordinate caps (e.g., accelerate QC for hazardous to free tokens faster).

Section 3 — Constraint-aware optimization strategies

Strategy 1: Dynamic, prediction-based admission control for scarce resources (cold-packing) with controlled preemption
- Constraints addressed: Shared Cold-Packing, Priority Handling; indirectly eases Batching and Hazard cap impacts by smoothing flow.
- Changes proposed:
  - Implement a priority queue for cold-packing with dynamic priority scores per order computed at ready time: score = predicted tardiness risk within SLA window, considering order type (express/standard), remaining route cut-offs, downstream batch schedules, and current queues.
  - Allow preemption only at safe interruption points (e.g., end of a subtask or sealing phase) and only if the express order’s predicted lateness exceeds a threshold (e.g., risk > 70%). Otherwise, keep non-preemptive priority.
  - Reserve 1 of 5 cold stations as an “express lane” during peak windows if the forecasted express cold demand exceeds a threshold; release the lane when express inflow drops below threshold to avoid underutilization.
- Data/analysis leverage:
  - Train a time-to-due-date risk model using historical logs (features: order type, region, time-of-day, current WIP, station utilizations, hazard tokens usage, expected route departure times).
  - Queue mining to estimate service and interarrival distributions and to forecast queue lengths 30–60 minutes ahead.
- Expected outcomes:
  - Reduced cold-packing waiting time for orders actually at risk while minimizing unnecessary preemptions.
  - Lower variance and tails in standard cold-packing waits; higher effective throughput from fewer interruptions.
  - Fewer late express orders with minimal collateral delay.

Strategy 2: Adaptive batch release policy by region using hybrid size–time triggers
- Constraints addressed: Batching; interacts positively with Priority and Hazard cap.
- Changes proposed:
  - Per region, implement a hybrid batching rule: release a batch when it reaches dynamic size S*(t) or at a time cap T*(t), whichever comes first.
  - S*(t) and T*(t) are adjusted hourly based on forecasted arrivals, current QC backlog, hazard-cap pressure, and cut-off times. Example: increase S* when high inbound volume is predicted and hazard cap pressure is low; reduce S* and T* near dispatch cut-offs or when hazard cap slows upstream completions.
  - Introduce micro-batches for express orders: allow immediate label generation for express once QC completes, independent of standard batch, if route/carrier supports it.
  - Optionally decouple label printing from final load formation: generate provisional labels earlier to avoid E2E delays but allow regrouping at dispatch if needed.
- Data/analysis leverage:
  - Historical batch-formation curves by region/time-of-day, predicted QC completion arrivals, and past transportation costs vs consolidation levels.
  - Optimization model that minimizes total cost = time penalty cost (delivery lateness risk) + transport cost (underfilled batches).
- Expected outcomes:
  - Lower batch-wait times without large loss of consolidation benefits, improved on-time departure to carriers, and less variability caused by upstream caps.

Strategy 3: Token-based control loop for the hazardous cap with fast-turnover scheduling
- Constraints addressed: Hazardous concurrent limit; indirectly improves Batching and general flow.
- Changes proposed:
  - Implement an explicit “token bucket” of 10 hazardous slots shared by Packing and QC. Orders can start only if they acquire a token. Release tokens immediately at activity completion.
  - Prioritize hazardous orders that can complete quickly to increase token turnover (Shortest Predicted Processing Time first among hazardous; SPPT). Pair this with a rule to move hazardous orders quickly from Packing to QC (or vice versa) to minimize idle token time.
  - Allocate a dedicated QC lane/time window for hazardous during peak, reducing cross-activity blocking.
  - If an express hazardous order arrives, temporarily raise its priority within token access but cap the maximum continuous time the token is held by express to prevent starvation.
- Data/analysis leverage:
  - Predict processing times for hazardous at Packing/QC; measure token occupancy and time-at-cap to tune scheduling thresholds.
- Expected outcomes:
  - Higher effective throughput for hazardous without breaching the cap, reduced waiting due to the cap, fewer knock-on delays to batch readiness.

Strategy 4: Flexible capacity uplift and conversion during peaks
- Constraints addressed: Cold-Packing capacity, Hazardous throughput.
- Changes proposed:
  - Convert 1–2 standard stations into cold-capable during high cold demand windows (using portable chilling kits and trained staff), based on forecasted demand; revert during off-peak.
  - Cross-train additional staff for hazardous handling to ensure QC/Packing don’t stall due to staffing constraints.
- Data/analysis leverage:
  - Demand forecasting from logs, station utilization profiles, and scenario-based ROI comparing rental/kit cost vs reduction in overtime/late penalties.
- Expected outcomes:
  - Direct reduction in cold-packing queue lengths and time-at-cap; smoother flow to downstream QC and batching.

Strategy 5: Decouple non-bottleneck sub-steps and pre-stage work
- Constraints addressed: Interactions among Cold-Packing, Priority, and Batching.
- Changes proposed:
  - Move preparatory tasks (e.g., packaging material kitting, data validation for labels) before the cold station becomes the critical path. Pre-stage cold-eligible orders so that cold-station time is used only for “cold-critical” touches.
  - Introduce a “ready-to-cold-pack” buffer where all prerequisites are done; prioritize the buffer strictly by the dynamic priority score (from Strategy 1), minimizing station idle time and non-value-added handling during preemptions.
- Data/analysis leverage:
  - Time and motion analysis from the log (activity granularity) and measured handling times; identify sub-steps that can be shifted upstream.
- Expected outcomes:
  - Shorter processing times at the bottleneck, fewer preemption penalties, and improved overall throughput.

Section 4 — Simulation and validation

Simulation approach
- Use a discrete-event simulation (DES) calibrated from the event log (via process mining) to test each strategy safely.
- Model components:
  - Arrival processes: fit interarrival time distributions by segment (express/standard, region, cold/hazardous) by time-of-day/day-of-week. Include peak season profiles.
  - Service time distributions: fit per activity and segment (e.g., Packing: cold vs standard; QC: hazardous vs non-hazardous). Include setup/interrupt penalties where relevant.
  - Resources and calendars: define station capacities (5 cold, N standard), staff shift calendars, and skill matrices (hazard-capable QC staff).
  - Priority and preemption logic: implement dynamic priority scores and preemption thresholds. Include changeover loss when preemptions occur.
  - Hazardous concurrency cap: implement a token bucket of size 10 spanning Packing and QC.
  - Batching: implement per-region hybrid batch release rules (Strategy 2), with express micro-batches.
  - Material handling/travel: include average transport/staging times where relevant to avoid overstating resource delays.
- Validation and calibration:
  - Back-test the baseline model: verify that simulated KPIs (cycle times, queue lengths, utilizations, time-at-cap, batch dwell times) match historical distributions and percentiles.
  - Sensitivity analysis: vary arrival surges, resource downtime, and compliance checks to ensure robustness.

KPIs to compare across scenarios
- End-to-end lead time and its tail percentiles (P50/P90/P95) for express and standard.
- On-time delivery rate by order type and region.
- Resource utilizations and time-at-capacity (cold stations), queue length distributions.
- Hazardous token occupancy, time-at-cap, and hazardous wait time.
- Batch metrics: dwell times, size, release punctuality relative to carrier cut-offs.
- Preemption metrics: frequency, added overhead minutes, impact on standard orders.
- Throughput and WIP.

Experiment design
- A/B compare baseline vs each strategy; then test combined strategies (e.g., 1+2+3) to capture interaction gains.
- Optimize thresholds (e.g., express lane activation, batch size/time caps, preemption risk threshold) using simulation-based optimization to meet service targets at minimal cost.

Section 5 — Monitoring post-implementation

Dashboards and metrics to sustain control
- Cold-Packing control panel:
  - Real-time queue length and predicted wait for cold orders (express and standard).
  - Station utilization and time-at-capacity; express lane occupancy when enabled.
  - Overtake rate and preemption count; interruption overhead minutes.
  - SLA risk alerts when predicted wait exceeds thresholds.
- Batching performance by region:
  - Batch dwell time (first-ready to release) distributions and P90/P95.
  - Batch size vs time-to-release curves; % batches released after cut-off.
  - Share of orders on micro-batches (express) and their on-time rate.
- Hazardous cap monitor:
  - Live hazardous concurrency H(t) and token occupancy; time-at-cap trend.
  - Hazardous wait time decomposition (cap vs capacity vs other).
  - Compliance violations (should be zero) and near-breach alerts (e.g., H(t)  9 for >X minutes).
- Priority impact tracking:
  - Express cycle time and on-time delivery rate.
  - Displacement cost to standard orders during windows with express arrivals (delta waiting vs matched control windows).
- Global KPIs:
  - End-to-end lead time by order type/region, throughput, WIP.
  - Queue-based early warning: predicted 60–90 minute congestion at cold-packing or QC.
  - Cost-to-serve proxies: overtime, rework, changeover minutes.

Operationalizing continuous improvement
- Daily review of exceptions: top 10 periods by batch dwell, time-at-cap for hazardous, and cold-station queues; root-cause flags from waiting attribution.
- Weekly recalibration:
  - Refit prediction models and update thresholds for dynamic batching and priority admission.
  - Evaluate ROI of temporary capacity conversions used during the week.
- Compliance guardrails:
  - Hard stop automation when hazardous token cap is reached; automated evidence logs for audits.
  - Alert rules tied to preemption frequency or overhead exceeding bounds, triggering policy clampdowns.

Closing note
By explicitly measuring and attributing waiting to instance-spanning constraints, modeling their interactions, and validating targeted interventions via simulation, the fulfillment center can reduce end-to-end times, stabilize flow under peak loads, and maintain regulatory compliance—without over-allocating costly capacity. The combination of dynamic priority admission, adaptive batching, and token-based cap management provides coordinated control over the most critical cross-instance dependencies in this process.