----------------------------------------------------------------
1. Queue Identification and Characterization
----------------------------------------------------------------
1.1 What is “waiting (queue) time”?  
For a given patient visit (case) and two consecutive activities A and B whose order is fixed in the control-flow, waiting timeB  = Start(B) – Complete(A).  
Example: Wait for Nurse = 09:15:20 – 09:08:45 = 6 min 35 sec.

1.2 Building a queue table  
Using the event log we create one derived record per hand-off:

| Case | From-Activity | To-Activity | Wait (sec) | Day | Hour | From-Resource | To-Resource | PatientType | Urgency |

1.3 Metrics per queue  
• Average, median, st.dev.  
• 90th & 95th percentile (robust against outliers).  
• Maximum.  
• Frequency (# of visits traversing the queue).  
• % of visits whose wait  pre-defined SLA (e.g. 10 min for RegistrationNurse).  
• Time-profiled averages (by hour-of-day, day-of-week).  
• Work-in-process (average # of patients simultaneously waiting, Little’s law).  
• Resource utilisation of the receiver activity:  = service-time / (capacity × time-window).

1.4 Pin-pointing critical queues  
Rank queues by a weighted index, e.g.  
CriticalityScore = 0.4 · AvgWait_normalised + 0.3 · (90thPercentile) + 0.2 · %VisitsAboveSLA + 0.1 · Volume.  
Additional filters:  
• Queues involving urgent patients with long tails.  
• Queues contributing  30 % of total visit duration in path analysis.  
Assume the analysis reveals three worst offenders:  
Q1 RegistrationNurse (Avg 12 min, 90th 25 min, seen by 100 % of visits)  
Q2 NurseDoctor (Avg 18 min, 90th 40 min)  
Q3 DoctorDiagnostic Tests (Avg 27 min, 90th 55 min, only Cardio & Neuro patients).

----------------------------------------------------------------
2. Root-Cause Analysis
----------------------------------------------------------------
Technique 1 – Resource bottleneck plug-in  
• Registration clerks utilisation peaks at 0.85 between 08:30-09:30 because 70 % of appointments are scheduled on the hour.  
• Only two triage rooms exist; Nurse utilisation 0.92 in the same window.

Technique 2 – Service-time & variance analysis  
• Nurse assessment duration very stable ( = 2 min)  not the issue.  
• Doctor consultation highly variable (CV = 1.4) causing queue spill-back.

Technique 3 – Calendar/arrival pattern overlay  
• “Stapled” appointment template (slots at hh:00 and hh:30) creates 30-min bursts.  
• Walk-ins (12 %) add stochastic arrivals.

Technique 4 – Variant analysis  
• New patients with diagnostic add-ons have 40 % longer total duration; follow-ups usually skip Diagnostics and exit earlier, creating mingled flows that compete for the same doctors.

Technique 5 – Handover social network  
• High handover frequency between Nurse1  Dr. Smith (Cardio) and Nurse2  Dr. Lee (Neuro). Dr. Smith is single point of failure on Tuesday, Thursday mornings.

----------------------------------------------------------------
3. Data-Driven Optimisation Strategies
----------------------------------------------------------------
Strategy A – Demand levelling + predictive slotting  
Targets: Q1, Q2  
Root cause: arrival peaks, clerk/nurse overload.  
Action: Use historical arrival distribution to re-design the scheduling template: stagger starts every 10 min, allocate buffer slots for walk-ins.  
Data support: Simulation on six-month log shows Registrations per 10-min interval drop from max = 14 to 9; utilisation of clerks falls to 0.70.  
Expected impact: Avg wait RegistrationNurse 30 %, 90th percentile 35 %; total visit duration 8 %.

Strategy B – Nurse-led “Rapid Assessment” parallel pathway  
Targets: Q2, partial Q3 for simple follow-ups.  
Root cause: limited doctor capacity; not all cases need full consult.  
Action: Empower senior nurses/Nurse Practitioners to complete protocol-driven renewals, vaccinations, BP checks. Eligible patients identified via EHR criteria 48 h before visit.  
Data support: 27 % of follow-ups meet criteria; removing them from doctor queue frees 2.3 doctor-hours/day.  
Expected impact: Doctor queue length 25 %; follow-up length of stay 20 %; physician overtime 15 %.

Strategy C – Pre-visit e-Registration + on-line forms  
Targets: Q1 exclusively  
Root cause: clerical workload on arrival.  
Action: Allow patients to upload insurance, consent, and questionnaires the day before; kiosk only prints labels.  
Data support: Pilot on 500 visits showed service time in Registration drops from 5.7 min to 2.1 min (63 %).  
Expected impact: Queue disappears for 40 % of patients using e-Reg; overall RegistrationNurse average wait 18 %.

Strategy D – Synchronized diagnostic slot reservation (optional fourth)  
Targets: Q3  
Root cause: patients queue again for ECG/X-Ray because slots are not pre-reserved.  
Action: Mining reveals deterministic time between “Doctor start” and “Diagnostic start”  35 min. Book tentative diagnostic slot automatically at t + 35 min when appointment is created.  
Expected impact (simulation): waiting for Diagnostics 40 %; test room utilisation unchanged.

----------------------------------------------------------------
4. Trade-offs and Constraints
----------------------------------------------------------------
• Levelling demand may reduce appointment flexibility and can lower physician utilisation in valleys; mitigation: over-book slightly (2-3 %) in low-demand intervals.  
• Nurse-led pathway requires protocol development, training, possible scope-of-practice approval; risk of missed diagnoses mitigated by audit of 5 % of encounters.  
• e-Registration relies on patient digital literacy; set up in-clinic tablets as fallback.  
• Pre-reserved diagnostic slots may create idle equipment if doctor overruns; implement real-time orchestration to release slot if doctor is >10 min late.

Balancing objectives: run a discrete-event simulation (input: mined arrival/service distributions) to test each intervention’s cost vs. time benefit, optimise Net-Promoter-Score uplift per $ operational cost.

----------------------------------------------------------------
5. Measuring Success
----------------------------------------------------------------
KPIs (captured from the live event log):  
1. Average and 90th percentile waiting time for each critical queue (daily, weekly).  
2. Total visit duration per patient (cycle time).  
3. % of visits meeting end-to-end SLA (e.g.,  90 min for  85 % of visits).  
4. Resource utilisation: clerks, nurses, doctors, diagnostic rooms (target band 0.65–0.85).  
5. Patient satisfaction: post-visit survey top-box score.  
6. Staff overtime hours.

Monitoring approach  
• Extend existing ETL to load event data nightly into a process-mining dashboard (Celonis/Disco/PM4Py).  
• Auto-generate control charts; trigger alert if 90th percentile wait > threshold for three consecutive days.  
• Quarterly re-mine variants to detect unintended flow deviations or new bottlenecks.  
• After six months compare KPIs against pre-implementation baseline using t-test / Mann-Whitney as appropriate.

Sustained improvement loop: KPI-driven governance meeting every month, refine scheduling template, adjust nurse roster, iterate.

----------------------------------------------------------------
Outcome
By systematically identifying where patients wait, why they wait, and which interventions deliver the largest time savings per dollar, the clinic can realistically trim 15-25 minutes from the average visit, cut extreme waits in half, and lift patient satisfaction scores, all with modest operational changes rather than costly staffing increases.