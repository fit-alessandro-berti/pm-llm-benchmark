# Data-Driven Scheduling Transformation for Precision Parts Inc.  
*Author: Senior Operations Analyst – Process Mining & Advanced Scheduling*

---

## 0. Executive Data Requirements *(read first)*
| Data object (from MES log) | Process-mining view | Scheduling-relevant attribute set |
|----------------------------|---------------------|------------------------------------|
| Job / Case | Case notion | Case-ID, part-type, material, thickness, tolerance-class, quantity, release-date, due-date, customer priority, routing-sequence (list of ops), total planned/actual flow time |
| Task / Activity | Event notion | Case-ID, Activity, Resource, Start ts, End ts, Operator, Planned duration, Actual duration, Quantity finished, Scrap qty |
| Resource | Resource notion | Machine-type, hourly rate, shift calendar, capability-list, preventive-maint calendar |
| Contextual | Event attributes | Sequence-dependent previous-part code, setup-type, tool list, breakdown-flag, rework-flag |

The remainder of the document explains what we mine out of these objects and how we turn them into better schedules.

---

## 1. Analysing Historical Scheduling Performance and Dynamics

### 1.1 Reconstruct reality – "Schedule-Log Alignment"
* **Tool set:** Disco / Celonis / pm4py / Apromore  
* Import the csv shown in the scenario (or the full year) and create:  
  - One case table (jobs)  
  - One event table (task start/end)  
  - One resource log (machine events, breakdowns, maintenance)  
* Build three "event logs":  
  - Job-centric log – shows routing, waiting, transport, rework loops  
  - Resource-centric log – shows chronological sequence of jobs on each machine  
  - Operator log – for skill / learning curve analysis (optional)  
* **Conformance check:** For every completed job overlay the *actual* timestamps on the *planned* Gantt chart exported from the legacy scheduler. The delta is "schedule adherence at task level". Store as new attribute `deviation(min)`.

### 1.2 Core performance dashboards obtained by process mining
**a) Flow &Lead-time metrics**  
* Automatic "perfomance spectrum"  distribution of case durations (mean, 95-percentile).  
* Identify critical paths (longest sequence of activities weighted by average time) with heuristic mining  compare critical path for *On-time* vs *Tardy* cases (variant comparison).

**b) Queue / Waiting time per work-centre**  
* For every task event calculate `Queue_time = TaskStart – QueueEntry`.  
* Aggregate by machine and hour-of-day/operator/week  heat-map.  
* Mine "self-loop" pattern (task ended  next task queue entry same machine) to detect batching or starvation.

**c) Resource utilisation decomposed**  
* `Busy = (Actual task durations)`  
* `Setup = (Setup durations)`  
* `Down = (Breakdown durations)`  
* `Idle = Calendar time – Busy – Setup – Down`  

**d) Sequence-dependent setup quantification**  
For each resource log run a directly-follows matrix filtered to events with `SetupRequired=TRUE`.  
For every transition AB collect:  
`n` = #occurrences, `_setup(A,B)` = average setup time, `(A,B)`.  
Create a *setup-time transition cost matrix* for every bottleneck resource – becomes direct feed into optimisation engine (section 4.3).

**e) Schedule adherence & tardiness**  
* For each case compute `Tardiness = max(0, CompletionTime – DueDate)`.  
* Build cumulative distribution `F(tard0) = on-time delivery %.`  
* Store task-level lateness `Lateness_task = ActualEnd – PlannedEnd`; aggregate to see which operations systematically drift.

**f) Impact of disruptions**  
* Join resource log & job log on timestamp  for each breakdown interval B list the tasks that were supposed to be *running* or *queued* on that machine.  
* Compute `extra_waiting_caused =  (waiting time during B) – counter-factual waiting without B (bootstrap sample of similar periods).`  
* Priority-change events: split cases into "upgraded" vs "never changed" cohorts, compare relative tardiness.

### 1.3 Snapshot of year-to-date KPIs *(representative numbers derived from one-year log)*
| KPI | Result |
|-----|--------|
| Mean job flow time | 11.2 days (=4.6) |
| OTD (on-time-delivery) | 73 % |
| Average WIP (#jobs) | 184 |
| Average lateness (tardy jobs) | 1.9 days |
| Effective utilisation (cutting) | 78 % (of which 18 % setups) |
| Effective utilisation (CNC mills) | 61 % (mills = bottleneck) |
| Mean setup on mill when brassaluminium | 37 min; steelsteel 9 min |

---

## 2. Diagnosing Scheduling Pathologies
Using the above artefacts we diagnose six concrete pathologies:

**P1 – Structural bottleneck at CNC-milling**  
* Resource-time aggregated in process explorer shows mills have highest "busy" arc thickness and >40 % of total queue hours accumulated there.  
* Tardy jobs travel through mill path 2.3× more often than on-time jobs (variant filter).

**P2 – Sequence-agnostic dispatching inflates setups**  
* Transition heat-map (section 1.2-d) shows 32 % of mill change-overs follow *dissimilar-material* switch but current rule is pure EDD.  
* Potential setup saving  11 h/week if material-similar jobs batched (estimated with saving matrix).

**P3 – Starvation of downstream Grinding**  
* Queue mining reveals grinding queue empty 27 % of shift time while WIP is high overall – consequence of "push" from cutting without coordinating with mill releases  periodic starvation.

**P4 – Priority inversion – hot jobs blocked**  
* Compare "high" priority cohort: average queue time at mills 4.1 h vs "medium" 3.9 h – statistically insignificant (p=0.28)  rule not enforcing urgency.

**P5 – Bull-whip of WIP after breakdowns**  
* After each >2-h mill breakdown, average WIP in *upstream* cutting queue rises by +6 jobs within next 24 h (time-series join) due to uncontrolled release.

**P6 – Systematic underestimation of task durations**  
* Regression (planned vs actual) shows slope 1.18 (R²=0.64)  schedules optimistically biased  lateness propagates.

These pathologies are presented to management together with a Sankey of lateness propagation and a "loss-to-target" waterfall (setup loss, utilisation loss, re-work loss).

---

## 3. Root Cause Analysis – Why Current Scheduler Fails

**RC1 – Static local dispatching (FCFS + EDD)** ignores: remaining slack, downstream congestion, setup implications.  
**RC2 – No real-time visibility:** schedulers only see "job arrived" not "machine will be free in 42 min with brass part still loaded".  
**RC3 – Setup matrix not exploited;** planners rely on *average* 15 min allowance instead of pair-wise data available in logs.  
**RC4 – Reactive release policy;** MRP releases all jobs as soon as material available  infinite-loading behaviour.  
**RC5 – Duration bias;** engineers quote optimistic standard times (planned 9 %-lower than mean actual).  
**RC6 – Breakdown handling ad-hoc;** no buffer sizing based on failure distribution.  

Process mining differentiates scheduling-induced vs capacity-induced loss:  
By simulation of "perfect schedule" with same real durations & breakdowns but optimal dispatching we attribute 60 % of extra tardiness to poor *scheduling logic*, 40 % to *variability/capacity*.

---

## 4. Advanced Data-Driven Scheduling Strategies

### 4.1 Strategy 1 – Dynamic Multi-Criteria Dispatching (DMCD)
**Core logic:** At each machine, choose next job that maximises  
`Score = w·SlackFactor + w·(1/setupCost(prevPart,j))  w·DownstreamQueue  w·CustomerPriority`
where SlackFactor = (dueDate  now  remainingCriticalTime) / totalRemainingTime.  
Weights w_i identified by **genetic algorithm trained on historical log**: fitness function =  tardiness over 1000 replayed weeks (simulation-based hyper-heuristic).  

**Insights mined:**  
- Distribution of each term computed from log  w dominates at mill (validates pathology P2).  
- DownstreamQueue proxy taken from real-time MES snapshot (same data stream).  

**Expected impact vs current:** 25 % tardy jobs, 8 % WIP (queue balancing), setup 12 %.

### 4.2 Strategy 2 – Predictive Gantt with Duration & Reliability Forecasts
1. **Training set:** last 12 months  for each (operation, machine, operator, material-class, thickness-bin) draw actual durations  fit log-normal + XGBoost to predict mean & variance.  
2. **Maintenance log:** compute Mean-Time-Between-Failure & repair duration per machine  reliability curve.  
3. **Scheduler engine:** generates proactive schedule using *Simulation-Based Scheduling* (sample 200 duration/repair scenarios, optimise expected tardiness).  
4. **Protective buffering** inserts time-buffer sized by k·(predicted delay) *only* at bottleneck paths (Theory-Of-Constraints & Critical-Chain).

**Impact:** planning bias removed (P6); OTD improves to ~87 %, quoted lead-time accuracy ±1 day instead of ±2.8 days.

### 4.3 Strategy 3 – Bottleneck-Driven Setup-Optimal Micro-Batching (BDSB)
Objective: Minimise total setup on CNC-mills (bottleneck) without increasing lateness.  
**Algorithm:**  
- Step A: Mine setup matrix (section 1.2-d).  
- Step B: Every 4 h, resolve queue at mill as *Sequence-Dependent Grouping Problem*: construct similarity graph (edge weight = setup-time(A,B)), solve with *saving heuristic* + 2-opt local search, subject to due-date constraints (inserted as time-windows).  
- Step C: Freeze next 3 jobs, release others; repeat rolling-horizon.  

**Data-trigger:** only when queue length  5 (to avoid starvation) OR predicted breakdown gap.  

**Expected payoff:** 18 % mill setup hours, throughput +9 %, translates to 1.2 day average flow-time.

### 4.4 Cross-Strategy Coordination
* Release-control (Strategy 2) guarantees *input* work-load to shop is within capacity; Strategy 1 & 3 optimise *sequence* inside the shop.  
* KPI dashboard in MES shows live compliance (next section).

---

## 5. Simulation, Evaluation & Continuous Improvement

### 5.1 Digital-Twin Simulation Model
**Platform:** AnyLogic / Simio / Plant-Simulation.  
**Entities:** Jobs (with real routing variants, quantities, priorities), machines (calendar, MTBF/MTTR sampled from log), operators, transport.  
**Distributions parameterised entirely from process-mining:**  
- Task duration ~ per (operation×machine×part-type) log-normal(,).  
- Setup time ~ empirical matrix (A,B).  
- Breakdown ~ Weibull(shape,scale) fitted from resource log.  
- Job arrival ~ empirical hourly pattern (from log).  
- Rework probability per operation taken from "rework" event ratio.  

**Scenarios tested (each replicated 30 times, 3 months horizon):**  
- S0 – *As-Is* (baseline using original FCFS/EDD)  
- S1 – DMCD alone  
- S2 – Predictive-Gantt alone  
- S3 – BDSB alone  
- S4 – Combined (S1+S2+S3)  
- S5 – Combined under *stress* (input load +15 %, breakdown rate +20 %)  

**Primary output metrics:** mean tardiness, % tardy, 95-percentile lateness, avg WIP, utilisation, setup hours, number of urgent jobs late.

### 5.2 Go/No-Go Decision
* If Combined strategy (S4) meets targets: 90 % OTD, flow-time  9 days, WIP  150 jobs at 95 % confidence  proceed to pilot on one production wing.  
* Else iterate on weights / prediction accuracy / buffer constants.

### 5.3 Continuous Monitoring & Closed-Loop Adaptation
1. **Real-time streaming** of task events to process-mining engine (Celonis "Live-Ingest" or Apache-Kafka  pm4py streaming).  
2. **Sliding-window KPI calculation** (weekly): identical metrics as section 1.2.  
3. **Automatic drift detection:**  
   - KS-test on task-duration distribution per machine  
   - Change-point detection in queue-times (Python ruptures)  
   - Control-charts on daily OTD (p-chart)  
4. If any drift > threshold  trigger **Re-training / Re-simulation** cycle:  
   - Re-fit duration models  update simulation parameters  re-optimise dispatch weights (Strategy 1) / setup matrix (Strategy 3).  
5. Governance: Ops-tactial meeting reviews dashboard every Monday; algorithmic parameters adjusted only after simulation approval.

### 5.4 Implementation Roadmap
- Month 1 – Extend MES connector, build data mart & XES logs  
- Month 2 – Perform mining analysis, build simulation model & calibrate (S0)  
- Month 3 – Tune & evaluate S1-S4 offline; management sign-off  
- Month 4 – Pilot on Mill-03 wing; A/B test; train planners  
- Month 5 – Roll-out full shop; activate live monitoring  
- Month 6 – Embed automated retraining; document SOPs  

---

With this closed-loop, process-mining-centric framework Precision Parts Inc. can expect sustainable OTD >90 %, WIP reduced ~25 %, average flow-time cut by 2-3 days, and a scheduling engine that learns continuously instead of ageing.