Here's a DuckDB SQL query that meets your benchmark requirements:

```sql
WITH ordered_events AS (
  SELECT
    case_id,
    activity,
    timestamp,
    LAG(activity, 1) OVER (PARTITION BY case_id ORDER BY timestamp) AS prev_activity,
    LAG(timestamp, 1) OVER (PARTITION BY case_id ORDER BY timestamp) AS prev_timestamp,
    LAG(activity, 2) OVER (PARTITION BY case_id ORDER BY timestamp) AS prev_prev_activity
  FROM event_log
),
cases_to_filter AS (
  SELECT DISTINCT
    case_id
  FROM ordered_events
  WHERE
    activity = 'Confirm Order'
    AND prev_activity = 'Create Order'
    AND prev_prev_activity = 'Approve Purchase Requisition'
    AND EXTRACT(epoch FROM (timestamp - prev_timestamp)) / (60 * 60 * 24) > 5
)
SELECT e.*
FROM event_log e
WHERE NOT EXISTS (
  SELECT 1
  FROM cases_to_filter f
  WHERE e.case_id = f.case_id
);
```

### Explanation:
- **`ordered_events`**: Uses window functions to look back at the two previous activities and their timestamps within each case.
- **Sequence detection**: Checks for the exact sequence `'Approve Purchase Requisition'  'Create Order'  'Confirm Order'` by comparing current and two lagged activity values.
- **Time condition**: Filters only those sequences where the duration between `'Create Order'` and `'Confirm Order'` exceeds 5 days (converted from epoch seconds to days).
- **Final result**: Excludes *all* events from any case that had such a slow sequence, returning only events from safe cases.

Let me know if you'd like to tweak the time threshold or check for multiple such sequences per case!