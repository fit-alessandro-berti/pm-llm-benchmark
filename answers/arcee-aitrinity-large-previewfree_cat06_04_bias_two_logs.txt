Looking at the two groups, the first thing that jumps out is the role of the CommunityGroup attribute. In Group B, whenever someone is a member of a community group, their score gets a +10 boost before the final decision. That never happens in Group A — there, the score stays exactly as calculated from the start. This means the same numerical score in both groups can lead to very different outcomes: a 720 in Group A is rejected, but a 720 in Group B with a community boost becomes 730 and is approved.

The LocalResident attribute is also unevenly distributed — Group B has it set to TRUE for all cases, while Group A has it FALSE. That means Group B benefits from both the local resident flag and the community boost, while Group A gets neither advantage. These systematic differences in attributes directly translate into different scoring paths and, ultimately, different approval rates.

So the bias isn't in the raw scores themselves, but in the extra adjustments and flags applied only to one group. That extra +10 boost for community group members, combined with the absence of any similar benefit for the other group, creates an uneven playing field where identical initial scores can yield opposite final decisions.