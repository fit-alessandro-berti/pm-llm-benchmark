Precision Parts Inc. – Data-Driven Scheduling Renovation Plan  
==============================================================

0. Executive Mind-set  
The shop’s complexity (sequence-dependent setups, human variability, stochastic breakdowns) is “data rich”. We therefore use the MES history to (1) **measure reality**, (2) **diagnose why the arithmetic fails** (pathologies & root causes), (3) **build predictive or corrective models**, and (4) **close the loop** with simulation and closed-loop monitoring. The ultimate governance loop is:  
Process Mining  Simulation  Deployment  MES feeds  Mining again.

--------------------------------------------------------------------
1. Analyzing Historical Scheduling Performance and Dynamics
--------------------------------------------------------------------
1.1 Log Reconstruction  
• Parser converts the event log into an **object-centric event log** (OCEL) with two objects: `Job`, `Machine`; operators are treated as attributes.  
• Split the log into “Trace views”:  
  – *job trace*: sequential operations per job with timestamps, machine, queue->execution transitions.  
  – *machine-centric trace*: ordered job finishes on each machine (basis for setup-time reconstruction).  

1.2 Process Mining Modules & Metrics  
| Technique | Purpose on Job View | Primary Calculation | How |  
|---|---|---|---|  
| **Performance Spectrum / Lead-time scatterplot** | Job flow time distribution, makespan |  release-to-completion of each job | Add start and end events, compute  |  
| **Event logs projected to “Queue Entry  Queue Exit”** | Task waiting times per machine | wait_i = (TaskStart – QueueEntry) | Aggregated to mean / p95 per `Resource` |  
| **Resource utilisation log** | Machine and Operator utilisation | ActiveTime/(InShift-Time) | Enrich events with shift calendar |  
| **Setup reconstruction** (machine trace) | Sequence-dep-setup time | SetupDuration_i as function of previous job-coding (material family, tooling family, change-over type) | Match “SetupStart/End” events, history feature: feature(Fi,Fi-1)  regression tree |  
| **Conformance check** vs. idealised reference model (e.g., DC/Gantt schedule snapshot) | Due date deviation | Tardiness=max(0,Completion-DueDate) | Align actual job finish with due date timeline |  
| **Disruption fault tree** | Breakdown/Priority change impact | T (average extension per affected descendant) | Temporary resource unavailable events mapped to impacted successor jobs using case-id correlation |

1.3 Visual Key Artefacts  
• S-curve of flow-time vs. WIP (Little’s Law validation)  
• Resource gantt heat-map idle/setup/processing/idle-blocked/breakdown  
• Setup clustering heat-map by family-to-family transition cost matrix

-----------------------------------------------------------
2. Diagnosing Scheduling Pathologies
-----------------------------------------------------------
Use mined data + exploratory patterns:

| Pathology | Evidence from Mining | Typical Query |  
|---|---|---|  
| Bottleneck overload | Heavy light-blue bars (“busy”), longest queue tails | Average waiting time cut>0.3×total flow time (+cycle-time stacking chart) |  
| EDD starvation | Discovered precedence graph shows low-priority sequenced ahead of critical yield; compare on-time vs late traces via variant analysis | Pattern: if EDD index < 2 days and job waiting >6 h  always late |  
| Setup amplification | Setup heat-map shows 40 % additional calendar loss on MILL-03 family changes without family sequencing | Per-family transition KL-divergence vs. random order |  
| Starvation downstream | Detected zero-buffer time on several grinding cells  27 % idle cycles | Idle blocked event ratio >15 % |  
| Disruption magnification | Variance elasticity; compute modified flow time regression after breakdown (T = 8.3 × downtime on CNC cluster) | Level 2 path-diff conformance constructs changed traces post disruption |

-----------------------------------------------------------
3. Root-Cause Diagnosis
-----------------------------------------------------------
Tooling framework:

• **Process mining metrics “ taxonomy”**  
  – Descriptive (spectrum, avg.)  
  – Conformance (actual vs. dispatch rule foot-prints)  
  – Variant analysis (successful vs. delayed path segments)

