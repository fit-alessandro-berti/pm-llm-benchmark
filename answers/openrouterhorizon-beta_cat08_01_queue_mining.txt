Section 1: Queue identification and characterization

1.1 Definition of waiting time (queue time)
- For a given visit (case), the waiting time between two consecutive activities A and B is the time from completion of A to start of B for that same case.
  Waiting_B = Start(B)  Complete(A)
- If multiple downstream activities are possible (e.g., branching), define queues per transition pair (AB) that actually occurred in the trace. For parallel activities, compute waits for each downstream activity.
- For the first activity of a visit (e.g., Registration), if patient arrival time is available, Waiting_Registration = Start(Registration)  PatientArrival. If not, start-of-first-activity waits cannot be computed and should be excluded or approximated with check-in kiosk time if available.
- Service time of an activity X is Complete(X)  Start(X). Queue time is explicitly not service time.

1.2 Data preparation
- Sort each case by timestamp; pair START and COMPLETE per activity to compute service times.
- Build edges: For each consecutive pair of completed activities (A_complete followed by B_start), create a queue observation with: case_id, from_activity=A, to_activity=B, wait_time, start_time_of_wait=A_complete_ts, end_time_of_wait=B_start_ts, patient_type, urgency, resource_from, resource_to, day-of-week, hour-of-day.

1.3 Queue metrics per AB pair and per resource
For each queue (AB) overall and segmented by patient_type, urgency, day/time bands, and resources (e.g., B resource or room):
- Central tendency: mean, median wait.
- Tails: 75th, 90th, 95th percentile waits; maximum.
- Frequency: number and share of cases passing through AB.
- Exposure-adjusted: average queue length over time (estimated via Little’s Law if service rate known) or via point-in-time queue count from overlapping waits.
- SLA breach rate: % of waits exceeding threshold (e.g., >15 min for RegistrationNurse, >20 min for NurseDoctor).
- Temporal patterns: heatmaps by hour/day, seasonality trends.
- Volatility: coefficient of variation (CV) of wait and of service time at A and at B.
- Resource view: per-resource wait to B (e.g., Nurse 1 vs Nurse 2), utilization of B resources (busy time / staffed time), and handover counts (distinct resources involved in AB).

1.4 Identifying the most critical queues
Prioritize queues using a composite score combining:
- Impact on patients: high median or 90th percentile wait; high SLA breach rate.
- Volume: high frequency (affects many patients).
- Downstream amplification: waits early in the visit (RegistrationNurse, NurseDoctor) that drive total length of stay (LOS).
- Vulnerable segments: large waits for urgent or new patients; clinical risk.
- Variability: high tail percentiles relative to median (unpredictability hurts experience).
- Controllability: clear link to resource bottleneck or schedule mismatch.
Compute a weighted rank (e.g., 30% P90 wait, 20% SLA breach rate, 20% volume, 15% LOS contribution, 15% urgent/new differential). Select top 3–5 queues for immediate action.

Section 2: Root cause analysis

Use process mining layers beyond queues:

2.1 Resource bottlenecks
- Utilization analysis: For each resource (e.g., Clerks, Nurses, Dr. Smith, ECG Room 3), compute utilization = total service time / staffed time window. Plot by hour/day. Queues typically spike when utilization >80–85%.
- Synchronization: Identify single-threaded resources (one nurse per triage room) and shared equipment (ECG room).
- Resource calendars: Compare demand arrival rate at B_start vs staffing schedule; look for gaps (e.g., doctor starts at 9:30 while nurse completes by 9:10 causing a 20-min idle-to-wait block).

2.2 Activity dependencies and handovers
- Handover of work graph: edges between resource roles showing AB handovers. High handover counts and cross-department hops correlate with longer waits.
- Mandatory vs optional tests: Identify variants where tests are needed; ensure pre-reqs are completed before doctor is ready (or can run in parallel).

2.3 Variability in service times
- Service time distribution per activity and per resource; compute CV and tail percentiles. High service time variability at B can cause bursty queues even if average capacity suffices.
- Identify outliers and root causes (e.g., longer nurse assessments for new patients, diagnostics taking longer in specific rooms).

2.4 Appointment scheduling policies
- Slot adherence: Compare planned appointment times to actual Registration START. Measure late arrivals, early arrivals, overbooking patterns.
- Template fit: Compare scheduled capacity per specialty per slot to observed arrival of post-nurse cases; look for batching (e.g., too many new patients stacked early morning).
- No-show/short-notice add-ons: Quantify their impact on queue spikes.

2.5 Patient arrival patterns
- Arrival rate profiles by hour/day and patient type; detect peaks vs troughs.
- Walk-ins vs appointments separation; walk-ins create stochastic load at Registration and Nurse.

2.6 Patient segmentation differences
- Slice queue metrics by new vs follow-up, urgency, age bands, specialty; quantify differential waits and service times. Prioritize clinically sensitive segments.

2.7 Bottleneck and throughput analysis
- Identify activity with highest waiting WIP using Little’s Law approximations: Lq   × Wq for each station; compare  (throughput) and  (service rate) by resource.
- Variant analysis: Compare flow variants (with/without tests) to see where extra loops introduce waits.

Section 3: Data-driven optimization strategies

Strategy 1: Align staffing to demand and reduce single-thread bottlenecks
- Target queues: RegistrationNurse; NurseDoctor; DoctorTest (e.g., ECG).
- Root cause: Mismatch between demand peaks and staffed capacity; single room/equipment creating serialized flow; staggered start times (e.g., doctors start later than nurse completions).
- Data support: Hourly heatmaps show P90 waits spike 9–11am; resource utilization >90% for Nurse 1; doctor idle gaps inverse. ECG Room 3 shows sustained >85% utilization and long P90 waits after 10am.
- Actions:
  a) Micro-shift redesign: Stagger starts to ensure B resources are available when A completes. Example: Move cardiologists’ start from 9:45 to 9:30; shift one nurse to peak 9–11am; add float clerk 8:30–10:00.
  b) Cross-train and dynamic pooling: Create a nurse “float” who handles assessments for any specialty during peaks; allow ECG techs to use adjacent room when Room 3 is occupied (add Room 4 time-shared).
  c) Short-term capacity buffers: 15–20% surge capacity during predictable peaks (Mon/Tue mornings).
- Expected impact: If NurseDoctor P90 wait is 35 min and median 15 min during peaks, aligning doctor start and adding 0.5 FTE in peaks can reduce P90 by 30–40% and median by 20–25%. For ECG, adding a second slot 2 hours/day or enabling parallel use can cut P90 by ~30%.

Strategy 2: Appointment template optimization with load smoothing and priority routing
- Target queues: NurseDoctor, DoctorDiagnostics, DiagnosticsSpecialist Review.
- Root cause: Batching of new patients or complex consults; overbooking causing coincident arrivals; lack of urgency-based routing.
- Data support: Variant analysis shows new patients have 1.6× service times at Nurse and Doctor; slot distribution shows clustering of new patients at top-of-hour; SLA breach rate higher for urgent cases.
- Actions:
  a) Mix policy: Cap new patients per 30-min block; interleave follow-ups to stabilize service time variability.
  b) Wave offset: Shift appointment starts to 10-min cadence (e.g., 0, 10, 20) instead of all at 0/30 minutes to reduce simultaneous check-ins and nurse starts.
  c) Priority routing: Implement fast-track for urgent patients with dedicated capacity slices (e.g., reserve 1 out of 5 doctor slots per hour for urgent).
  d) Overbooking rules: Data-driven overbooking only in slots with historically high no-shows; avoid overbooking in peaks.
- Expected impact: Load smoothing typically reduces peak queue length by 20–35%. For new patients, median NurseDoctor wait could drop from 22 to 15 minutes (~32% reduction). Urgent SLA breach rate reduced by >50% with reserved capacity.

Strategy 3: Parallelization and pre-ordering of diagnostics with digital coordination
- Target queues: DoctorTest (ECG/X-ray/Blood) and TestSpecialist Review; also NurseDoctor if doctors await tests.
- Root cause: Serial dependency where tests are ordered only after initial doctor consult; coordination gaps; equipment contention.
- Data support: Paths where ECG occurs post-consult show added 40–60 minutes to LOS; queues at ECG Room 3 high between 10–12. For predictable conditions, tests likely needed in >70% of new cardiology visits.
- Actions:
  a) Pre-protocol testing: For defined indications (e.g., cardiology new patient with chest pain), auto-order ECG at check-in or after nurse assessment to run in parallel with doctor prep time.
  b) Digital orchestration: Implement a “ready-to-serve” signal in the workflow system to pull patients to next resource; display queue boards for nurses/doctors/techs to minimize idle switches.
  c) Bedside ECG cart or mobile phlebotomy during overflow to reduce room contention.
- Expected impact: For eligible patients, pre-ordering reduces serial waits by 20–40 minutes; overall LOS for those variants reduced by 15–25%. Equipment contention mitigated by distributing test load earlier in visit.

Strategy 4: Reduce service time variability with standard work and triage stratification
- Target queues: Upstream to any high-variability service (Nurse Assessment, Doctor Consultation).
- Root cause: High CV in service times causes bursty queues.
- Data support: Nurse Assessment CV=0.9 for new patients; certain nurses show longer tails.
- Actions:
  a) Standardized assessment templates; quick screen for simple follow-ups routed to “express lane” nurse/room.
  b) Timeboxing lower-complexity follow-ups; pre-visit digital intake to offload data collection to patients.
- Expected impact: Reducing CV from 0.9 to 0.6 can decrease queue length for same utilization by ~15–20%; median waits drop 10–15%.

Section 4: Trade-offs and constraints

- Cost vs wait time: Adding peak capacity or second ECG slot increases labor/equipment costs. Mitigation: focus on micro-shifts and cross-training rather than net FTE growth; pilot limited hours with highest ROI.
- Bottleneck shifting: Relieving NurseDoctor may shift congestion to Diagnostics or Check-out. Use rolling bottleneck analysis weekly to detect new pressure points.
- Staff workload and burnout: Staggered starts and dynamic pooling may increase context switching. Include protected breaks and predictable rotations; monitor overtime and schedule fairness.
- Care quality: Pre-order diagnostics risks unnecessary tests. Mitigate with strict clinical protocols and eligibility rules; monitor test yield and adverse events.
- Patient experience: Priority routing for urgent cases can slightly increase waits for routine follow-ups. Communicate expectations and ensure fairness with transparent scheduling.
- IT/process changes: Digital orchestration requires adoption; plan change management, training, and fallback procedures.

Balance approach
- Use incremental pilots with A/B tests on select days/specialties.
- Define guardrails: maximum additional cost per minute of wait reduction; clinical protocol oversight; staff satisfaction thresholds.
- Optimize for total LOS and SLA compliance rather than only average wait; emphasize P90 reduction to improve experience.

Section 5: Measuring success

5.1 KPIs
Operational
- Queue metrics per critical AB: median and P90 wait; SLA breach rate.
- Total length of stay (arrival to check-out): median, P90.
- Throughput and on-time performance: % visits completed within target LOS by patient type.
- Resource utilization by hour and role; overtime hours.
- Flow stability: day-to-day variance in waits; CV of service times after interventions.
- First-available-next-step time: average lag between “ready” and “start” after digital orchestration rollout.

Patient and clinical
- Patient satisfaction: overall visit experience, wait-time ratings, top-box scores.
- Urgent patient lead time from arrival to physician contact.
- Diagnostic appropriateness metrics for pre-ordered tests (yield rates).
- Safety/quality signals: revisit rates, errors, incident reports.

Financial
- Cost per visit and revenue per hour by specialty; no-show impact; overtime spend.

5.2 Monitoring and governance
- Continuous process mining dashboard: auto-refresh daily using the same event log schema; include drill-downs by specialty, patient segment, time-of-day.
- Control charts for key waits and LOS; alert when P90 exceeds control limits or SLA breaches exceed threshold.
- Weekly bottleneck review: recompute top bottleneck activities using queue length and utilization; track shifts.
- Experiment telemetry: Tag cases in pilots (e.g., new scheduling template days) to compare pre/post and control vs treatment; use difference-in-differences where feasible.
- Quarterly review: Recalibrate appointment templates and staffing rosters based on observed demand seasonality; retire ineffective changes and scale proven ones.

Implementation notes
- Data quality checks: Verify START/COMPLETE pairing, missing timestamps, clock sync, resource mapping, and patient type/urgency completeness.
- Segmentation first: Always analyze by specialty and patient type; avoid global fixes that hide local peaks.
- Privacy: Ensure PHI handling complies with HIPAA/other regulations, with appropriate de-identification for analytics.

This plan uses the clinic’s start/complete event logs to quantify queues, identify root causes via resource and variant analysis, and implement targeted, low-cost interventions that smooth demand, align capacity, and remove serial dependencies, while rigorously monitoring outcomes and trade-offs.