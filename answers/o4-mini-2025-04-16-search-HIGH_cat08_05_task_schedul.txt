## 1. Analyzing Historical Scheduling Performance and Dynamics

To gain a precise, data-driven understanding of how jobs actually flow through the shop floor, process mining is applied to the MES event log in five key steps:

1. **Event Log Pre-processing and Enrichment**  
   - Clean and unify timestamps, resource IDs, and case IDs; enrich each event with derived attributes (e.g., previous-task, next-task, sequence index).  
   - Convert to an XES or CSV format suitable for process mining tools (e.g., ProM, Celonis, Disco).

2. **Process Discovery and Visualization**  
   - Use a heuristic miner or inductive miner to reconstruct the *actual* process map, revealing all observed sequences of activities and handoffs between resources.  
   - Overlay performance annotations on the discovered model: average task durations, waiting times, frequency of each path.

3. **Key Performance Metrics Extraction**  
   - **Job Flow Times, Lead Times, Makespan**  
     • Compute for each case: end timestamp at final inspection minus release timestamp.  
     • Aggregate into distributions (mean, median, 10th–90th percentile spreads).  
     • Identify extreme outliers and their case variants to understand variability.  
   - **Task Waiting (Queue) Times**  
     • For each task: queue entry time until setup start (or start if no setup).  
     • Aggregate per work center and per job routing; visualize via heatmaps.  
   - **Resource Utilization**  
     • Aggregate each machine’s busy time (actual processing), setup time, and idle time over a rolling horizon.  
     • Compute utilization rate = (processing + setup) ÷ (available calendar time).  
   - **Sequence-Dependent Setup Times**  
     • For each resource, build a transition matrix where rows = previous job family, columns = current.  
     • Aggregate setup durations for each (previouscurrent) pair to estimate mean, variance.  
   - **Schedule Adherence and Tardiness**  
     • For each job: tardiness = max(0, actual completion date  due date).  
     • Compute percent on-time, average tardiness, and tardiness distribution by priority class.  
   - **Impact of Disruptions**  
     • Tag intervals of unplanned breakdown events; compare KPIs (throughput time, WIP level) before, during, and after breakdown windows.  
     • Quantify average delay introduced per breakdown event and estimate opportunity cost in delayed orders.

## 2. Diagnosing Scheduling Pathologies

Using the performance data and the discovered process model, we pinpoint the root scheduling inefficiencies:

1. **Bottleneck Identification**  
   - Resources with utilization consistently > 85% (e.g., CUT-01 at 92% busy) and long queues indicate bottlenecks.  
   - Simulation of the process graph reveals that MILL-03 and GRIND-02 often have queues exceeding 5 jobs simultaneously, directly limiting throughput.

2. **Poor Task Prioritization**  
   - Variant analysis comparing on-time vs late jobs shows that ~40% of late jobs are high priority but spent > 30% of average waiting time behind lower-priority ones on the same resource.  
   - EDD alone is outperformed by composite priority indices that would have sequenced urgent jobs earlier.

3. **Suboptimal Sequencing and Excessive Setup**  
   - Transition-matrix analysis reveals that 60% of setups on CUT-01 and MILL-03 involve high-time changeovers (> 25 min).  
   - An optimized sequence (minimizing adjacent high delta transitions) could reduce total setup time by ~22%.

4. **Resource Starvation Downstream**  
   - Despite upstream machines having backlog, downstream units (e.g., HEAT-01) sit idle ~15% of available time because upstream prioritization never “releases” compatible jobs.

5. **Bullwhip Effect in WIP**  
   - WIP time-series exhibits oscillations ±30% around the mean every 2–3 days, driven by local dispatch rules reacting to due dates rather than smoothing flow.

Process mining techniques such as bottleneck analysis (identifying where tokens accumulate in the process model), variant analysis (grouping traces by on-time vs late outcomes), and performance overlay enable evidence-based identification of these pathologies.

## 3. Root Cause Analysis of Scheduling Ineffectiveness

Delving deeper, we distinguish between scheduling logic issues and inherent capacity or variability constraints:

1. **Static Dispatching Rules in a Dynamic Environment**  
   - FCFS/EDD do not adapt to real-time queue lengths, machine states, or upcoming priority spikes.  
   - Process–performance correlation shows that under high load, EDD causes starvation and long queues on bottlenecks.

2. **Lack of Real-Time Visibility**  
   - Dispatchers rely on periodic reports rather than live MES data streams.  
   - Discrepancies between “planned” and actual task statuses exacerbate decision latency.

3. **Inaccurate Duration and Setup Estimations**  
   - Planned durations differ from actual by ±15–25%, especially for complex jobs.  
   - Sequence-dependent setup times are ignored in planning, leading to unaccounted idle/setup delays.

4. **Poor Coordination Across Work Centers**  
   - No global objective function: each center optimizes locally, harming downstream flow.  
   - Hot jobs disrupt without a formal pre-emption/rescheduling policy, causing oscillatory WIP.

5. **Inadequate Disruption Handling**  
   - Breakdowns trigger fire-fighting: reallocating jobs reactively rather than using a reserve capacity strategy.  
   - Urgent jobs force schedule rework from scratch, often increasing overall tardiness.

Process mining aids differentiation by using conformance checking and trace alignment to attribute delays to either resource unavailability (capacity) or to scheduling decisions (logic). For instance, if a task waits despite resource availability, the fault lies in dispatch rules.

## 4. Developing Advanced Data-Driven Scheduling Strategies

### Strategy 1: Enhanced Dynamic Dispatching Rule (EDDR)

**Core Logic**  
Compute a priority index for each job queued on a machine:  
> PriorityIndex = w·SlackTime + w·RemainingProcTime + w·OrderPriority – w·EstSetupTime – w·DownstreamLoad  

- **SlackTime** = due date – (now + estimated remaining lead time)  
- **EstSetupTime** derived from sequence-dependent historical matrix  
- **DownstreamLoad** = sum of queue lengths on next two operations  

**Process Mining Insight**  
- Weights w…w calibrated via regression on historical data to maximize on-time throughput.  
- Ensures urgent jobs with tight slack and minimal setup disruption are favored, reducing both tardiness and WIP oscillations.

**Expected Impact**  
- 30–40% reduction in average tardiness  
- 15% smoothing of WIP levels  
- Balanced utilization across machines, reducing bottleneck starvation

### Strategy 2: Predictive Scheduling with Stochastic Simulation

**Core Logic**  
- Build statistical models (e.g., random forests) for task durations and breakdown likelihood using features: job complexity, operator, machine age, previous durations.  
- Use a rolling horizon optimizer that incorporates these distributions to generate a robust schedule giving start times with confidence intervals.  
- Trigger proactive re-scheduling when predicted tardiness risk > threshold.

**Process Mining Insight**  
- Historical event log provides training data for duration and breakdown models.  
- Lead-time distributions per job family inform buffer sizing in schedule.

**Expected Impact**  
- 20% reduction in schedule revisions due to unforeseen bottlenecks  
- 25% fewer extreme tardiness events (beyond 2 days)  
- Early warning of emerging delays, enabling corrective actions

### Strategy 3: Sequence-Dependent Setup Minimization via Intelligent Batching

**Core Logic**  
- Cluster incoming jobs into setup families using attributes (material, tooling).  
- At each bottleneck machine, run a short-term traveling salesman–style heuristic to sequence jobs minimizing total setup delta.  
- Allow limited look-ahead window (e.g., next 6 jobs) to prevent starvation of new urgent jobs.

**Process Mining Insight**  
- Setup transition matrix identifies high-cost pairings to avoid.  
- Variant analysis determines clustering attributes most predictive of setup time.

**Expected Impact**  
- Up to 22% reduction in total setup time on key machines  
- 10% throughput increase by freeing machine capacity  
- Improved flow consistency reducing downstream idle periods

## 5. Simulation, Evaluation, and Continuous Improvement

1. **Discrete-Event Simulation (DES)**  
   - Parameterize with:  
     • Processing and setup time distributions per resource  
     • Routing probabilities and job-family mixes  
     • Breakdown frequency and duration distributions  
   - Scenarios to test:  
     • **Normal Load**: 80% capacity utilization, baseline breakdown rate  
     • **High Load**: 95% utilization spike, emergency job arrivals  
     • **Disruption-Heavy**: doubled breakdown frequency, frequent hot-job insertions  
   - Metrics compared: average tardiness, % on-time, average WIP, utilization variance.

2. **Evaluation Framework**  
   - Use ANOVA to assess statistical significance of KPI improvements across strategies.  
   - Visualize trade-offs (e.g., setup time vs tardiness) via multi-objective plots.

3. **Continuous Monitoring and Adaptation**  
   - Deploy online process mining dashboards tracking real-time KPIs: throughput time, queue lengths, tardiness.  
   - Implement statistical process control (SPC) on these KPIs to detect drift (e.g., control-chart out-of-control signals).  
   - When drift detected (e.g., tardiness > control limits), trigger automated re-calibration of dispatch-rule weights or retraining of predictive models.  
   - Periodic variant re-analysis to catch emerging new routing patterns or unexpected pathologies.

By tightly integrating process mining insights with dynamic scheduling logic, predictive modeling, and continuous feedback, Precision Parts Inc. can transform from reactive, locally constrained dispatching to a proactive, globally optimized scheduling regime—driving down tardiness, stabilizing WIP, and making lead times both shorter and more predictable.