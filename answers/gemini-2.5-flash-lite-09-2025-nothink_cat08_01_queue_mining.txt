## Process Mining Approach for Outpatient Clinic Throughput Optimization

The challenge facing the outpatient clinic—excessive waiting times leading to patient dissatisfaction—is a classic throughput and queue management problem perfectly suited for process mining, specifically queue mining. By analyzing the provided event log data (Case ID, Activity, Start/Complete Timestamps, Resource, Patient Type, Urgency), we can move from anecdotal complaints to precise, actionable insights.

---

### 1. Queue Identification and Characterization

In the context of this event log, **waiting time (queue time)** for a specific activity ($A_i$) is defined as the duration between the completion of the preceding activity ($A_{i-1}$) and the start of the current activity ($A_i$) for the same patient case.

$$\text{Waiting Time}(A_i) = \text{Timestamp}(\text{Start}, A_i) - \text{Timestamp}(\text{Complete}, A_{i-1})$$

If the log captures the "start" and "complete" of the *same* activity instance, the duration between the *start* of the first activity (Registration) and the *complete* of the last activity (Check-out) provides the **Total Visit Duration (Cycle Time)**. The analysis must focus on the gaps *between* activities.

#### Key Metrics for Queue Characterization:

We must calculate these metrics for every transition (e.g., Wait for Nurse Assessment after Registration, Wait for Doctor Consultation after Nurse Assessment).

1.  **Average Waiting Time ($\mu$):** The mean time patients spend waiting in the queue before a specific service starts.
2.  **Median Waiting Time (50th Percentile):** Less sensitive to extreme outliers than the mean, indicating the typical experience.
3.  **90th Percentile Waiting Time ($P_{90}$):** Represents the waiting experience for the majority of "worst-off" patients, which directly correlates with satisfaction complaints.
4.  **Queue Frequency:** The total number of times a specific waiting transition occurs.
5.  **Wait-to-Service Ratio:** $\frac{\text{Average Wait Time}}{\text{Average Service Time (Duration of } A_i \text{ itself)}}$. A high ratio indicates service capacity is generally adequate, but scheduling/sequencing is poor.

#### Identifying Critical Queues:

Critical queues requiring immediate attention will be identified using a multi-criteria scoring system:

1.  **High Impact:** Queues with the highest $P_{90}$ wait times, as these define the ceiling of patient frustration.
2.  **High Volume/Frequency:** Queues that occur very frequently, even if the average wait is moderate, as they affect the highest number of patients (e.g., waiting for the common ECG station).
3.  **Bottleneck Identification (Queue Mining Output):** We will use specialized queue mining algorithms (e.g., those identifying the longest accumulated wait time across the entire process path) to highlight bottlenecks contributing most significantly to the overall cycle time.

**Prioritization Rule:** The highest priority goes to queues where **$P_{90}$ Wait Time exceeds a predefined acceptable threshold (e.g., 15 minutes)**, especially when coupled with high frequency or a clear resource constraint identified in the next step.

---

### 2. Root Cause Analysis

Identifying a long wait time (e.g., 30 minutes waiting for the Doctor Consultation) is merely symptom identification. Process mining must drill down into the root causes using contextual data:

| Potential Root Cause | Process Mining Technique Used | Data Focus |
| :--- | :--- | :--- |
| **Resource Bottlenecks** | **Resource Utilization Analysis & Overlay Visualization** | Identify resources (doctors, nurses, specific rooms) associated with the longest *service times* or those that are continuously busy ($\approx 100\%$ utilization) during peak queue times. A queue often forms when the preceding activity finishes, but the required resource is busy completing a long, preceding task for *another* case. |
| **Variability in Service Time** | **Activity Duration Analysis (Box Plots)** | Analyze the distribution of service times for activities leading up to the bottleneck (e.g., Nurse Assessment). High variance means unpredictable resource availability, causing downstream queues. |
| **Scheduling/Throughput Mismatch** | **Throughput Analysis & Conformance Checking** | Compare the observed path/timing against the expected/ideal patient flow model. If many patients are being seen out of appointment order, or if "Urgent" cases disproportionately delay "Normal" cases, scheduling policies are the likely issue. |
| **Patient Type Dependency** | **Performance Aggregation by Attribute** | Segment the waiting time metrics by `Patient Type` (New vs. Follow-up) and `Urgency`. If New patients wait significantly longer for registration, it suggests the check-in process isn't scaled for onboarding complexity. |
| **Process Deviations/Rework** | **Variant Analysis & Rework Detection** | Identify process variants where the patient goes back and forth between resources (e.g., Doctor sends patient to Lab, patient returns to Doctor immediately). Rework significantly inflates the time a resource is "occupied," leading to queues for the next patient. |

By overlaying the performance data (wait times) onto the structural model (process map), we can pinpoint exactly which resource or process path is collapsing under demand.

---

### 3. Data-Driven Optimization Strategies

Based on the hypothetical analysis uncovering bottlenecks at the Nurse Assessment queue and the Doctor Consultation queue, here are three concrete strategies:

#### Strategy 1: Dynamic Triage and Parallel Pre-Consultation Processing

*   **Target Queue(s):** Wait time between **Nurse Assessment Completion** and **Doctor Consultation Start**.
*   **Underlying Root Cause:** High variability in doctor consultation complexity leading to unpredictable service times, combined with a sequential flow.
*   **Proposed Action:** Implement a **Parallel Pre-Visit Station**. For high-volume, low-complexity follow-ups, allow the nurse to complete standardized tasks (vitals, medication review, minor prescription refills) and immediately move the patient to a **Pre-Consultation Holding Area** where they wait for the *next available* physician slot, rather than waiting specifically for *their scheduled* doctor.
*   **Data Support:** Analysis showing that follow-up visits have a service time standard deviation 50% lower than new patient visits.
*   **Expected Impact:** If the pre-consultation process can be standardized for 30% of visits, we expect a **20-30% reduction in the $P_{90}$ wait time for the Doctor Consultation queue** by decoupling the nurse handoff from the doctor's immediate availability.

#### Strategy 2: Resource Balancing for Registration/Check-in

*   **Target Queue(s):** Wait time for **Registration Start** (especially for 'New' patients) and Wait time for **Check-out Start**.
*   **Underlying Root Cause:** Peaks in arrival volume mismatching clerk scheduling, particularly due to complex onboarding documentation for new patients.
*   **Proposed Action:** Implement **Skill-Based Scheduling and Floating Support**. Use the arrival time data to identify the 2-hour peak window (e.g., 9:00 AM - 11:00 AM). Re-allocate administrative staff from low-activity afternoon slots to cover this peak. Introduce a "floating clerk" trained specifically in complex new patient registration to jump in immediately when the queue exceeds 3 waiting cases.
*   **Data Support:** Time-series analysis showing registration queue length spikes above 5 patients between 9:00 and 10:30 AM daily, while clerk utilization is below 60% between 3:00 PM and 5:00 PM.
*   **Expected Impact:** A projected **50% reduction in average wait time at Registration** during peak hours, significantly improving the initial patient experience.

#### Strategy 3: Targeted Diagnostic Pre-scheduling

*   **Target Queue(s):** Wait time between **Doctor Consultation Completion** and **Diagnostic Test Start** (e.g., ECG, Blood Draw).
*   **Underlying Root Cause:** Physicians frequently order tests as an *afterthought*, leading to a queue at the lab/imaging desk when multiple doctors finish complex cases simultaneously.
*   **Proposed Action:** Implement a **"Smart Pre-Order" Logic**. For consultations where the probability of requiring a specific common test (based on diagnosis code or visit type) is $>70\%$, the system prompts the physician to pre-book the diagnostic slot *while the patient is still with the nurse or prior to the main consultation*.
*   **Data Support:** Correlation analysis showing that 75% of Cardiology follow-ups require an ECG, but only 10% of these ECGs were scheduled before the consultation began.
*   **Expected Impact:** Reduced friction in the diagnostic phase by converting a sequential wait into a potentially **parallel activity**, aiming for a **40% decrease in the average wait time before diagnostic tests**.

---

### 4. Consideration of Trade-offs and Constraints

Optimization always involves trade-offs. The primary constraint here is maintaining **Care Quality** while controlling **Operational Costs**.

| Strategy | Potential Trade-off/Negative Side-Effect | Balancing Mechanism |
| :--- | :--- | :--- |
| **Dynamic Triage (Strategy 1)** | Risk of "skimming" the easiest cases, leaving complex cases to wait longer for their specific specialist, potentially impacting focused care quality. | Ensure the process mining confirms the *complexity gap* between parallelized vs. sequential cases is significant enough. Monitor patient safety indicators for the 'pre-consultation' group. |
| **Resource Balancing (Strategy 2)** | Increased labor cost due to moving staff from off-peak to peak hours, or requiring overtime/new hires if flexibility is limited. | Focus initially on **re-allocating existing staff** before approving new hires. Measure the ROI: Does the cost of one extra hour of clerk time justify the reduction in patient complaints (improved retention)? |
| **Smart Pre-Ordering (Strategy 3)** | Increased resource utilization (rooms/equipment) early in the day, leading to potential *over-utilization* and creating a new bottleneck at the testing area later in the day. | Use the process model to map the total load on the ECG room. If utilization exceeds $85\%$ across the day with this strategy, the bottleneck shifts to testing, necessitating increased testing capacity (a capital expense consideration). |

**Balancing Conflicting Objectives:** We balance cost control by prioritizing **flow changes (strategies 1 and 3)** that rearrange existing resources before escalating to **staffing increases (strategy 2)**. The overall goal is to use data to ensure that *every unit of staff/room time is spent on the highest-value activity*, thus maximizing throughput without increasing input costs excessively.

---

### 5. Measuring Success

Success must be measured against the primary goals: reducing overall visit duration and improving satisfaction (via reduced waiting).

#### Key Performance Indicators (KPIs):

1.  **Primary Throughput KPI:** **Total Visit Duration (Cycle Time):** Measure the mean and $P_{90}$ time from Registration Start to Check-out Complete.
2.  **Primary Satisfaction KPI:** **Average and $P_{90}$ Total Queue Time:** Sum of all identified waiting times across the entire process path for a single case. *Target: Reduce Total Queue Time by 25% within 3 months.*
3.  **Specific Bottleneck KPI:** The average wait time for the specific queues targeted by the intervention (e.g., Wait time before Doctor Consultation).
4.  **Efficiency KPI:** **Resource Wait-to-Service Ratio:** Monitor the ratio for critical resources (e.g., Dr. Smith's queue ratio). A decrease implies better scheduling relative to actual service demand.

#### Ongoing Monitoring and Sustained Improvement:

Success requires shifting to **Continuous Process Monitoring**.

1.  **Automated Event Log Capture:** Ensure the EHR/scheduling system continuously feeds the event log data structure (Case ID, Activity, Timestamps, Resource) into a dedicated process mining tool.
2.  **Automated Dashboarding:** Create a near real-time dashboard displaying the KPIs (especially Total Queue Time and Bottleneck Wait Time). Set **alert thresholds** based on the prior unacceptable performance levels.
3.  **Drift Detection:** Periodically re-run the process discovery model (e.g., monthly). This helps detect **process drift**—where staff revert to old habits or new variations creep in—or if a previously solved bottleneck (e.g., Registration) has been inadvertently shifted to a new one (e.g., Lab Check-in). If drift is detected, targeted retraining or process reinforcement is immediately scheduled.