============================================================
1. PROCESS DISCOVERY & CONFORMANCE CHECKING
============================================================

1.1Pre-processing & Event Log Construction  
• Case definition – two useful granularities:  
a) Vehicle-Day (e.g., “V12-20241205”) to analyse fleet flow and utilisation.  
b) Package ID to analyse customer service performance (late / failed deliveries).  
A single physical record can therefore belong to two logs that are analysed in parallel and later related through Vehicle ID and timestamps.  

• Event attributes to harmonise  
– Timestamp (convert to UTC, add timezone flag).  
– Activity name (normalise: “Arrive Customer”, “Delivery Success”, etc.).  
– Lifecycle (start/complete) where durations matter (e.g., “Service @ Customer” starts at Arrive and ends at Depart).  
– Resource attributes (Driver ID, Vehicle ID).  
– Performance attributes (speed, fuel level if available, odometer, traffic score).  

• Data integration challenges  
1. Clock drift between devices  perform timestamp alignment using depot events as calibration points.  
2. Granularity mismatch (GPS every 5 s, scanner events sparse)  aggregate GPS to stay-points / segments (e.g., ‘Driving’, ‘Idle’, ‘Stopped-Engine-On’, ‘Stopped-Engine-Off’).  
3. Missing / duplicate events (loss of signal, rescans)  cleaning rules and outlier detection.  
4. Linking maintenance log to driving log: insert “Maintenance Start/End” events and lag them to nearest Vehicle-Day cases, or create dedicated Vehicle-Period cases for fleet health analysis.  

1.2Process discovery  
• Vehicle-Day log – apply algorithms such as i) Inductive Miner (Noise0.2) for a sound BPMN-like model, or ii) Fuzzy Miner for exploratory maps including frequencies and performance edges.  
• Typical high-level path:  
Start Shift  (‘Drive’  ‘Stop-Traffic’)*  [repeat “Arrive Customer  Service  Depart”]  (Unscheduled Stop | Maintenance)  Return Depot  End Shift.  
• Visual overlays show mean/median times between nodes and highlight rare behaviours (e.g., “Engine Warning  Towed to Depot”).  

1.3Conformance to dispatch plan  
• Import the planned route as a reference model: sequence of planned stops with planned arrival windows and planned travel times.  
• Replay the actual log on the reference model using token replay or alignments:  
– Move-Model deviations: stop skipped or delivered in the wrong order.  
– Move-Log deviations: unplanned stops (coffee, refuelling, breakdown).  
– Time deviations: early/late arrival > configured threshold; excessive dwell time vs. plan; prolonged driving segments.  
• KPIs captured during conformance: average “fitness” per route, number of extra kilometres, percentage of packages served in correct sequence, etc.

============================================================
2. PERFORMANCE ANALYSIS & BOTTLENECK IDENTIFICATION
============================================================

2.1Key Performance Indicators (examples)  
1. On-Time Delivery Rate = (# packages delivered within promised window) / (# delivered)  
• Event basis: ‘Delivery Success’ timestamp vs. customer window.  
2. Average Service Time per Stop = mean(Depart – Arrive).  
3. Average Driving Time between Stops = mean(Arrive(n) – Depart(n-1)).  
4. Travel : Service Ratio = DrivingTime / ServiceTime per Vehicle-Day.  
5. Fuel Consumption per km = (Litre) / (Km)  (if CAN-bus fuel data; else estimate via odometer ).  
6. Vehicle Utilisation = (Shift Duration – Depot Idle) / 24 h.  
7. Traffic Delay Index = (Actual Driving Time – Planned Driving Time) / Planned.  
8. Failed Delivery Rate = (# Delivery Failed) / (# attempts).  
9. Maintenance-induced Downtime = (Maintenance durations during shift).  

2.2Techniques to detect bottlenecks  
• Performance overlay on process maps – highlight edges/nodes with 90th-percentile durations or frequencies.  
• Traffic hotspot mining – cluster GPS pings with speed < X km/h to derive “congestion zones”; correlate with prolonged driving edges.  
• Variant analysis – compare fastest vs. slowest 20 % Vehicle-Days: look for activities that only appear in slow variants.  
• Timeline heatmaps – x-axis = time of day, y-axis = average driving speed or dwell time; reveals rush-hour bottlenecks.  
• Resource-performance matrix – pivot by Driver ID; outliers indicate training needs.  
• Case-duration decomposition – process cubes slicing by route, weekday, vehicle class, weather tag (import external data).  
• Queuing diagnostics – for depot “Return” event: waiting time before unloading or refuelling.

============================================================
3. ROOT-CAUSE ANALYSIS
============================================================

Potential root causes & how to validate them with process mining:

A. Sub-optimal static routing  
• Evidence: low model fitness, high number of sequence deviations, excess kilometres.  
• Analyse: compare “extra km” against traffic delay; path replay to show back-tracking.

B. Under-estimated travel times / ignoring congestion patterns  
• Evidence: systematic positive time deviations during peak hours; traffic hotspot overlay shows recurring slow segments at same times.  

C. High service-time variability  
• Evidence: service-time distribution heavy-tailed; link long services to customer type or building type stored in master data.  

D. Unscheduled maintenance or vehicle reliability  
• Evidence: cases containing “Unscheduled Stop – Maintenance” have 2× average duration; correlate breakdowns with mileage since last service.

E. Driver behaviour differences  
• Evidence: speed profiles, idling duration, harsh braking events vs. fuel consumption; cluster drivers by KPI vector and investigate outliers.  

F. High failed-delivery rate  
• Evidence: cases with ‘Delivery Failed’ create re-routing the next day; compute additional km / overtime attributable to re-deliveries; correlate with time-window width and customer call-ahead practices.

============================================================
4. DATA-DRIVEN OPTIMISATION STRATEGIES
============================================================

Strategy 1 – Dynamic, traffic-aware re-routing  
• Targets: Excess driving time, late deliveries.  
• Root cause: Static dispatch plan ignores real-time congestion.  
• Process-mining support: Traffic delay index > 25 % in 8-10 a.m. window; replay shows many move-model deviations where drivers self-re-route.  
• Action: Integrate live traffic API; re-optimise remaining sequence every X stops; dispatch app pushes updated route.  
• Expected KPI impact:  Average Driving Time 10-15 %;  On-Time Delivery 8 pp;  Fuel per km 5 %.

Strategy 2 – Predictive maintenance scheduling  
• Targets: Unscheduled breakdowns, overtime, high repair cost.  
• Root cause: Maintenance intervals based on calendar not usage/condition.  
• Process-mining support: Breakdown probability rises sharply after 7,500 km since last service; affected cases add avg. 2 h downtime.  
• Action: Build survival model using mileage & engine sensor events; schedule preventive service during low-demand days; embed “Maintenance Due” as planned activity to avoid route assignment.  
• Expected impact:  Maintenance-induced Downtime 40 %;  Repair cost 20 %;  Vehicle Availability 5 pp.

Strategy 3 – Customer time-window & communication optimisation  
• Targets: Failed deliveries, re-delivery kilometres, customer dissatisfaction.  
• Root cause: Windows too wide (customers absent) or too tight (driver can’t make it).  
• Process-mining support: 70 % of failed deliveries linked to 12-18 h open windows; token-replay shows lateness > 30 min correlates with failure.  
• Action:  
a) Offer smaller paid premium slots in dense areas where driver arrival variance  ±15 min.  
b) Send predictive ETA SMS based on real-time replay fitness (“driver three stops away, ~20 min”).  
c) Allow customer live deflection (leave with neighbour).  
• Expected impact:  Failed Delivery Rate 50 %;  Extra km 6 %;  Customer NPS.

(Alternative / additional strategies could include driver eco-driving training based on idling analysis, or territory realignment using historic stop density and service-time heatmaps.)

============================================================
5. OPERATIONAL CONSTRAINTS & CONTINUOUS MONITORING
============================================================

5.1Respecting constraints  
• Hours-of-service: optimisation models incorporate maximum shift length and mandatory breaks; conformance checker flags any ‘Drive’ after legal hours.  
• Vehicle capacity: dispatcher maintains weight/volume attributes; process map variants verify no “Load > Capacity” incidents.  
• Customer windows: dynamic routing solver keeps ETA within promised range; post-execution conformance KPI = SLA breach count.  

5.2Process-mining dashboards for ongoing control  
• Real-time (near-real-time) tiles:  
– Today’s On-Time % by route & driver.  
– Active traffic delay index heatmap over city grid.  
– Vehicles approaching maintenance threshold (km & days).  
• Weekly management view:  
– Trend lines of Travel : Service Ratio, Fuel/km, Failed-Delivery Rate.  
– Box-plots of service time per customer segment.  
– Driver league table (driving efficiency, idling, punctuality).  
• Alerting rules:  
– Case predicted to miss > 2 deliveries  notify dispatcher.  
– Vehicle variance from planned route > 10 km  investigate.  
– Fitness drop below 0.8 for any route  flag for re-planning.  
• Continuous improvement loop: each month, re-run discovery on latest log, compare to baseline model to ensure implemented strategies keep bottlenecks from re-emerging.

By systematically integrating multi-source data, employing process-mining discovery, conformance, and performance analytics, and translating insights into targeted operational changes, Speedy Parcels can measurably raise punctuality, lower fuel and maintenance costs, and sustain these gains through ongoing monitoring.