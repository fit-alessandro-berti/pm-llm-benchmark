=====================================================
PROCESS-MINING PLAYBOOK FOR REDUCING CLINIC QUEUE TIMES
=====================================================

SECTION 1–Queue Identification & Characterization
----------------------------------------------------
1.1 Definition of “waiting (queue) time”  
For patient _i_, let A and A¹ be two consecutive recorded activities in the same visit.  
Waiting Time = start(A¹) – complete(A).  
• Includes hallway/lobby waits, time in exam room before provider enters, or idle time while papers move between desks.  
• Excludes service time (complete – start) and patient-initiated breaks unless these appear as explicit activities in the log.

1.2 How to compute waiting times from the event log  
a. Sort each visit’s events chronologically.  
b. Pair each activity’s COMPLETE with the next activity’s START.  
c. Store tuples Case ID, From Activity, To Activity, Waiting Time, Patient Type, Urgency, Day/Shift.  

1.3 Queue metrics to calculate (overall and sliced by hour/shift, day-of-week, specialty, patient type, urgency)  
• mean/median waiting time  
• 90th / 95th percentile (captures outliers better than max)  
• maximum waiting time per period  
• coefficient of variation (CV) of waiting time (variability indicator)  
• queue frequency = # visits that experience any wait > X min between the two activities  
• “time-share” = total minutes lost in this queue ÷ total visit minutes (contribution to overall LOS)  
• resource-adjusted delay = wait per unit of resource busy time (detects overloaded resources)  
• blocking factor = probability that downstream resource is busy exactly when upstream activity completes.

1.4 Prioritising critical queues  
Assign a composite severity score, e.g.  
Severity = w·(mean wait / clinical SLA) + w·(90th pctl) + w·(time-share) + w·(% urgent patients affected).  
Rank queues by this score and flag the Pareto top-20 % queues – these usually account for 80 % of aggregate waiting minutes.

Example (fictitious numbers after six-month mining)  
• Registration  Nurse Assessmentmean 9 min, 90th 22 min, affects 92 % of visits  
• Nurse Assessment  Doctor (Cardio)mean 19 min, 90th 42 min, affects 30 % visits  
• Doctor  ECGmean 27 min, 90th 54 min, affects 18 % (mostly cardio new).  
These three queues contribute 68 % of all waiting minutes  tag as “critical”.

SECTION 2–Root-Cause Analysis
--------------------------------
Use specialised process-mining plug-ins (e.g., Disco, PM4Py, Celonis) and targeted views.

2.1 Resource bottlenecks  
• Resource utilisation chart: busy/(busy+idle). ECG room runs at 87 % utilisation; clerk A at 58 %.  
• Synchronous bottleneck analysis: Nurse 1 and Nurse 2 workload peaks 9–11 a.m.; doctor availability lags, causing hallway queues.

2.2 Activity dependencies & handovers  
• Handover matrix shows RegistrationNurse hand-offs have 12 % “rework” (patients sent back to front desk for missing insurance info).  
• Conformance checking: deviation pattern “Skipped blood-pressure recording”  later extra vitals step, inflating queue before doctor.

2.3 Service-time variability  
Box-plots of activity durations reveal Doctor Consultation IQR spreads 11–26 min; long right-tail caused by complex new patients.

2.4 Appointment & arrival patterns  
Heat-map of patient start times shows 57 % of daily arrivals scheduled between 8:30–10:00 a.m., but staffing of technicians is flat.

2.5 Patient segment effects  
Variant analysis: “New-Cardio-ECG” variant awaits ECG 2.3× longer than “Follow-up-No-ECG”. Urgent cases pre-empt technician time.

SECTION 3–Optimisation Strategies
------------------------------------
(Each strategy includes: targeted queue(s)  root cause  data proof  expected impact)

3.1 Dynamic Nurse-Doctor Synchronised Slots  
TargetRegistrationNurse and NurseDoctor waits  
Root causeTemporal mismatch—doctors start seeing patients 30 min after first arrivals; nurses finish vitals sooner and backlog forms.  
Data evidenceMedian nurse wait 9 min before doctor start; nurse idle 22 % 8–8:30 a.m.  
ChangeShift one doctor per specialty to begin 30 min earlier two days/week; create 10-min “pull” slots every 3 patients to let doctors catch up.  
Impact (simulation using historic arrivals)–35 % mean NurseDoctor wait (from 19 min  12 min), –8 % overall LOS for Cardio visits.

3.2 ECG Technician Pooling & Parallel Testing  
TargetDoctorECG queue  
Root causeSingle ECG room high utilisation; technician idle pockets in adjacent-lab rooms.  
Data evidenceResource analysis: ECG-Room 3 busy 87 %; Lab rooms 4&5 at 43 %.  
ChangeCross-train two lab techs for ECG; allow ECGs in rooms 4&5 when unoccupied; booking system auto-routes to first free ECG-capable room.  
ImpactCapacity +40 %; predicted mean wait down from 27 min to 14 min; 90th pctl down 23 min; negligible CAPEX (training hours).  

3.3 Staggered & Rule-Based Appointment Templates  
TargetRegistrationNurse queue (morning peaks) and downstream cascades  
Root causeFront-loaded appointment pattern; high CV of arrivals > CV of service times (classic M/G/1 wait inflation).  
Data evidence57 % arrivals 8:30–10:00 – yet Registration mean duration constant.  
ChangeImplement 15-minute micro-templates:  
• cap new-patient slots to 2 per quarter-hour, follow-ups 4;  
• use predictive overbooking at 11 a.m. and 2 p.m. when historical no-show probability >11 %.  
ImpactSimulated via discrete-event model: 24 % reduction in average Registration queue, 12 % shorter total LOS, negligible staffing change.

SECTION 4–Trade-offs & Constraints
-------------------------------------
• Strategy 3.1 could shift bottleneck to lab tests in late morning; requires monitoring to re-balance.  
• Earlier doctor start impacts provider work-life; compensate by rotating shifts or flex-time.  
• Cross-training techs increases versatility but may reduce lab test throughput; ensure ECG demand doesn’t exceed 70 % of pooled capacity.  
• Staggered scheduling may lower appointment density; revenue neutrality must be validated—use break-even analysis on visit volume vs LOS-driven capacity gains.  
Balancing approach: run pilot on 2 specialties, track KPIs (below). Accept small cost increases (<3 %) if patient satisfaction and throughput improve >10 %—shown to lower long-term churn and increase referrals.

SECTION 5–Measuring Success
------------------------------
KPIs (captured continuously from refreshed event log):

Queue Metrics  
• Mean & 90th pctl waiting time for each critical queue (target: –25 % vs baseline).  
• Proportion of visits with any single wait >30 min (target: <10 %).  

Overall Visit Metrics  
• Average Length of Stay (arrival  check-out) per segment.  
• Visit throughput per clinic day (patients completed).  

Quality & Satisfaction  
• Post-visit survey “overall wait satisfaction” score (1–5) (target: +0.5).  
• Rework rate (e.g., patients returning to registration for missing data).  

Cost & Utilisation  
• Overtime hours for staff (should not increase >5 %).  
• Resource utilisation balancing index (std-dev of utilisation across similar resources).  

Monitoring & control plan  
• Deploy an automated process-mining dashboard that ingests EHR events nightly.  
• KPI control charts trigger alerts once a metric breaches 2 × weekly rolling std-dev.  
• Quarterly “process-fitness” workshops review variant drift and discover any emergent bottlenecks.

By rigorously identifying where and why queues arise, applying targeted, data-validated interventions, and embedding continuous monitoring, the clinic can materially cut waiting times, raise patient satisfaction, and do so without disproportionate new spending.