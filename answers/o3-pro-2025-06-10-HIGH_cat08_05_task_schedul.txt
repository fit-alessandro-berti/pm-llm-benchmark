========================================================
1.  ANALYZING HISTORICAL SCHEDULING PERFORMANCE AND DYNAMICS
========================================================
Step 0 – Data Preparation  
•  One event-log line = one “atomic” change of state.  
•  Case ID = Job ID (JOB-####).  
•  Activity = log’s “Activity/Task” column.  
•  Resource = Machine ID (primary) plus Operator ID (secondary).  
•  Two time stamps for each atomic activity are reconstructed from Start/End pairs so that every event has a start- and a complete-time (XES “lifecycle” concept).  
•  Add external attributes: due-date per case, priority, product family, routing string, etc.

1.1  Process Discovery of the Real Flow  
Tools: PM4Py / Celonis / Disco.  
•  For the overall job flow: Fuzzy-Miner (handles low-frequency edges) to reconstruct the routing variability.  
•  For each critical machine: Sequence-viewer (“timeline” plug-in) to see exact job order.  
•  Token-based replay provides conformance costs that later quantify “plan vs. reality”.

1.2  Performance Metrics Extracted

A. Job-level  
•  Flow / Lead / Makespan: complete-time(last task) – release-time.  Distributions per product family.  
•  Tardiness: max(0, completion – due date).  Percentage late, mean lateness, maximum lateness.

B. Task / Machine-level  
•  Queue / Waiting time: start-time(setup or task) – queue entry.  
•  Service time: setup + processing.  
•  Setup ratio: setup/(total busy).  Extract automatically because activities are explicitly labelled “Setup Start/End”.

C. Resource Utilisation (per machine)  
Busy_processing = (Task StartTask End)  
Busy_setup      = (Setup StartSetup End)  
Idle            = calendar available – Busy_processing – Busy_setup – breakdown.  
KPIs:  
  – OEEproxy = Busy_processing / calendar.  
  – True Util = (Busy_processing+ Busy_setup) / calendar.  
  – Setup Share per machine.

D. Sequence-dependent set-up matrix  
For every machine m create matrix S_m(i,j)=mean setup time when job of family i follows family j.  
Algorithm:  
  1. Sort log by Resource, StartTime.  
  2. Whenever event_k(Job A) is “Task End” and event_{k+1}(Job B) is “Setup Start”, read families A,B and duration(setup).  
  3. Aggregate  heat-map that immediately shows painful transitions.

E. Impact of Disruptions  
•  Overlay breakdown intervals on Gantt chart; use “what-if” token-replay deleting those intervals to quantify tardiness.  
•  Priority changes: mine “variant before/after change” and correlate with waiting-time reduction or jump-ahead events.

========================================================
2.  DIAGNOSING SCHEDULING PATHOLOGIES
========================================================
Evidence obtained with process-mining plug-ins:

Pathology 1 – Chronic Bottlenecks  
•  Bottleneck Miner (van der Aalst): >60 % of jobs spend >40 % of total lead time waiting for specific machines MILL-03 and GRIND-01.  
•  During those intervals downstream machines show starvation (idle>35 %).

Pathology 2 – Ineffective Prioritisation  
•  Variant analysis: high-priority jobs still 48 % late.  Heat-map of queue positions shows they often enter queue in position 3-5.  
•  Waiting-time regression: Priority coefficient not significant  rule not enforced.

Pathology 3 – Setup Explosion  
•  On CUT-01 the worst three family transitions add 18 h setup per week (>1 shift).  
•  In 27 % of weeks jobs were sequenced family ABA producing avoidable “back-and-forth” setups (“setup echo”).

Pathology 4 – Bullwhip WIP Waves  
•  Work-in-progress per day (Process Cube, dimension “routing stage”) shows 3-day oscillations with amplitudes ±40 %.  Root cause: every Monday large batch release regardless of downstream status.

Pathology 5 – Disruption Sensitivity  
•  Breakdown miner: each 2-h unplanned stop on MILL-02 cascades into extra 6 h tardiness on average (critical path).  No evidence of proactive rescheduling events.

========================================================
3.  ROOT-CAUSE ANALYSIS OF SCHEDULING INEFFECTIVENESS
========================================================
1. Static local rules  
   – FCFS + EDD ignore setup sequences, downstream queues, or actual remaining slack  explains Pathology 2 & 3.

2. No real-time visibility  
   – Operators start next job in physical FIFO lane, unaware that another job in another cell will violate due date  Pathology 1 & 2.

3. Data quality & estimation issues  
   – Planned durations differ from actual by MAD 22 %.  Schedulers use fixed standards; set-ups ceilinged at 20 min although real range 5-90 min  unrealistic commitment dates.

4. Disruption handling  
   – Log shows no “reschedule” events within 30 min after breakdown start in 81 % of incidents  purely reactive, leads to Pathology 5.

Process-mining separation of “poor logic” vs. “capacity limit”:  
•  Within-capacity replay: run token-replay with perfect sequencing (Greedy minimal setup) but actual capacities.  Lead-time reduces by 38 %  large share attributable to logic, not physical limits.

========================================================
4.  ADVANCED DATA-DRIVEN SCHEDULING STRATEGIES
========================================================
Strategy 1  – Dynamic Composite Priority Index (CPI) Dispatching  
Core logic: Each time a machine becomes free, choose job j that maximises  

CPI_j = w1·(1/Slack_j) + w2·Priority_j + w3·CRR_j + w4·(1/PredSetup(m,prev,j)) + w5·DownstreamWIP_j  

Where  
Slack = DueDate – (Now + est.remaining total processing)  
CRR (critical ratio of remaining proc time) = RemainingTime / Slack  
PredSetup(m,prev,j) = expected setup derived from S_m matrix.  
w_i weights learned via off-line simulation optimisation (GA).  

Process-mining input:  
•  S_m matrices, real-time queue lengths, distribution of processing times by job family & operator.  

Addresses: late jobs (Slack), poor prioritisation (Priority), setup explosion (PredSetup), starvation (DownstreamWIP).  

Expected impact from DES experiments:  
– Mean tardiness –45 %, WIP –20 %, setups –12 %.

Strategy 2  – Predictive, Rolling-Horizon Schedule with Digital Twin  
Core logic:  
1. Every 30 min run a MILP/CP solver on a 48-hour rolling horizon.  
2. Task durations are not deterministic: use ETA95 = mean+1.64· from mined log conditional on machine+operator+family.  
3. Breakdowns: integrate remaining useful life (RUL) predictor (Gradient Boosting on sensor time-series) to insert preventive windows and avoid scheduling tasks across high-risk intervals.  
4. Solver objective: minimise weighted tardiness + setup cost + overload penalty.   

Process-mining input:  
•  Conditional duration distributions, setup matrices, breakdown probability profiles.  

Addresses: disruption sensitivity, inaccurate durations.  

Expected impact:  
– Schedule stability  (reschedule frequency –40 %)  
– Customer delivery reliability 95 th percentile.

Strategy 3  – Setup-Time Oriented Batch & Sequence Optimiser (STOB)  
Core logic:  
1. Daily at 16:00 freeze the next-day release list.  
2. Cluster jobs into “setup-compatible” groups using k-medoids on feature vector (material, thickness, tooling set).  
3. On each bottleneck machine solve a Traveling-Salesman Problem variant where distance = predicted setup times  sequence with minimum total setup.  
4. Release to shop floor following Load-Oriented Order Release (LOOR) so that Workload_norm(bottleneck)  threshold.  

Process-mining input:  
•  Historical setup matrix to build distance metric, throughput curves to set LOOR thresholds.  

Addresses: setup explosion, Monday WIP wave, bottleneck load leveling.  

Expected impact:  
– Setup time –30 % on CUT-01 and MILL-03  
– Throughput +12 % without extra capacity.

========================================================
5.  SIMULATION, EVALUATION, AND CONTINUOUS IMPROVEMENT
========================================================
5.1  Discrete-Event Simulation Test-bed  
•  Model built in AnyLogic/SimPy; entities = jobs; resources = machines, operators.  
•  Parameterisation from process-mined distributions:  
   – Task processing & setup times: empirical or log-normal fitted per (machine, family, operator).  
   – Routing: actual variant probabilities.  
   – Breakdowns: Weibull inter-arrival & repair times mined from “Breakdown Start/End”.  
•  Scenarios:  
   S1  Baseline demand + historical breakdown rate.  
   S2  120 % demand surge.  
   S3  Frequent hot jobs ( doubled).  
   S4  High-breakdown (MTBF –30 %).  

Metrics captured: lateness distribution, WIP, average flow-time, machine utilisation, total setup, number of reschedules.  
Ranking: Use TOPSIS with weights agreed by management.

5.2  Continuous Monitoring & Adaptive Loop  
•  Event stream from MES feeds process-mining engine (PM4Py streaming).  
•  KPIs auto-computed hourly; CUSUM on mean tardiness detects drift.  
•  If drift>threshold, trigger:  
   – Re-estimate duration models.  
   – Re-optimise CPI weights (Strategy 1) via online learning.  
   – Push new schedule parameters to MES via API.  
•  Monthly “process performance cockpit” shows trend of OEE, setup %, due-date adherence.

========================================================
Result: A closed-loop, analytics-driven scheduling framework where process-mining facts feed optimisation logic, simulation proves value before release, and continuous monitoring guarantees that Precision Parts Inc. quickly reacts to new patterns, ultimately reducing tardiness, WIP, and wasted capacity while smoothing customer lead times.