Got it — you want a **full DuckDB SQL query** that:

1. Counts how many events occur per `case_id`.
2. Filters out any `case_id` where the count exceeds **6**.
3. Returns all original event rows — but only for the `case_id` values meeting that criterion (6 or fewer events).

Here’s a clear DuckDB SQL solution:

```sql
SELECT e.*
FROM event_log AS e
JOIN (
    SELECT case_id
    FROM event_log
    GROUP BY case_id
    HAVING COUNT(*) <= 6
) AS filtered_cases
ON e.case_id = filtered_cases.case_id;
```

### How this works
- **Inner query**:
  - `GROUP BY case_id` groups events by process instance.
  - `HAVING COUNT(*) <= 6` keeps only cases with **6 or fewer events**.
  
- **Outer query**:
  - Joins the filtered list of `case_id`s back to the original table to return **all event rows** for qualifying cases.

---

 **DuckDB-specific notes**:
- This uses entirely standard SQL: works directly in DuckDB without special syntax.
- `COUNT(*)` will count all rows per `case_id`.

---

If you’d prefer a single query without explicit join, you can leverage a window function:

```sql
SELECT *
FROM (
    SELECT el.*,
           COUNT(*) OVER (PARTITION BY case_id) AS event_count
    FROM event_log AS el
) AS sub
WHERE event_count <= 6;
```

This also works in DuckDB and can sometimes be a bit easier to read for quick filtering.

---

Do you want me to **optimize** this for very large event logs in DuckDB (e.g., avoiding multiple scans)? That would allow it to run faster on big datasets.