## 1. Analyzing Resource Behavior and Assignment Patterns

### 1.1 Prepare and enrich the event log

From the log you provided, we have what we need for a rich **resource perspective**:

- Case ID (ticket)
- Activities (create, assign, work start/end, escalate, reassign, close)
- Timestamps (START / COMPLETE)
- Resource, Agent Tier, Agent Skills
- Ticket attributes (Priority, Category, Required Skill, Channel, etc.)

First, derive some standard performance attributes per ticket and per activity:

- **Case-level**
  - Total resolution time (Created  Resolved/Closed).
  - Time in each tier (sum of “Work L1”, “Work L2”, etc.).
  - Number of:
    - Assignments
    - Reassignments
    - Escalations (L1L2, L2L3)
  - SLA breach flag (based on priority-specific SLA).

- **Activity-level**
  - Handling time per “Work X Start/End” (per agent).
  - Waiting time before first “Work X Start” in a tier.
  - Waiting time introduced after “Escalate” or “Reassign”.

These are computed from timestamps and will drive most analyses.

---

### 1.2 Metrics per agent and per tier

Using process mining/performance analysis, focus on:

**Per Agent (Resource)**

- **Volume / workload**
  - # of tickets handled (overall and by priority, category, required skill).
  - # of active tickets (WIP) over time (e.g., sampled every 15 minutes).
- **Time metrics**
  - Average and distribution of handling time per activity.
  - Average waiting time before agent starts work (proxy for queue behavior).
- **Outcome metrics**
  - First-contact resolution (FCR) rate for L1 agents:
    - % of tickets the agent closes without escalation or reassignment.
  - Escalation rate:
    - % of tickets the agent escalates to higher tier.
  - Reassignment rate:
    - % of tickets that leave the agent after “Reassign”.
  - SLA performance for tickets touch by the agent:
    - % of handled tickets that end in SLA breach.
- **Skill usage**
  - For each agent skill (from their profile), # and % of tickets actually requiring that skill (from `Required Skill` or inferred from final resolver).
  - % of their time spent on tasks:
    - Matching their main skills.
    - Below their skill level (e.g., L2 security expert working generic “Basic-Troubleshoot”).

**Per Tier (L1, L2, L3)**

Aggregate the above:

- Tier-level FCR (e.g., % resolved at L1).
- Average time spent per tier per case.
- Escalation rates between tiers (L1L2, L2L3, and any reverse flows).
- Volume per tier by priority / category (e.g., P2 Network, P3 Software-App).

These metrics show whether, for example:

- L1 is resolving enough tickets or over-escalating.
- L2/L3 are overloaded with tickets that could be resolved earlier.
- Some tiers specialize in certain categories in practice (even if not by design).

---

### 1.3 Process mining: organizational and resource interaction analysis

Use **organizational mining** techniques to reveal actual patterns:

1. **Handover-of-work / social network analysis**

   Build a graph where:
   - Nodes = agents or roles (L1, L2, L3, or clusters).
   - Directed edge AB if B performs an activity on a ticket after A.

   Edge weights:
   - # of handovers (frequency).
   - Average time between A’s last activity and B’s first activity (handover delay).
   - Filter by “Escalate” and “Reassign” events to focus on problem handovers.

   Insights:
   - Which L1 agents frequently escalate to which L2/L3 agents.
   - “Super hubs” (e.g., a small group of L2s receiving most escalations).
   - Patterns like:
     - L1 A05  L2 B12  L2 B15 (indicating misrouting before reaching the “real” expert).

2. **Role discovery / clustering**

   Using activities and skills per resource, cluster agents into **functional roles**:
   - E.g., “Network-Firewall specialists”, “CRM app specialists”, “Generic L1 troubleshooters”.
   Compare discovered roles with:
   - Declared tier (L1/L2/L3).
   - Documented skills.

   This reveals:
   - Agents performing specialist roles without being formally recognized.
   - Misaligned tiers (L2 acting as L1 in practice).

3. **Comparison with intended assignment logic**

   The current “round-robin within tier + manual escalation” can be modeled as expected behavior (e.g., process model with routing rules).

   Use **conformance checking** to compare:
   - Expected assignments (e.g., L1 should handle first, then escalate if specific conditions).
   - Actual event sequences (who actually took the ticket, in what order).

   Deviations show:
   - Direct L2/L3 assignments bypassing L1.
   - Frequent reassignments within the same tier (contradicting clean round-robin).

---

### 1.4 Skill utilization analysis

Treat `Required Skill` as ground truth for what the ticket ultimately needed (if this field is updated when resolved or enriched from problem classification).

**Steps:**

1. **Per skill:**
   - Volume of tickets requiring the skill.
   - Number of agents who have that skill.
   - Average waiting time before the first agent with that skill starts work.
   - % of those tickets:
     - Assigned correctly (first worker has the skill).
     - Initially handled by someone without the skill and then escalated/reassigned.

2. **Per agent:**
   - Fraction of their workload requiring their main skills vs generic tasks.
   - Cases where they worked on tickets requiring a skill they *don’t* have (possible mislabeling or skill profile issues).

3. **Skill-level utilization vs. availability:**
   - For each skill, approximate utilization:
     - total handling time on tickets requiring that skill
     ÷
     total available time of agents who have that skill.
   - Identify:
     - Critical skills with near-100% utilization and big queues (likely bottlenecks).
     - Over-capacity skills with low utilization (opportunity to broaden responsibilities).

This tells you whether L2/L3 specialists are overused on basic tasks, and where key skills are causing systemic delay.

---

## 2. Identifying Resource-Related Bottlenecks and Issues

Using the metrics above, you systematically pinpoint where resource logic is failing.

### 2.1 Bottlenecks from skill scarcity

Indicators:

- High average **waiting time** before first “Work L2 Start” on tickets requiring specific skills (e.g., `Networking-Firewall`).
- Sustained **queue lengths** for certain skill-specific work queues.
- High **utilization** (>80–85%) of agents with that skill, coupled with SLA breaches for related tickets.

Quantification:

- For each skill:
  - Average delay before first qualified agent starts work.
  - % of SLA breaches on tickets requiring that skill vs others.
  - Example: “P2 Network-Firewall tickets wait on average 2.5 hours for first L2 work; 40% of their SLA breaches are due to this waiting time.”

---

### 2.2 Delays from reassignments and escalations

From the log, isolate events:

- `Escalate L2`, `Escalate L3`, `Reassign`, `Assign L2/L3`.

For each escalation/reassignment:

- Measure:
  - Time from decision (e.g., `Escalate L2`) to next “Work X Start”.
  - Additional queue time introduced compared to tickets with fewer handovers.

Quantification:

- Average extra time per:
  - Escalation (L1L2, L2L3).
  - Intra-tier reassignment (L2L2).
- Average # of such events per ticket, by category/priority.
- Derive:
  - “Each additional reassignment adds, on average, 1.2 hours to resolution time.”
  - “Tickets with 3 handovers have an SLA breach rate of 45%, vs 12% for tickets with 1 handover.”

This directly ties handovers to delays and breaches.

---

### 2.3 Impact of incorrect initial assignments

Look for:

- Cases where:
  - First assigned agent’s skills do not include the ticket’s final `Required Skill`.
  - Or where the ticket is escalated multiple times before reaching an agent with the required skill.

Measures:

- % of tickets where first agent is not skill-matched (based on `Required Skill` vs `Agent Skills`).
- Escalation rate when initial agent is mismatched vs matched.
- Incremental delay:
  - Average time to resolution for correctly matched-first vs mismatched-first tickets.
- SLA breach impact:
  - % SLA breach for mismatched-first vs matched-first tickets.

This quantifies how much poor initial assignment is costing.

---

### 2.4 Underperforming or overloaded agents/teams

**Overloaded:**

- Agents with:
  - High WIP.
  - High utilization.
  - Long queues before their “Work Start” events.
- Compare productivity:
  - Throughput (tickets closed per day) vs time spent.

**Underperforming:**

- Agents with:
  - Longer handling times than peers for same category/skill and priority.
  - Higher escalation rates for categories where peers succeed at L1.
  - Higher SLA breach rates on cases they touch compared to peers (adjusting for case mix).

Use process mining to benchmark:

- Filter to specific category+priority+skill.
- Compare distributions of handling time across agents.
- Identify outliers at both ends (top performers and laggards).

---

### 2.5 Correlating assignment patterns with SLA breaches

Define for each ticket:

- Features:
  - # of assignments, # of escalations, # of reassignments.
  - Total waiting time per tier.
  - Initial match (yes/no) between agent skills and required skill.
  - First tier that handled the ticket.
  - Use of specialists vs generic troubleshooters.
- Outcome:
  - SLA breach (yes/no).

Analyze:

- Simple statistics:
  - SLA breach rate by:
    - # of handovers.
    - Initial match vs mismatch.
    - Tier that finally resolved.
- More advanced:
  - Logistic regression or decision tree:
    - Dependent: SLA breach.
    - Independent: features above + priority, category.

You might find patterns like:

- “Controlling for priority and category, each additional assignment multiplies breach odds by 1.8.”
- “Tickets misrouted initially (no skill match) have 3× breach odds, even when resolved by the same ultimate skill.”

---

## 3. Root Cause Analysis for Assignment Inefficiencies

Having identified patterns, you now look for underlying causes.

### 3.1 Deficient assignment rules (round-robin, no skill/queue awareness)

Evidence from process mining:

- Round-robin patterns within a tier, regardless of category/skill.
- High mismatch between:
  - `Required Skill` of case.
  - Skills of the first assigned agent.
- Agents with specialist skills handling many generic tickets because they happen to be “next in line”.

Root cause:

- The assignment logic does not:
  - Check required skills.
  - Consider current workload.
  - Consider historical performance on similar tickets.

---

### 3.2 Inaccurate or incomplete skill profiles

Evidence:

- Frequent successful resolution of specialized categories by agents whose profiles do not list the corresponding skill.
- Conversely, agents with a listed skill almost never receiving or resolving those tickets.

Process mining approach:

- Infer **empirical skills** from history:
  - If an agent repeatedly resolves `App-CRM` tickets with good speed and low escalation, they likely have that skill.
- Compare empirical skills with documented skills.

Root cause:

- Skill matrix not maintained.
- Agents moved roles or gained skills without updates.
- Hiring/rotation not reflected in system.

---

### 3.3 Poor initial categorization or skill requirement identification

Evidence:

- Tickets whose `Ticket Category` changes mid-life.
- Tickets with early category A but resolved by skills typically associated with category B.
- Tickets with repeated reassignments and changing `Required Skill` values.

Variant analysis:

- **Smooth variants**:
  - Tickets with 0–1 handovers, quick resolution, no SLA breach.
- **Problem variants**:
  - Tickets with multiple reassignments, long delays, SLA breach.

Compare:

- How often initial category matches final `Required Skill` in smooth vs problem variants.
- Whether certain channels (e.g., phone vs email vs portal) show more misclassification.
- Whether certain dispatchers or teams produce more miscategorized tickets.

Root cause:

- Inadequate triage rules or forms.
- Poor use of templates / category trees.
- Insufficient dispatcher training.

---

### 3.4 Lack of real-time visibility into workload

Evidence:

- Some agents heavily overloaded while others are idle.
- Long queues for certain skills even when other similarly skilled agents are less utilized.
- Tickets assigned to busy specialists instead of available generalists, purely due to round-robin.

Root cause:

- The assignment mechanism doesn’t access:
  - Real-time WIP per agent.
  - Current queue lengths per skill.
  - Expected handling time.

---

### 3.5 L1 training and empowerment gaps

Evidence:

- Very low FCR at L1 for categories that peers elsewhere resolve at L1.
- Many tickets escalate to L2, but L2 quickly resolves with basic steps.
- L1 agents have higher handling times and higher escalation rates for certain categories.

Decision mining:

- At decision point “Escalate vs Resolve at L1”, mine rules:
  - Conditions under which L1 resolved successfully.
  - Conditions under which they escalated, then L2 resolved quickly.

Root cause:

- L1 lacks knowledge or confidence on certain categories.
- Missing or poor knowledge base support.
- Culture of “escalate early” rather than “attempt resolution”.

---

## 4. Developing Data-Driven Resource Assignment Strategies

Below are five concrete strategies informed by the analyses.

### Strategy 1: Skill- and Role-Based Routing (replacing blind round-robin)

**Issue addressed**

- Misassignment and unnecessary reassignments.
- Specialists doing generic work.
- Tickets initially going to agents without the required skills  delay, escalations.

**How it uses process mining insights**

- From organizational mining, you know:
  - Which agents functionally are CRM specialists, firewall specialists, etc.
- From skill utilization analysis, you know:
  - Which skills are critical, who uses them effectively, and their performance metrics.
- From root cause analysis, you know:
  - Misalignment between documented skills and empirical skills.

**Approach**

1. For each **ticket type** (Priority + Category + optionally subcategory):
   - Determine historically which skills and roles resolved these efficiently (low duration, low escalation).
2. Build a **routing map**:
   - E.g., P2+Network+Firewall  “Network-Firewall specialists (L2)” as primary pool; if none available, then “Senior Network generalists”.
   - P3+Software-App+CRM  “App-CRM specialists”; P4+Software-App  generic L1 troubleshooters where FCR is high.
3. Replace round-robin with:
   - Route each new ticket to the **smallest pool of agents** that:
     - Have the required skill.
     - Are historically efficient with such tickets.

Prioritize by proficiency:
- Rank agents by historical performance on that ticket type (e.g., average handling time, # of escalations).
- Within the pool, use fair distribution (but see Strategy 2).

**Data required**

- Historical performance per agent per ticket type.
- Accurate (and empirically validated) skill mappings.
- A “routing table” maintained in the ITSM tool.

**Expected benefits**

- Fewer misassignments, fewer reassignments.
- Reduced resolution time and escalation.
- Better use of specialists only where needed.

---

### Strategy 2: Workload- and Priority-Aware Dynamic Assignment

**Issue addressed**

- Uneven workload: some agents overloaded, others idle.
- Delays and SLA breaches for P2/P3 with long waits, despite available capacity elsewhere.

**How it uses process mining insights**

- From performance mining:
  - You know arrival patterns by hour/day and category.
  - You know typical handling times per agent and skill.
- You can estimate current and near-future load per agent.

**Approach**

Implement a **dispatch algorithm** that considers:

- Ticket priority (P2 > P3 > P4).
- Required skill / routing pool from Strategy 1.
- Current agent load:
  - # of active tickets.
  - Expected remaining time (based on average handling times).
- SLA urgency:
  - Remaining time to SLA per ticket.

Assignment rule:

- For each incoming ticket, select an agent in the appropriate skill pool who:
  - Is not overloaded (below a configurable WIP threshold).
  - Minimizes a cost function combining:
    - Priority (higher gets higher weight).
    - Expected waiting time before start.
    - SLA time remaining.

Alternatively, allow **“pull”**:
- Agents pull from prioritized skill queues.
- Queue rules ensure high-priority tickets surface first.

**Data required**

- Near real-time log of WIP per agent and queued tickets.
- Historical handling times by agent and ticket type.
- SLA definitions per priority.

**Expected benefits**

- Balanced utilization across agents.
- Shorter waiting times, especially for P2/P3.
- Lower SLA breach rates driven by queue delays rather than complexity.

---

### Strategy 3: Predictive Skill Inference and Complexity Classification

**Issue addressed**

- Poor initial assignment due to misclassification of tickets.
- Incorrect or late identification of required skills.
- Unnecessary escalations when L1 could resolve or when a specialist should handle from the start.

**How it uses process mining insights**

- Use past cases to train models:
  - For given ticket attributes at creation (Category, subcategory, channel, short description, keywords), predict:
    - Required Skill.
    - Likely Tier for first resolution.
    - Complexity level (e.g., “L1-solvable”, “needs L2/L3”).

**Approach**

1. Build a dataset:
   - Features: channel, initial category, free-text description (vectorized), time-of-day, customer segment.
   - Labels:
     - Final `Required Skill` (from resolution).
     - Tier where ticket was actually resolved.
     - Whether L1 successfully resolved without escalation.

2. Train ML models (e.g., gradient boosting, text-based models) for:
   - `Required Skill` prediction.
   - Binary classification: “L1 can resolve” vs “needs specialist”.

3. Integrate predictions into intake:
   - Pre-fill or suggest `Required Skill`.
   - Suggest tier/skill pool for assignment.
   - Flag tickets where L1 is unlikely to succeed  route directly to L2.

**Data required**

- Historical log with final resolver info and required skill.
- Access to full ticket descriptions.

**Expected benefits**

- Reduction in misrouted tickets and reassignments.
- Better match between first assigned agent and actual needs.
- Faster handling of complex tickets by sending directly to specialists.

---

### Strategy 4: Data-Driven Escalation Rules and L1 Empowerment

**Issue addressed**

- Over-escalation from L1 to L2/L3.
- Specialists handling tasks that are actually L1-solvable.
- Low L1 FCR for categories where it could be higher.

**How it uses process mining insights**

- Decision mining:
  - For each category/priority, analyze:
    - When L1 attempted resolution (time spent, steps taken).
    - The probability of successful resolution vs escalation.
- Identify categories where:
  - L1 succeeds X% with relatively low resolution time.
  - L1 escalates but L2 resolves quickly using basic steps.

**Approach**

1. For each category-subcategory and priority:
   - Compute L1 FCR and average L1 time-to-resolution.
   - Compute how often L1 escalates and how quickly L2/L3 resolves after escalation.

2. Define:
   - **L1-responsible catalog**:
     - Categories where L1 historically does well (high FCR, good speed).
   - **Escalate-directly catalog**:
     - Categories where L1 rarely succeeds and L2 resolves quickly.

3. Operational changes:
   - For L1-responsible categories:
     - Encourage/require L1 to do deeper troubleshooting before escalating.
     - Provide targeted knowledge articles based on L2’s historical fixes.
   - For escalate-directly categories:
     - Allow routing to L2 at intake (with required skill identified by Strategy 3).

4. Training:
   - Target training where L1 almost succeeds (FCR slightly below target).
   - Track improvements over time.

**Data required**

- Event log with clear tier activities and outcomes.
- Mapping of categories to knowledge base articles and resolution patterns.

**Expected benefits**

- Increased L1 FCR where feasible  fewer escalations.
- Reduced time waste where L1 cannot realistically resolve.
- Improved utilization of L2/L3 (less low-value work).

---

### Strategy 5: Dynamic Cross-Tier Staffing and Skill Rebalancing

**Issue addressed**

- Persistent bottlenecks for certain skills/tier combinations.
- L2/L3 idle time in some intervals, while L1 or other skills are overloaded.
- Seasonal/diurnal demand variation (e.g., Network incidents spikes on Mondays).

**How it uses process mining insights**

- From historical arrival patterns:
  - Identify time-of-day and day-of-week load per category/skill.
- From performance and utilization:
  - Know which tiers/skills are under- vs over-utilized.

**Approach**

1. Build time-series:
   - Ticket arrivals per category/priority per hour.
   - Average handling times per agent/skill by period.
2. Use simulation/forecasting (see Section 5) to:
   - Determine peak load periods for each skill.
   - Assess whether small reassignments (e.g., 1–2 L2s helping L1) could reduce queues.

3. Operationalize:
   - Define **flex pools**:
     - Agents who can work across tiers for specific tasks.
   - Schedule cross-tier activities:
     - During low L2 load, some L2s pick up L1 backlog for compatible tickets.
     - During L1 backlog, some trained L1 handle simple L2 tasks where they proved capable.

**Data required**

- Historical ticket arrival and handling patterns.
- Skill and cross-skill training data.

**Expected benefits**

- Better overall capacity utilization.
- Reduced peak-time bottlenecks without necessarily increasing headcount.
- More resilient SLA performance during surges.

---

## 5. Simulation, Implementation, and Monitoring

### 5.1 Using simulation to evaluate new assignment strategies

**Build a simulation model**

1. **Process model**
   - Discover the *as-is* process using Inductive Miner / Heuristic Miner.
   - Include key activities:
     - Ticket Created, Assign L1/L2/L3, Work Start/End, Escalate, Reassign, Resolve/Close.
   - Annotate with branching logic based on historical probabilities.

2. **Arrival patterns**
   - Use historical inter-arrival times:
     - By category, priority, time-of-day, day-of-week.

3. **Service times and resources**
   - For each activity and agent (or role):
     - Fit distributions (e.g., lognormal) for handling time.
   - Define resource pools by skill and tier.
   - Include working calendars (shifts, holidays).

4. **Assignment rules**
   - Implement current “round-robin + manual escalation” as the baseline scenario.
   - Implement proposed strategies as alternative scenarios:
     - Skill-based routing.
     - Workload- and priority-aware assignment.
     - Direct routing of predicted complex tickets to L2.

5. **SLA definitions**
   - Define P2/P3 SLAs in the simulator.
   - Track SLA compliance per scenario.

**Run what-if scenarios**

Examples:

- Scenario A: As-is routing.
- Scenario B: Skill-based routing only.
- Scenario C: Skill-based + workload-aware routing.
- Scenario D: Add predictive skill inference and direct L2 routing where indicated.
- Scenario E: Reassign some FTE from one skill pool to another.

Metrics to compare:

- Average and percentile resolution time per priority/category.
- SLA breach rate by priority.
- Average # of assignments / reassignments per ticket.
- Utilization per resource/skill pool.
- Queue lengths and waiting times for key skills.

Calibrate the model:

- Ensure that the simulation of the as-is scenario matches historical KPIs reasonably well before trusting “what-if” results.

---

### 5.2 Implementation roadmap (high level)

1. **Phase 1 – Transparency & quick wins**
   - Deploy process mining dashboards to expose current patterns.
   - Correct obvious skill profile inaccuracies (from empirical skill analysis).
   - Implement modest routing tweaks within the existing tool (e.g., basic skill-based assignment for clear-cut categories).

2. **Phase 2 – Assignment engine enhancements**
   - Introduce rule-based skill routing (Strategy 1).
   - Incorporate basic workload awareness in assignment rules (Strategy 2).
   - Pilot on selected categories (e.g., P2 Network and P3 Software-App).

3. **Phase 3 – Predictive and dynamic strategies**
   - Deploy ML-based skill inference and complexity classification (Strategy 3).
   - Adjust escalation policies and L1 training (Strategy 4).
   - Implement dynamic cross-tier staffing where justified by simulation (Strategy 5).

---

### 5.3 Monitoring with process mining dashboards

After implementation, use process mining for **continuous monitoring and control**.

**Key resource-related KPIs**

- **SLA & performance**
  - SLA compliance rate per priority and category.
  - Average and median resolution times.
  - Average waiting time before first work at each tier.
- **Assignments and reassignments**
  - Avg # of assignments and reassignments per ticket.
  - % of tickets with 2 reassignments.
- **Escalations**
  - Escalation rate from L1 to L2/L3 by category.
  - Time spent in L1 before escalation.
  - FCR at L1 per category/agent.
- **Resource utilization**
  - Utilization per agent and per skill pool.
  - WIP per agent over time.
  - Workload balance indicators (e.g., Gini coefficient over agent workloads).
- **Skill usage**
  - % of specialist time spent on specialized vs generic tasks.
  - Waiting time for key skills (e.g., Network-Firewall) over time.

**Process views to track**

- **Performance-enhanced process map**
  - Colored by average waiting time between activities and per tier.
  - Filterable by priority, category, skill.

- **Handover-of-work networks**
  - Monitor changes in handover patterns:
    - Expect fewer L1L2L2 zigzags.
    - Expect more direct L1closure or L1specialist.

- **Variant analysis**
  - Compare frequency of “clean” variants (few handovers, fast resolution) vs “messy” ones.
  - Watch for “messy” variants re-emerging under new policies.

- **Conformance checking**
  - Ensure new routing rules are followed:
    - Check that tickets of certain categories almost always go to the right skill pool.
    - Detect manual overrides and non-compliant assignments.

**Continuous improvement loop**

- Monthly review:
  - Identify new bottlenecks (e.g., growth in demand for a given skill).
  - Adjust routing rules and skill training.
- Feedback into simulation:
  - Use latest data to re-simulate and test further optimization (e.g., staffing changes).

---

By systematically mining the event log from resource, performance, and organizational perspectives, you can first *see* the real assignment behavior and its impact on SLAs, then design and validate targeted strategies (skill-based routing, workload-aware assignment, predictive triage, L1 empowerment, dynamic staffing), and finally monitor their effectiveness in an ongoing, data-driven way.