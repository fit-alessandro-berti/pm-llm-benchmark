## 1) Identifying instance-spanning constraints and quantifying impact

### 1.1 Shared packing stations (incl. limited Cold-Packing stations)
**How to identify from the log**
- Use **resource-centric interval reconstruction** from START/COMPLETE timestamps:
  - Each `Packing` event becomes an interval `[start, complete)` tied to `Station Sx/Cx`.
  - Build station timelines and compute overlaps, idle gaps, and queue buildup.
- Classify orders by `Requires Cold Packing = TRUE/FALSE` and isolate the subset that must use `Station C*`.

**What to quantify (impact metrics)**
- **Queue time before Packing** (per order type):
  - `Wait_for_Packing = Packing.START – ItemPicking.COMPLETE` (or predecessor completion).
  - Break down by `Cold vs Standard`, `Express vs Standard`, peak vs non-peak.
- **Resource utilization**:
  - Cold station utilization = busy_time / available_time (per station, per shift).
- **Implied queue length / WIP at Cold-Packing** (time series):
  - At time *t*: `#orders waiting for cold packing` inferred from “eligible to start packing” minus “started packing”.
- **Throughput loss due to capacity**:
  - Compare achieved throughput to theoretical throughput under observed service times:
    - e.g., max cold throughput  `(#cold_stations * available_time) / median_packing_duration_cold`.
- **Blocking probability**:
  - P(order waits > X minutes for cold station).

**Formal constraint statement**
- Capacity constraint: at most **5 concurrent Cold-Packing** activities facility-wide.

---

### 1.2 Batching for shipping label generation (synchronization across cases)
**How to identify**
- If the log has an explicit batch identifier (e.g., `System (Batch B1)`), it’s direct.
- If not, infer batches using **clustering rules** consistent with operations:
  - Same `Destination Region` (and possibly same carrier/cutoff window), and label generation timestamps close together.
- Detect a “synchronization point”:
  - Orders complete `Quality Check` but do not proceed immediately to `Shipping Label Gen.`

**Impact metrics**
- **Batch wait time**:
  - `Wait_for_Batch = ShippingLabel.COMPLETE – QualityCheck.COMPLETE`
  - If label gen has START/COMPLETE, use START for waiting and COMPLETE for duration.
- **Batch formation delay distribution**:
  - For each inferred/known batch: `max(QC.complete) – min(QC.complete)` within the batch.
- **Aging / tail impact**:
  - Fraction of orders whose end-to-end SLA miss is explained by batch wait (e.g., >30% of their cycle time after QC).
- **Batch size vs delay curve**:
  - Relationship between batch size and average batch wait.

**Formal constraint statement**
- Synchronization constraint: label generation is triggered by **group readiness**, not individual readiness.

---

### 1.3 Priority handling (Express orders preempting Standard)
**How to identify**
Priority/preemption can show up in multiple ways depending on logging fidelity:

1) **Direct preemption evidence** (best case):
- If the system logs `SUSPEND/RESUME` or resource handoff events, you can quantify preemption explicitly.

2) **Indirect preemption inference** (common in warehouses):
- A standard order is “ready” for a resource but waits while express orders start/complete on that same constrained resource class.
- Approach:
  - Build a **time-ordered queue** for each resource pool (Cold stations, standard stations, QC staff pool).
  - For each standard case waiting interval, count how many express jobs started during that wait.

**Impact metrics**
- **Added waiting time for Standard due to Express** (incremental delay):
  - For each standard order, estimate “counterfactual earliest start” under non-preemptive FIFO vs observed start.
  - Aggregate: average/median extra minutes, and tail (P95) impact.
- **Priority inversion / starvation indicators**:
  - Number of times a standard order’s waiting time exceeds a threshold while express jobs continue to be served.
- **Express SLA benefit vs Standard penalty**:
  - Compare express lead time improvement against standard lead time degradation.

**Formal constraint statement**
- Scheduling constraint: express jobs have **higher priority** and may be **preemptive** (or effectively preemptive via queue-jumping).

---

### 1.4 Regulatory compliance: max 10 hazardous orders simultaneously in Packing or Quality Check
**How to identify**
- Filter cases with `Hazardous Material = TRUE`.
- Reconstruct intervals for:
  - `Packing` (START–COMPLETE)
  - `Quality Check` (START–COMPLETE)
- Compute concurrency over time: at each time *t*, count hazardous intervals active in either activity.

**Impact metrics**
- **Compliance metric (hard)**:
  - `Max concurrent hazmat (Packing  QC)` and number/duration of violations (should be 0).
- **Throughput restriction metric (soft)**:
  - Fraction of time the hazmat WIP cap is “binding”:
    - `%time concurrency == 10`
  - **Hazmat blocking time**:
    - For hazardous orders: waiting time before Packing/QC attributable to the cap being reached.
- **Spillover to non-hazmat orders**:
  - If shared staff/resources are involved, measure whether hazmat regulation indirectly increases waits for non-hazmat.

**Formal constraint statement**
- Global WIP cap: `#hazmat_in(Packing or QC)  10`.

---

### 1.5 Separating within-instance vs between-instance waiting
Use timestamp types to decompose each step into:
- **Service time (within-instance)**: `Activity.COMPLETE – Activity.START`
- **Inter-activity waiting**: `NextActivity.START – PrevActivity.COMPLETE`

Then attribute inter-activity waiting into *between-instance* causes using resource/batch signals:

**Attribution logic (practical and auditable)**
1) **Resource contention** (between-instance):
- During the waiting interval, required resource pool utilization is high (e.g., cold stations busy).
- “Could not start because no capacity” test:
  - If all eligible stations are occupied for a substantial portion of the wait, classify as resource-wait.

2) **Batching wait** (between-instance):
- Waiting occurs specifically between QC complete and label gen, and batch trigger conditions not yet met (batch not released).

3) **Priority displacement** (between-instance):
- During a standard order’s waiting interval, express orders begin service on the same pool ahead of it.

4) Residual:
- If none apply, treat as **internal delay** (within-case issues like missing items, exceptions, rework) and investigate separately.

This yields a **waiting-time breakdown** per order and per segment, which is what you need to target improvements.

---

## 2) Analyzing interactions between constraints (why they matter)

Instance-spanning constraints won’t act independently; key interactions to test explicitly:

### Interaction A: Express × Cold-Packing scarcity
- Express orders that require cold packing will **consume the scarcest capacity** and can produce:
  - Large queue spikes for standard cold orders
  - Increased “priority penalty” because preemption happens inside a tight bottleneck
- Measure: correlation between express cold arrivals and subsequent cold queue length / waiting times.

### Interaction B: Batching × Express
- If batching is region-based, express orders may either:
  - (a) bypass batching (if rules allow)  improves express SLA but may reduce batching efficiency, or
  - (b) get forced into batches  defeats express promise and creates SLA misses.
- Measure: express orders’ time from QC complete to label gen vs standard, by region/cutoff.

### Interaction C: Hazmat cap × Batching (same region)
- If many hazardous orders for the same region are ready around the same time, batching can unintentionally **synchronize** them, causing:
  - Long waits upstream because the hazmat WIP cap blocks Packing/QC starts
  - Large release bursts that hit the cap again (oscillation)
- Measure: time periods where hazmat concurrency hits 10 coinciding with batch releases.

### Interaction D: Hazmat cap × Priority
- If express hazmat exists, prioritizing it may “crowd out” standard hazmat and keep the cap binding longer, increasing total blocking.

**Why this is crucial**
- If you optimize batching without accounting for hazmat caps, you can worsen compliance pressure.
- If you add cold capacity without changing priority rules, you may still see standard-order starvation at peaks.
- The best levers are often **policy changes** (release rules, batch triggers, priority discipline), not just adding capacity.

---

## 3) Constraint-aware optimization strategies (concrete, interdependency-aware)

### Strategy 1 — Cold-Packing capacity management + smarter dispatching (addresses: Cold scarcity, Priority interaction)
**Change proposed**
- Introduce **two-tier dispatching** for cold stations:
  1) Reserve **1 cold station** (or a configurable fraction of time) for Express cold orders during peak windows.
  2) For remaining stations, use **shortest-processing-time or due-date–aware** sequencing (based on historical packing durations and SLA deadlines), not pure FIFO.
- Add **demand prediction** (hourly forecast) using recent arrival patterns:
  - Predict cold-order arrival rate by hour/day; adjust reservation dynamically.

**How it uses data**
- From logs: fit distributions for cold packing duration by SKU mix / order attributes.
- From logs: forecast arrivals (time series) for express cold.

**Expected outcomes**
- Lower express SLA misses **without runaway starvation** of standard cold orders.
- Reduced cold queue volatility; better utilization of non-reserved cold capacity.
- Measurable KPI improvements:
  -  P95 wait_for_cold_packing
  -  on-time shipment for express cold
  - Stable standard lead times vs current preemption behavior

---

### Strategy 2 — Replace “wait-for-full-batch” with dynamic batching triggers (addresses: Batching delays, Express, Hazmat interaction)
**Change proposed**
Implement **hybrid batching** for Shipping Label Generation:
- Release a batch when *either*:
  1) Batch reaches target size (efficiency), **or**
  2) Oldest order in region hits a **max-wait threshold** (service guarantee), **or**
  3) A carrier cutoff time is approaching (deadline-based).
- Add an explicit rule: **Express orders bypass batching** or have much smaller batch thresholds.

For hazmat-heavy regions:
- Add a “hazmat-aware” rule limiting how many hazmat orders are released into downstream steps at once (avoid synchronized bursts).

**How it uses data**
- Estimate the cost curve: batching efficiency gain vs delay cost (from historical delivery performance).
- Learn region-specific optimal thresholds (North may batch quickly; South might need time-based release).

**Expected outcomes**
- Large reduction in post-QC waiting (a frequent hidden contributor to lead time).
- Better predictability: fewer extreme tail cases waiting “for the batch”.
- Maintains routing efficiency while protecting SLA:
  -  avg and P95 wait_for_batch
  -  on-time dispatch rate
  -  SLA misses caused by label-generation waiting

---

### Strategy 3 — Non-preemptive priority at safe boundaries + dedicated express lane for bottlenecks (addresses: Priority handling, Cold, QC contention)
**Change proposed**
Instead of pausing in-progress work, adopt:
- **Non-preemptive priority**: once a packer starts an order, it completes; priority applies only when selecting the *next* job.
- Create a small **express lane** at key bottlenecks:
  - One QC staff member per shift (or time-sliced capacity) primarily handles express arrivals.
  - If no express is waiting, they help standard.

If cold packing is the bottleneck, combine with Strategy 1’s station reservation.

**How it uses data**
- Quantify how much time is currently lost due to interruptions/context switching (inferred from longer cycle times and resource switching patterns).
- Identify when express peaks occur to staff the express lane only when needed.

**Expected outcomes**
- Improved flow efficiency (less partially-done work, less station thrashing).
- Express stays fast, but standard becomes more stable:
  -  variance of packing durations (less “hidden pauses”)
  -  standard starvation events
  -  overall throughput due to reduced switching losses

---

### Strategy 4 — Enforce and shape the hazmat WIP cap via controlled release (addresses: Hazmat limit, interactions with batching/priority)
**Change proposed**
Treat the hazmat limit as a **managed WIP constraint** (like Kanban):
- Introduce a **hazmat gate** before Packing (or before QC, whichever is binding):
  - Only allow a new hazmat order into Packing/QC if current hazardous concurrency < 10.
- Add **sequencing** inside hazmat:
  - Prioritize by due date, then by shortest expected processing time (to keep WIP moving).
- If batching causes bursts, integrate with Strategy 2 to avoid synchronized releases.

**How it uses data**
- From logs: identify whether Packing or QC is the primary hazmat bottleneck (cap-binding location).
- Simulate different gating points and rules to minimize blocking.

**Expected outcomes**
- Guaranteed compliance with fewer “cap-binding” episodes.
- Better throughput stability (fewer stop-and-go waves):
  -  hazmat blocking time
  -  %time concurrency==10
  -  hazmat throughput without violating the cap

(If you only want three strategies, treat this as an optional fourth; in practice it’s often high impact.)

---

## 4) Simulation and validation (constraint-respecting “digital twin”)

### Approach
Build a **discrete-event simulation (DES)** informed by mined parameters (a process-mining-to-simulation pipeline):
- Control-flow model: Order Received  Picking  Packing  QC  Label Gen.
- Attach:
  - **Resource pools**: pickers, standard stations, cold stations (capacity=5), QC staff, label-gen system.
  - **Calendars**: shift schedules, breaks, peak season staffing differences.
  - **Routing logic**: cold vs standard, hazmat flags, express vs standard priority.
  - **Batching logic**: region-based batch formation and release policies.
  - **Hazmat WIP cap**: concurrency limit across Packing+QC for hazmat cases.

### What to focus on to make it realistic
1) **Arrival patterns** (non-stationary):
- Use time-dependent arrival rates (hour-of-day/day-of-week), especially for peaks.

2) **Service-time distributions by segment**:
- Packing duration differs by cold/non-cold, hazmat handling, order size (if available).
- QC duration likewise.

3) **Queue disciplines**:
- Implement explicit priority rules (preemptive vs non-preemptive) and test both.

4) **Batch formation**:
- Explicitly model batch triggers and cutoff times.
- Label generation as a (fast) activity but with batching-induced waiting.

5) **Global hazmat cap**:
- Enforced across two activities simultaneously (Packing OR QC), not per station.

### Validation
- Calibrate until the simulation reproduces baseline:
  - Lead time distribution (avg/median/P95)
  - Queue-time distributions per step
  - Utilization patterns
  - Batch wait times and batch sizes
  - Hazmat concurrency time series

### Experiments (what you compare)
- Baseline vs each strategy vs combined strategies:
  - End-to-end cycle time, on-time shipment %, express SLA %, throughput/day
  - Standard-order penalty (must be bounded)
  - Compliance (0 violations)
  - Robustness under peak arrival scenarios (stress test)

---

## 5) Post-implementation monitoring (process mining dashboards + operational control)

### Core KPI dashboard (executive)
- **On-time shipment rate** (overall, by express/standard, by region)
- **End-to-end lead time** distribution (median, P90/P95)
- **Throughput/day** and backlog size

### Constraint-specific control dashboards (operations)

**A) Cold-Packing station dashboard**
- Queue length over time (estimated WIP waiting for cold packing)
- Wait_for_cold_packing (avg/P95) split by express/standard
- Cold station utilization and starvation/idle detection
- “Reservation effectiveness”: %time reserved capacity is used by express vs wasted

**B) Batching dashboard**
- Batch sizes by region and time window
- Batch wait time (QC complete  label gen start/complete)
- % orders exceeding max-wait threshold (new policy compliance)
- Cutoff misses attributable to batching

**C) Priority handling dashboard**
- Standard-order delay attributed to express (incremental waiting estimate)
- Count of “near-starvation” events (standard waiting > threshold while express served)
- Express SLA adherence at each stage (not just end-to-end)

**D) Hazmat compliance & flow dashboard**
- Time series of hazardous concurrency across Packing+QC
- %time at cap (=10), and any violations (=0 target)
- Hazmat blocking time before Packing/QC
- Throughput of hazmat orders vs non-hazmat (ensure no unintended collapse)

### Monitoring method
- Use **conformance checking** against the new policies:
  - Batch max-wait rule adherence
  - Priority rule enforcement (non-preemptive boundaries)
  - Hazmat gate compliance
- Add **alerting**:
  - Cold queue > threshold for X minutes
  - Batch wait approaching threshold
  - Hazmat concurrency approaching 10 with rising arrivals

---

If you share the actual event log schema (column names, whether START/COMPLETE exist for all activities, whether batches are explicitly logged, and whether resource calendars are available), I can specify the exact queries/features to compute each metric and outline a minimal “analysis-to-simulation” data pipeline.