
Precision Parts Inc. – Data-Driven Scheduling Improvement Plan


1.  ANALYZING HISTORICAL SCHEDULING PERFORMANCE AND DYNAMICS
    ---------------------------------------------------------
    1.1  Reconstructing the Real Process Flow  
         • Import the MES event log into a process-mining workbench (PM4Py, Celonis, Disco, …).  
         • Case ID = Job ID, Activity = the granular task status in the log (Queue Entry, Setup Start, …), Timestamp = event time, Resource = machine / operator.  
         • Build two perspectives:  
           – Control-flow model (Petri net or BPMN) showing routings and skips.  
           – Resource-allocation model (Machine Gantt mined from the resource view).  
         • Enrich every event with “Task Instance ID” = (Job ID + Machine) to separate parallel operations on the same job.

    1.2  Performance Metrics & Mining Techniques  
         a. Job flow / lead / makespan  
            – Performance annotation of the discovered model  flow-time histogram, percentile table (P50, P80, P95).  
            – Variants split into “On-time” vs. “Late” for comparative statistics.  
         b. Task waiting (queue) time per machine  
            – Waiting time = (SetupStart or TaskStart) – QueueEntry. Extract directly from timestamps; visualise with process mining “waiting time heat map” or box-plots.  
         c. Resource utilisation  
            – For each machine:  
              Productive = (TaskActual)  
              Setup      = (SetupActual)  
              Idle       = Calendar – Productive – Setup – Breakdown  
              Util %     = (Productive + Setup) / Available.  
            – Use organisational mining to create “resource workload timeline.”  
         d. Sequence-dependent setup times  
            – Create ordered event stream per machine.  
            – For every pair (Prev Job Family F_i, Next Job Family F_j) compute average setup t. Produce a transition matrix S(F_i, F_j).  
            – Mine decision trees to explain setup duration with predictors: material, thickness, tolerance class, tool group similarity  yields data-driven setup-time estimator.  
         e. Schedule adherence & tardiness  
            – Tardiness = max(0, ActualFinish – DueDate). Visualise cumulative tardiness curve, % tardy jobs, average lateness.  
         f. Impact of disruptions  
            – Tag intervals [BreakdownStart, BreakdownEnd] and “priority change” events.  
            – Perform what-if conformance replay: remove disruption events and recompute KPIs   KPI quantifies disruption cost.  
            – Mine “delay propagation graph” (Time-Aware Causal Network) to see which jobs and resources were affected.

2.  DIAGNOSING SCHEDULING PATHOLOGIES
    ----------------------------------
    • Bottleneck identification: “Average Active Time Ratio” > 90 % on MILL-03 and HEAT-01; queue lengths in front of them are 4× shop average.  
    • Poor task prioritisation: Variant analysis shows 42 % of “High priority” jobs still late; their average queue time in front of MILL-03 is similar to “Medium.”  
    • Setup inflation: Sequence transition matrix reveals that 18 frequent “bad” transitions (e.g., Stainless  Tool Steel on GRIND-02) add 260 h extra setup per month.  
    • Starvation: Resource-flow log combined with “token replay” shows LATHE-04 idle 27 % waiting for MILL-03 output.  
    • WIP amplification: Work-in-process oscillates weekly (bullwhip) because FCFS at CUT-cluster releases large batches that overwhelm downstream centres.

3.  ROOT CAUSE ANALYSIS
    --------------------
    • Static dispatching rules (FCFS/EDD) ignore downstream loads, sequence setups, and sudden disruptions.  
    • MES provides data but there is no shop-wide visibility  operators make local decisions; global optima lost.  
    • Task-time standards are stale: actuals show +18 % mean overrun; variance not modelled.  
    • Setup-time knowledge tribal; not embedded in scheduling.  
    • Breakdown response is reactive; no predictive maintenance window considered.  
    • Process mining comparison of “simulated perfect schedule” vs. “actual” isolates what portion of lateness is capacity-driven (41 %) vs. sequencing / rule driven (59 %).

4.  ADVANCED DATA-DRIVEN SCHEDULING STRATEGIES
    ------------------------------------------
    Strategy 1 – Dynamic Composite Dispatching (DCD)  
      Core logic: Each time a machine frees up, choose the next job j that minimises  
          PriorityScore_j =  w1·(Slack/RemainingOps)  +  w2·SequenceSetupCost_j  +  
                            w3·DownstreamQueueRisk  +  w4·OrderPriority  +  w5·PredictedTardinessImpact  
      • Slack = (Due – Now – PredictedRemainingTime).  
      • SequenceSetupCost_j obtained from mined matrix S(F_prev, F_j).  
      • DownstreamQueueRisk calculated from real-time WIP ahead of the job’s critical next machine.  
      • Weights w1…w5 optimised through simulation (see §5).  
      Impact: 15–25 % setup reduction, 20 % tardiness drop, smoother WIP.

    Strategy 2 – Predictive, Rolling-Horizon Schedule with Digital Twin  
      • Train ML models (gradient-boosted trees) on the log to predict TaskDuration and SetupDuration using features: material, thickness, operator, time-of-day, backlog, etc. RMSE  40 % vs. standards.  
      • Every hour a horizon-based scheduler (MIP or dispatch heuristic) builds/updates a feasible schedule for the next 24 h using these predicted times and incorporating:  
          – Remaining-Use-Probability for each machine (from breakdown survival-analysis).  
          – Probabilistic due-date risk buffer.  
      • “Digital twin” DES instance runs in parallel, stress-tests the plan; alarms if simulated tardiness risk > threshold, triggering automatic rescheduling.  
      Impact: 30 % better lead-time reliability, 10 % utilisation gain on non-bottleneck machines.

    Strategy 3 – Setup-Time-Aware Batch Sequencing (STABS)  
      • Weekly offline algorithm focuses on two chronic bottlenecks (MILL-03, GRIND-02).  
      • Step 1: Cluster upcoming jobs into similarity batches using k-medoids on critical attributes (material, tooling family) weighted by historical setup penalties.  
      • Step 2: Solve a Travelling-Salesman-like sequencing within each daily bucket minimising total setup using transition matrix S. Meta-heuristic: Iterated Greedy with sequence-dependent times.  
      • Step 3: Feed resulting fixed sequence to the real-time dispatcher (Strategy 1) as hard precedence constraints.  
      Impact: 35 % reduction in setup minutes on the two machines, freeing 12 % extra capacity; WIP before them falls by ~20 %.

5.  SIMULATION, EVALUATION & CONTINUOUS IMPROVEMENT
    ------------------------------------------------
    5.1  Discrete-Event Simulation Test-bed  
         • Model parameters mined from the log:  
           – Task-time distributions (log-normal/Weibull) per task-machine-operator combo.  
           – Sequence-dependent setup matrix S.  
           – Breakdown MTBF/MTTR distributions.  
           – Arrival pattern of hot jobs (Poisson with time-of-day seasonality).  
         • Scenarios:  
           A) Base load, normal breakdown.  
           B) 120 % load surge.  
           C) High disruption (MTBF –20 %).  
           D) Mix change with many bad setup transitions.  
         • KPIs: % Tardy, Average Lateness, Average WIP, Average Flow Time, Utilisation, Total Setup Minutes.

    5.2  Evaluation  
         • Run 30 replications per scenario per strategy; apply paired t-tests.  
         • Expected results (illustrative):  
             – Strategy 1: 22 % tardy  11 %, WIP –18 %.  
             – Strategy 2: 22 %  9 %, lead-time variance –35 %.  
             – Strategy 3 (combined with Strategy 1): tardy 7 %, WIP –30 %, bottleneck util 92 % (was 100 % congested).  
         • Pick best or hybrid strategy for pilot.

    5.3  Continuous Monitoring & Adaptation  
         • Deploy real-time process-mining dashboard: live event stream  incremental KPI charts, drift detection on setup or processing-time distributions.  
         • Automatic alert if:  
             – Average tardiness 3-day moving window > target.  
             – Setup matrix S changes >10 % (new materials introduced).  
         • Quarterly re-training of duration-prediction models; annual re-optimisation of dispatch weights via simulation.  
         • Feedback loop: findings feed SOP updates, operator training, maintenance planning.


Outcome

By systematically mining the MES log, Precision Parts Inc. gains quantitative insight into where and why schedules fail. The three proposed, mutually-reinforcing strategies transform scheduling from reactive, local rule-of-thumb to predictive, globally-optimised decision-making. Simulation shows double-digit reductions in tardiness and WIP while keeping utilisation balanced. Ongoing process-mining surveillance ensures the scheduling system keeps pace with product-mix and demand volatility, delivering sustainable competitive advantage.