### 1. Queue Identification and Characterization

In queue mining, waiting time (queue time) for a patient is defined as the duration between the completion of the previous activity and the start of the next activity in that patient's trace. For example, for patient V1001, the waiting time before Nurse Assessment is the time from Registration COMPLETE (09:08:45) to Nurse Assessment START (09:15:20), resulting in approximately 6.7 minutes. Waiting time before Doctor Consultation would be from Nurse Assessment COMPLETE (09:25:10) to Doctor Consultation START (09:45:55), approximately 20.8 minutes. This excludes any service (processing) time within activities themselves, focusing purely on idle time in queues.

To calculate these systematically from the event log:
- For each case (visit ID), sort events chronologically.
- Identify consecutive pairs of activities (e.g., Registration → Nurse Assessment → Doctor Consultation → Diagnostic Tests → Check-out).
- Compute waiting time as: Timestamp_START(next_activity) - Timestamp_COMPLETE(previous_activity).
- Aggregate waiting times per transition (e.g., "after Registration", "after Nurse Assessment", "after Doctor Consultation").

Key metrics to characterize each queue/transition:
- **Average (mean) waiting time**: Indicates typical delay.
- **Median waiting time**: More robust to outliers in skewed distributions common in healthcare.
- **90th percentile waiting time**: Captures experience of the "worst" 10% of patients, critical for satisfaction.
- **Maximum waiting time**: Highlights extreme cases.
- **Queue frequency**: Percentage of cases that go through this transition and experience any wait (>0 minutes).
- **Number/proportion of cases with excessive waits**: Define "excessive" threshold (e.g., >30 minutes) based on clinic targets or benchmarks.
- **Queue length proxies**: Average number of patients simultaneously waiting (estimated via overlapping waiting periods).

To identify the most critical queues:
- Prioritize by a composite score: e.g., (average waiting time × frequency of transition × number of affected cases).
- Focus on transitions with highest 90th percentile waits, as patient dissatisfaction is often driven by worst-case experiences.
- Segment by patient type (New vs. Follow-up) or urgency (Normal vs. Urgent) — queues disproportionately affecting urgent or new patients may be prioritized higher due to clinical risk or revenue impact.
- Transitions affecting the largest number of patients (e.g., post-registration or post-nurse) typically emerge as critical.

### 2. Root Cause Analysis

Root causes of significant queues extend beyond location and include resource constraints, process design, and variability.

Potential root causes:
- **Resource bottlenecks**: Insufficient staff, rooms, or equipment during peak hours; specific resources (e.g., certain specialists or diagnostic rooms) over-utilized.
- **Activity dependencies and handovers**: Sequential flow forces patients to wait for downstream availability; poor coordination between departments.
- **Variability in service times**: High variation in doctor consultation or test durations leads to unpredictable downstream availability (classic queueing theory effect: variability amplifies waits).
- **Appointment scheduling policies**: Overbooking, fixed slot lengths ignoring patient type differences, or poor staggering of arrivals.
- **Patient arrival patterns**: Walk-ins, no-shows, or bunching of scheduled arrivals creating peaks.
- **Patient characteristics**: New patients may require longer registrations/assessments; urgent cases may disrupt scheduled flow.

Process mining techniques to pinpoint root causes using the event log:
- **Bottleneck analysis**: Compute resource utilization (total active time per resource / available time) and identify resources with highest utilization correlated with downstream queues.
- **Resource frequency and performance views**: Dotted charts or resource heatmaps showing which staff/rooms are involved in long-wait transitions.
- **Variant analysis**: Discover process variants (common patient paths) using tools like fuzzy/inductive miner; compare waiting times across variants (e.g., patients needing diagnostics vs. consultation-only).
- **Performance overlay on process model**: Project waiting times on discovered Petri net or BPMN model to visualize bottleneck edges.
- **Social network analysis/handover of work**: Measure handover inefficiency between resources (e.g., frequent transfers between nurses and doctors causing delays).
- **Time-based filtering**: Analyze queues by hour/day to detect peak patterns linked to scheduling or staffing.
- **Attribute correlation**: Filter or compare metrics by patient type, urgency, or specialty to reveal differential impacts.

### 3. Data-Driven Optimization Strategies

**Strategy 1: Dynamic staffing allocation based on peak demand patterns**  
- **Targeted queue(s)**: Primarily post-registration and post-nurse assessment (common entry points to clinical areas).  
- **Root cause addressed**: Resource bottlenecks during peak hours and mismatch between fixed staffing and variable patient arrival patterns.  
- **Data support**: Time-based analysis shows high waits concentrated in specific hours/days; resource utilization metrics reveal under-staffing in those periods.  
- **Positive impacts**: Expected 20–40% reduction in average waiting time during peaks by adding flexible float staff or shifting schedules; overall visit duration reduced by 10–20 minutes on average.

**Strategy 2: Differentiated appointment scheduling templates by patient type and specialty**  
- **Targeted queue(s)**: Waiting before doctor consultation and before diagnostic tests.  
- **Root cause addressed**: One-size-fits-all slot lengths ignoring variability in service times (e.g., new patients or complex specialties take longer).  
- **Data support**: Variant analysis and service time distributions show significantly longer durations for new patients or certain specialties; correlation between scheduled slot and downstream waits.  
- **Positive impacts**: Reduce average wait before consultation by 15–30% by allocating longer slots for high-variability cases, smoothing flow and reducing backlog propagation.

**Strategy 3: Parallelization of non-dependent activities (e.g., order diagnostics early)**  
- **Targeted queue(s)**: Waiting for diagnostic tests after doctor consultation.  
- **Root cause addressed**: Strictly sequential flow and activity dependencies; doctors often order tests only after seeing patient.  
- **Data support**: Process variants reveal that in cases where tests are needed, sequential ordering adds substantial wait; comparison of current vs. potential parallel paths (simulated via historical reorderings) shows delay.  
- **Positive impacts**: Potential 25–50% reduction in wait time for diagnostic tests for relevant cases; overall visit duration shortened by 15–30 minutes for patients requiring tests, improving throughput without adding resources.

### 4. Consideration of Trade-offs and Constraints

Potential trade-offs:
- **Dynamic staffing**: Increases labor costs (overtime or float pool) and may raise staff fatigue if shifts are frequently adjusted. Risk of over-staffing during unexpectedly quiet periods.
- **Differentiated scheduling**: Longer slots for complex cases reduce daily appointment capacity per provider, potentially increasing access wait times (days to next available appointment) or requiring careful capacity planning.
- **Parallelization of diagnostics**: Early test ordering may lead to unnecessary tests if doctor later deems them unneeded (increasing costs and patient discomfort); requires protocol changes and physician buy-in to avoid quality risks.

Balancing conflicting objectives:
- Use simulation (what-if analysis in process mining tools) to quantify trade-offs before implementation — e.g., model cost increase vs. wait time reduction.
- Prioritize low-cost/high-impact changes first (e.g., scheduling adjustments over additional hires).
- Involve clinical staff in design to safeguard care quality; set guardrails (e.g., clinical decision support for early test ordering).
- Adopt phased rollout with A/B testing on subsets of specialties or days to monitor unintended effects.
- Align incentives: link improvements to shared goals (patient satisfaction scores, revenue from higher throughput).

### 5. Measuring Success

Key Performance Indicators (KPIs) post-implementation:
- **Primary**: Average and 90th percentile total waiting time per visit; average total visit duration (arrival to check-out complete).
- **Secondary**: Waiting time per critical transition (e.g., before doctor, before diagnostics); patient satisfaction scores (from surveys, correlated with wait times); daily patient throughput (volume handled without increasing staff hours).
- **Balancing**: Staff utilization rate (avoid over-work); proportion of on-time appointments; no-show rate; cost per visit or staffing cost per patient.

Ongoing process monitoring:
- Continue collecting the same structured event log (start/complete timestamps mandatory).
- Establish a dashboard refreshed weekly/monthly recalculating the same queue metrics, process model with performance overlay, and segmented KPIs.
- Set control limits (e.g., statistical process control charts) on key waiting time metrics to detect deviations early.
- Periodic conformance checking: compare actual traces against redesigned target process model to identify drift.
- Quarterly deep dives: re-run variant and root-cause analyses to catch emerging issues (e.g., seasonal changes or new specialties).

This structured, iterative approach ensures sustained data-driven improvement while adapting to evolving clinic dynamics.