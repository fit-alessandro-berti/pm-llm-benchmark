1. Queue Identification and Characterization  
----------------------------------------------------------------  
• Defining waiting time  
  - For each visit (Case ID) and for each adjacent activity pair AB:  
    WaitingTime(AB) = Timestamp(Start-B) – Timestamp(Complete-A)  
  - If Start-B < Complete-A (overlap or logging skew), treat as zero or investigate log quality.  
  - Example: For V1001, wait between Nurse Assessment COMPLETE (09:25:10) and Doctor START (09:45:55) = 20m45s.  

• Key queue metrics  
  – Average waiting time per queue (AB)  
  – Median and 90th (or 95th) percentile waits to capture tail delays  
  – Maximum wait (outliers)  
  – Queue frequency: % of cases experiencing positive wait  
  – Volume of cases per queue (to weight impact)  
  – Count (or % ) of cases exceeding threshold (e.g., > 30 min)  

• Identifying critical queues  
  – Rank queues by a “Queue Impact Score” = AverageWait × CaseVolume  
  – Highlight queues with high 90th percentile (severe outliers)  
  – Prioritize queues that disproportionately affect urgent or newpatient cohorts  
  – Focus immediate action on top 2–3 queues by this composite ranking  

2. Root Cause Analysis  
----------------------------------------------------------------  
• Resource bottlenecks  
  – Compute resource utilization (busy time ÷ available time) per staff/room  
  – Identify over-utilized (“hot”) resources causing downstream waits (e.g., single ECG room at 95% utilization)  

• Activity dependencies & handovers  
  – Use handover mining to see clusters of handovers between teams (e.g., NurseDoctor backandforth loops)  
  – Long delays often correlate with crossdepartment handovers  

• Variability in service times  
  – Analyze distribution of activity durations; high variance suggests unpredictable service  
  – Correlate long service times with longer subsequent waits (queuing theory: higher variability  longer queues)  

• Appointment scheduling patterns  
  – Overlay arrival timestamps vs. scheduled slots to detect bunching (e.g., morning “blocks” of new patient slots every hour)  
  – Identify “no-show” or walk-in peaks that shift load  

• Patienttype segmentation  
  – Perform variant analysis: compare queues for New vs. Follow-up vs. Urgent  
  – E.g., Urgent cases may cut the line but create idle downstream resources when slots are unfilled  

• Tools & techniques  
  – Bottleneck analysis (process throughput bottlenecks in Disco/Celonis)  
  – Dotplot & histogram visualizations of waits/durations  
  – Conformance checking to detect unplanned loops or skipped steps  
  – Resource calendar analysis (staff rosters vs. actual activity timestamps)  

3. Data-Driven Optimization Strategies  
----------------------------------------------------------------  
Strategy A: Dynamic Staffing Alignment for Peak Periods  
  • Targets: RegistrationNurse Assessment and Nurse AssessmentDoctor Consultation queues  
  • Root cause: Staff supply misaligned with patient arrival peaks (e.g., too few nurses 9:30–11:00)  
  • Data support: Utilization curve shows nurse utilization > 90% at 09:30–10:30; waiting times spike by +15 min (avg)  
  • Proposal:  
    – Reallocate 1–2 nurse shifts from lulls (post-lunch) to morning peak  
    – Implement part-time “float” nurse on call for surge support  
  • Expected impact:  
    – Reduce avg nurseassessment wait by 30 % (from 12 min  8 min)  
    – Speed downstream doctor start times by ~10 min, reducing total visit by ~8 %  

Strategy B: Staggered & Priority-based Appointment Scheduling  
  • Targets: Registration and Doctor Consultation start delays  
  • Root cause: Bulk scheduling of new patients on the hour causing registration queues, then doctor backlog  
  • Data support: 50 % of newpatient slots at 9:00/10:00; registration wait median 6 min, 90th percentile 20 min  
  • Proposal:  
    – Stagger newpatient appointments in 10-min intervals within each hour  
    – Reserve “floating” slots for urgent/walk-in cases to absorb variability  
    – Use simulation of the event log to fine-tune slot intervals  
  • Expected impact:  
    – Lower registration 90th percentile wait from 20 min  8 min  
    – Smooth registration throughput leading to fewer downstream doctor idle/burst cycles  

Strategy C: Parallelized Pre-Visit Diagnostics & Self-Service Registration  
  • Targets: Blood Test, X-Ray queues; Registration queue  
  • Root cause: Sequential routing forces patients to complete registration before diagnostics; front-desk clerks become choke points  
  • Data support: 20% of cases require lab/imaging; wait from RegistrationBlood Test START avg 18 min; registration avg service time 6 min  
  • Proposal:  
    – Deploy self-service kiosks or mobile check-in app for low-complexity patients (e.g., follow-ups)  
    – Allow direct routing: pre-registered patients go straight to lab/imaging without re-queuing at desk  
    – Implement standing orders (“orderinadvance”) for common diagnostics based on referral type  
  • Expected impact:  
    – Reduce registration service time by 40 % for kiosk users (from 6 min  3.5 min)  
    – Cut labentry wait by 50 % (from 18 min  9 min)  
    – Overall visit time reduction ~10–12 % for patients requiring diagnostics  

4. Trade-offs and Constraints  
----------------------------------------------------------------  
• Resource shift vs. staff workload  
  – Morning nurse boost may lead to underutilization post-lunch; float pool adds labor cost  
  – Mitigation: cross-train or rotate float nurses into other duties during lulls  

• Scheduling rigidity vs. patient convenience  
  – More granular slots may confuse patients; some may “no-show” if times don’t match availability  
  – Mitigation: clear communication, reminder systems, overbooking algorithm based on historical no-show rates  

• Technology investment vs. ROI  
  – Kiosks/mobile check-in requires capital & staff training; risk low adoption initially  
  – Mitigation: pilot small cohort (e.g., follow-up patients), track usage, scale if > 50 % uptake  

• Shifting bottlenecks  
  – Reducing registration wait could push congestion to diagnostics or checkout  
  – Mitigation: monitor downstream queues in near real-time dashboards; apply iterative improvement  

Balancing objectives  
  – Perform cost–benefit analysis: incremental cost of extra nurse vs. revenue from serving more patients and higher patient satisfaction  
  – Use multi-objective optimisation (e.g., weighted sum of average wait, staffing cost, NPS score)  

5. Measuring Success  
----------------------------------------------------------------  
• KPIs to track post-implementation  
  – Average and 90th percentile wait times for each targeted queue  
  – Total visit cycle time (Complete-Registration  Complete-Check-out)  
  – Resource utilization rates (staff, rooms, equipment)  
  – Patient satisfaction scores (e.g., post-visit survey NPS)  
  – No-show and walk-in rates (to assess scheduling effectiveness)  
  – Throughput volume (visits per day/week)  

• Ongoing process monitoring  
  – Implement live dashboards using process-mining software connected to the event log  
  – Set threshold alerts (e.g., if any queue’s 90th percentile wait > 30 min for 3 consecutive days)  
  – Schedule weekly/biweekly reviews with stakeholders to evaluate KPIs, re-prioritize next improvement cycle  

• Sustaining improvement  
  – Conduct periodic variant and conformance analyses to detect process drift  
  – Update staffing models and appointment rules seasonally (e.g., flu season) based on fresh log data  
  – Foster a continuousimprovement culture: share transparent metrics, gather front-line feedback, incentivize smallscale “kaizen” experiments  

By systematically mining queue times, drilling into root causes with resource and variant analyses, and deploying targeted, data-backed interventions—with robust monitoring and iterative refinement—the clinic can materially reduce patient waiting, shorten total visit times, and boost satisfaction without disproportionate cost increases.