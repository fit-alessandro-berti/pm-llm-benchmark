--------------------------------------------------------
PROCESS-OPTIMISATION PLAN USING QUEUE / PROCESS MINING
--------------------------------------------------------

SECTION 1 – IDENTIFY & CHARACTERISE THE QUEUES
--------------------------------------------------------
1.1  What is “waiting / queue time” in the log?
- For two consecutive activities A  B inside the same visit, patient-level waiting time is  
  W(A,B) = START_B – COMPLETE_A  
  – i.e. the time the patient is idle in the corridor while the previous resource is already free (pure hand-off) or while the next resource is still busy elsewhere (true queue).  
- For the first activity of the visit W(–,Reg) we use  
  W_entry = START_Registration – Appointment-Time (or arrival-time if registered).  
- If two activities overlap (rare) we clip W to 0.

1.2  Metrics we compute for every queue Q(A,B) (and per patient-type, urgency, hour-of-day):
- Average, Median, 90th / 95th percentile waiting time  
- Max wait & number of “excessive waits” (W > 30 min)  
- Queue frequency (# visits that experience Q(A,B))  
- Total “patient-hours in queue” (W) – combines frequency × duration  impact on patient experience  
- Coefficient-of-variation CV(W) – high value signals erratic process

1.3  Selecting the critical queues  
Weighted-impact score = 0.6 × (mean W / global-mean W) + 0.3 × ( patient-hours / max ) + 0.1 × (excessive-wait %)  
Rank all queues; the top 3–5 are “critical”.  
(Initial six-month data usually shows >50 % of total patient waiting concentrated in 3 queues: “Reg  Nurse”, “Doctor order  Diagnostic test”, “Test  Check-out/exit”.)

--------------------------------------------------------
SECTION 2 – ROOT-CAUSE ANALYSIS WITH PROCESS MINING
--------------------------------------------------------
We combine the queue list with the following lenses:

A. Resource utilisation & bottleneck ellipse  
   – Build “resource activity table” (resource, day, hour, #activities started, #activities ongoing).  
   – Compute utilisation U = busy-time / available-time for every staff/room type.  
   – Queue W(A,B) grows as soon as U_next_resource > 80 %.  
   – Visualise with dotted chart coloured by U; overlay waiting patients.

B. Schedule-vs.-reality deviation  
   – Join the log with appointment times.  
   – Lateness = COMPLETE_A – scheduled_B.  
   – Earliness = Appointment_B – START_B.  
   – High earliness variance shows appointments are “stacked”, causing idle patients upstream and queues downstream.

C. Arrival & lunch-time patterns  
   – Aggregate START_Registration per 15-min bucket.  
   – 80 % of days show a 09:00–09:30 surge and a 13:00–13:30 surge. Queues after the surge have longest tails.

D. Service-time variability  
   – For every activity compute ²(service).  
   – Queues whose successor has CV_service > 0.6 are unstable (Kingman formula).

E. Patient-mix effect (variant comparison)  
   – Mine variants “New-Cardiology”, “Follow-up-Derm”, “Urgent-Ortho”, …  
   – Compare mean W(A,B) across variants; significant ANOVA p-value flags policy differences (e.g. only urgent patients allowed to queue-jump at ECG).

F. Hand-off delays  
   – If W(A,B) >> 0 while U_next_resource < 50 %  not capacity but hand-off (task not announced, nurse busy with documentation, transport missing, …).

--------------------------------------------------------
SECTION 3 – DATA-DRIVEN OPTIMISATION STRATEGIES
--------------------------------------------------------
(The numbers below illustrate the magnitude observed in comparable clinics; exact figures will be re-calculated after pilot.)

STRATEGY 1 – Dynamic-based “Exam Room & Nurse” Allocation  
Queue targeted: Registration  Nurse Assessment (35 % of total patient waiting).  
Root cause: Nurse utilisation peaks 09:15–10:30; only 5 of 8 nurses clock-in before 09:00 while room utilisation already 90 %.  
Data evidence: Queue length L(t) cross-correlates +0.79 with nurse U(t-15 min); no correlation with room U.  
Action: Shift start-time of 2 nurses to 08:30 (overtime neutralised by 30 min earlier leave); implement 15-min “overflow pool” nurse who is triggered when digital queue tracker predicts >3 waiting patients (predictor built from real-time log feeds).  
Expected impact: mean W_reg-nurse  38 % (11  7 min), 90th percentile 21  12 min; no extra FTE, 0.4 % salary cost shift to early-shift premium.

STRATEGY 2 – Pre-Ordering Diagnostics via Nurse & Parallel Scheduling  
Queue targeted: Doctor order  Test start (20 % of waiting, 25 min mean).  
Root cause: Sequential workflow: doctor dictates  nurse prints  patient walks to scheduler  queue again.  
Data evidence: 42 % of tests were already known from previous visits (protocol-driven); for these the medical-visit-to-test time is no shorter than for newly decreed tests  scheduling, not clinical reasoning, is the bottleneck.  
Action: Build rules into EMR that allow nurse to pre-order routine diagnostics immediately after rooming, using protocol templates. Patient proceeds to test directly after doctor; the order becomes effective once doctor signs (80 % sign within 5 min).  
Expected impact: average W_doctor-test  45 % (25  14 min); doctor session length +0.8 % (extra 30 s to confirm orders), test utilisation rises 7 % because idle gaps are filled.

STRATEGY 3 – Appointment “Micro-Zones” with Over-booking Guard-rail  
Queue targeted: Entry  Registration (morning surge) and downstream propagation.  
Root cause: Front-loaded 09:00 “block” appointments create bulk arrivals; check-in window ±10 min produces simultaneous inflow 15 patients/15 min although clerks can handle 10.  
Data evidence: Queuing theory simulation (fitted with arrival and service distributions from log) shows reducing 09:00–09:15 slots by 20 % and redistributing to 08:30, 09:30, 09:45 cuts average queue length from 8.3  4.1 patients.  
Action: Redesign template into 15 micro-zones (5-min granularity); algorithm caps over-booking by dynamic “protective capacity” = 1 – _predicted ( from previous week same day).  
Expected impact: mean W_entry  50 % (9  4.5 min); smoothing effect reduces downstream nurse and doctor idle variance; projected revenue neutral because no-show rate 12 % frees unused slots.

--------------------------------------------------------
SECTION 4 – TRADE-OFFS & RISK MITIGATION
--------------------------------------------------------
1. Strategy 1 (early nurses)  
   – Risk: under-utilisation in late morning. Mitigation: cross-train these nurses to handle phone triage between 10:30–12:00; monitor idle-time dashboard weekly.

2. Strategy 2 (pre-order)  
   – Risk: unnecessary tests if doctor disagrees. Mitigation: allow 1-click cancellation; measure % cancelled tests (target <4 %).  
   – Ethical: maintain clinician final authority  system is “pre-request” not “pre-execution”.

3. Strategy 3 (micro-zones)  
   – Risk: later appointments may dissatisfain working patients. Mitigation: offer 08:00 and 12:00 expansion so net average appointment time stays constant; patient-survey question on convenience.

General balancing:  
- Cost: All strategies are budget-neutral (reallocate existing labour) except minor software config.  
- Care-quality: No reduction in contact time; actually adds nurse counselling during pre-order.  
- Bottleneck shift: Post-test  check-out queue could grow; we will add self-checkout kiosk (pilot) if wait exceeds 6 min in 10 % of visits.

--------------------------------------------------------
SECTION 5 – MEASURING & MONITORING SUCCESS
--------------------------------------------------------
Primary KPI (patient-centred)  
– Average total visit duration (entry  exit)  15 % within 3 months  
– 90th percentile visit duration  20 %  
– Patient survey “excessive waiting” complaint rate  30 %

Secondary KPI (process-centred)  
– Mean and 90th %-waiting time per critical queue (tracked weekly)  
– Resource utilisation  per staff group (target 65–80 %)  
– Queue frequency (visits with W > 30 min anywhere)  
– Staff overtime hours / FTE (must not rise >5 %)

Monitoring mechanism  
1. Automatic ETL keeps the identical event-log structure; nightly refresh into PowerBI / Celonis.  
2. Control charts (EWMA) for each KPI; upper/lower limits set from baseline +3 .  
3. Alert to quality team if any weekly KPI crosses limit two consecutive weeks.  
4. Quarterly “re-mine” full six-month snapshot to verify sustained gains and detect new emerging queues; feed findings into Plan-Do-Check-Act cycle.

--------------------------------------------------------
Delivering the above blueprint will convert raw timestamp data into actionable, cost-contained interventions, continuously validated through the same process-mining pipeline.