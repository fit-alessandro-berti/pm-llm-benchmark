The root of the disparity is in the way the “ScoreAdjustment” (the +10 “Community Boost”) is applied **only** in Group B.  That extra credit for belonging to “Highland Civic Darts Club” (and being a local resident) fundamentally changes one applicant’s outcome in B—and no one in A ever even has the chance to earn it.  

1. Preliminary scores and decisions at a glance  
   • Group A (Protected):  
     – P001: 720  no adjustment  Approved  
     – P002: 710  no adjustment  Rejected  
     – P003: 740  no adjustment  Approved  
   • Group B (Unprotected):  
     – U001: 720  +10 boost  730  Approved  
     – U002: 710  no boost   710  Rejected  
     – U003: 695  +10 boost  705  Approved  

2. How the bias manifests  
   a. Only unprotected applicants who are both LocalResident=TRUE *and* members of the “Highland Civic Darts Club” get +10 points.  
   b. No one in the protected group is a local resident or in a community club, so no one in Group A ever sees a ScoreAdjustment.  
   c. That +10 adjustment is *material*—it flips U003 from a 695 (presumed “below threshold”) to a 705 (“above threshold”), turning a would-be rejection into an approval.  

3. Systemic impact  
   – **Disparate treatment**: The algorithm’s rules give a built-in advantage to one group (unprotected locals in a certain club) but provide no parallel mechanism for the protected group.  
   – **Disparate impact**: Because protected applicants are never local residents, they are categorically barred from earning the community boost, even if they have identical or better credit profiles.  

In a fair system, any extra credit or “community boost” would either be available equally to everyone who meets the same conditions, or dropped entirely.  Here, its exclusive linkage to unprotected locals creates a built-in bias in final decisions.