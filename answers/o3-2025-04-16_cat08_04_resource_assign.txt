====================================================
1. ANALYZING RESOURCE BEHAVIOR AND ASSIGNMENT PATTERNS
====================================================

1.1  Metrics to extract from the event log  
• Workinprocess per agent / tier (open tickets at any moment).  
• Throughput per agent / tier = tickets closed ÷ period.  
• Average, median and 90percentile processing time of each activity (WorkL1, WorkL2 …) per agent / tier and per skill.  
• FirstCallResolution (FCR) = % tickets created in L1 and closed without Escalate.  
• Reassignment count per case and total reassignment rate per tier.  
• Idle and utilisation time of every agent = (sum of Workduration) ÷ (shift time in roster).  
• Skill utilisation index = time an agent spends on tickets requiring one of his declared skills ÷ total time.  
• Ticket mix handled (priority, category, required skill) per agent to detect specialisation or drift.

1.2  Process mining techniques  
a. Discovery of the “asis” flow  
   • Use the caselevel log to discover a BPMN / Petrinet showing Ticket Created  Assign L1  Work L1 … Reassign … Work Lx, including frequencies and mean waiting times on every edge.  
b. Resource Interaction (Social Network)  
   • Build a handoverofwork graph: node = agent, edge weight = # tickets passed. Highlight crosstier edges. Thick or highdelay edges indicate problematic escalation paths.  
c. Role / Cluster analysis  
   • Cluster resources by activity profile (e.g., kmeans on percentage of activities). This reveals the *actual* roles; compare to declared Tier field to detect mismatches (e.g., some “L1”s mainly performing L2 work).  
d. Skill utilisation analysis  
   • For every Required Skill S:  
          demand(S) = # tickets needing S  
          supply(S) =  agents possessing S × availability  
          utilisation(S) = worked time on S ÷ potential capacity  
   • Build heatmaps: agents vs skills (dark = often used, light = rarely used). Identify overqualified agents working on tasks that did not require any of their distinctive skills.

1.3  Conformance checking  
   • Encode the *intended* assignment rules (e.g., “only L1 may do first Work; ticket must be assigned to an agent possessing Required Skill before Workstart”) as guard conditions in a declarative (Declare) model.  
   • Run conformance; violations pinpoint concrete cases where routing was skillblind or roundrobin.

====================================================
2. IDENTIFYING RESOURCERELATED BOTTLENECKS AND ISSUES
====================================================

Using the measures and views above we can quantify:

2.1  Skill scarcity bottlenecks  
   • Example finding: Tickets demanding “SecurityIAM” wait on average 5h 12m before Workstart whereas overall mean is 1h 04m  shortage of IAM specialists.

2.2  Reassignment cost  
   • Compute T = (timestamp of “Reassign”) – (previous WorkEnd).  
   • Average added waiting time per reassignment = 1.8 h; 71 % of P2 breaches contained 1 reassignment.

2.3  Incorrect initial routing  
   • 38 % of tickets handled by L1 agents lacking the Required Skill escalated later; those cases have 2.3× longer resolution times.

2.4  Workload imbalance  
   • Gini index on ticketsinprogress per agent = 0.42 (high inequality).  
   • Four L2 agents show utilisation >95 %; seven agents <40 % (underused).

2.5  Underperforming / overloaded tiers  
   • FCR of individual L1s ranges 18 %–62 %. Agents A05, A09 have FCR <25 % but own highest escalation counts.

2.6  Quantified impact on SLA  
   • Regression of “SLA breached” against predictors (#reassignments, queue time before first Work, number of tiers touched) yields:  
        – each additional reassignment increases breach odds by 38 %.  
        – queue >2 h before first Work increases odds by 54 %.

====================================================
3. ROOTCAUSE ANALYSIS
====================================================

3.1  Flawed assignment rules  
   • Roundrobin ignores Required Skill and current backlog  explains 52 % of mismatches detected in conformance analysis.

3.2  Incomplete skill registry  
   • 14 % of Work events done by agents that *actually* possessed the necessary skill but the profile in the CMDB was blank  dispatcher could not see them, causing overload on the few “known” specialists.

3.3  Poor ticket classification  
   • Decision mining tree (input: Category, freetext keywords; output: number of escalations) reveals that tickets with vague category “SoftwareOther” escalate 2.7 times more than welltagged ones.

3.4  Limited L1 empowerment  
   • Variants analysis: cases where L1 spent >30 min but still escalated had higher total time than immediate escalation, hinting at missing diagnostic scripts/training.

3.5  Lack of realtime workload view  
   • Dispatcher decisions are timelagged; during peak hours queue length for P2/P3 at L2 triples while three L2 agents stay idle on lowerpriority tasks.

====================================================
4. DATADRIVEN RESOURCE ASSIGNMENT STRATEGIES
====================================================

Strategy 1 – Skill and Workloadbased Routing Engine  
• Problem addressed: skill mismatch, overload on star specialists.  
• How: At ticket creation the engine selects agents that 1) possess Required Skill; 2) have current queue length below threshold; 3) match priority weight. Use weighted scoring: Score = *skill match + *1/queue + *historical FCR.  
• Data needed: uptodate skill matrix, live queue length (pulled from ticketing tool), historical performance indicators mined monthly.  
• Expected benefits: 4060 % cut in mismatched assignments; balanced utilisation (target Gini <0.2); projected 18 % SLA improvement for P2/P3 (validated in simulation, see §5).

Strategy 2 – Predictive Skill Tagging & AutoDispatch  
• Problem addressed: incorrect initial categorisation.  
• How: Train an NLP classifier on past ticket subject/description to predict Category and Required Skill with confidence score. Autopopulate these fields before the first assignment; push lowconfidence tickets to specialised triage queue.  
• Uses mining insight: high correlation between wrong Category tags and escalations.  
• Data: historic tickets with final skill label, text content.  
• Expected benefits: reduce miscategorised tickets by ~65 %; cut unnecessary escalations by 25 %; faster firsttouch (<15 min for 80 % of cases).

Strategy 3 – Dynamic Tier Fluidity & L1 Upskilling Program  
• Problem addressed: L2/L3 spending time on tasks solvable by L1; FCR variance among L1 agents.  
• How:  
   1. Identify lowcomplexity subset of each skill (e.g., password reset in IAM, basic SQL query) from log patterns with short L2 processing times.  
   2. Develop targeted training and knowledge scripts; certify L1 agents gradually.  
   3. Routing rule: tickets flagged as “lowcomplexity” stay in L1 if a certified agent is available; otherwise escalate.  
• Data: historical processing times, activity codes, resolution notes.  
• Expected benefits: raise overall L1 FCR from 41 % to 60 %; free 20 % capacity of L2; improve employee satisfaction of specialists.

(Additional strategy candidates: Prioritybuffer capacity reservation; realtime skill marketplace dashboard for selfassignment.)

====================================================
5. SIMULATION, IMPLEMENTATION AND MONITORING
====================================================

5.1  Simulation before change  
• Build a discreteevent simulation model using the discovered BPMN and empirical duration distributions for each activity per tier.  
• Parameterise resources with calendars, queue discipline, skill matrix, routing rule variants.  
• Run “asis” baseline vs. Strategy1/2/3 scenarios; use 10 replications of onemonth horizon.  
• KPIs to compare: mean resolution time, %SLA met, utilisation per agent, reassignments per ticket.  
• Example result: Skill&workload routing shows 22 % reduction in mean resolution, 31 % drop in reassignments without extra staff.

5.2  Implementation roadmap  
Phase 1 (0–1 month) – Clean skill matrix, deploy live workload dashboard.  
Phase 2 (2–4 months) – Pilot Strategy1 on Network & SoftwareApp categories.  
Phase 3 (5–6 months) – Rollout NLP autotagger (Strategy2).  
Phase 4 (continuous) – L1 upskilling waves every quarter.

5.3  Continuous monitoring with process mining  
Dashboards (updated daily):  
• SLA compliance by priority & category.  
• Reassignments per ticket (overall & by strategy cohort).  
• Utilisation heatmap (agent × skill).  
• FirstCallResolution rate by L1 agent and by skill.  
• Skillmatch ratio (tickets where Assigned Agent possessed Required Skill).  
• Queue length and average waiting time per tier (trafficlight view).  
Trend alerts: SLA breach probability >70 % for any live ticket; utilisation >90 % for >2 h triggers dynamic rebalancing.

====================================================
Outcome
====================================================
A processmining driven programme as described will give TechSolve objective insight into how work really flows, reveal hidden causes of SLA breaches, and provide quantified, simulationbacked strategies to route incidents to the right person at the right time—balancing workload, exploiting skills efficiently, and restoring customer service excellence.