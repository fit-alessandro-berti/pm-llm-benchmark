
1. ANALYZING HISTORICAL SCHEDULING PERFORMANCE AND DYNAMICS


1.1 Reconstructing the Actual Flow via Process Mining

Using the MES event logs, process mining can reconstruct the real execution sequence of each job (CASE ID) through the variety of tasks (Cutting, Milling, Lathing, etc.) and resources (CUT-01, MILL-03, etc.). The key steps are:

• Event Log Preparation:  
  – Ensure each event record has a case identifier (JOB-XXXX), a timestamp, and an activity label (e.g., “Task Start (Cutting)”).  
  – Include resource identifiers (machine IDs), operator, and contextual attributes (priority, due date).  
  – Preprocess the log to handle missing timestamps or inconsistent records.

• Process Discovery:  
  – Use algorithms like the Inductive Miner or Alpha Miner to create a process model that shows the end-to-end flow of tasks for each job, including concurrency and rework if any.  
  – Different “variants” will emerge, representing different routings or operation sequences across machines.

• Conformance Checking:  
  – Compare the discovered process model to an expected (designed) routing model to identify deviations (e.g., out-of-sequence tasks, rework loops).  
  – This helps pinpoint real-world scheduling and routing behaviors that differ from plan.

1.2 Key Process Mining Techniques and Metrics

1.2.1 Job Flow Times, Lead Times, and Makespan Distributions  
• Flow Time (start to finish of a job) and Lead Time (job release to final completion) are measured for each JOB-XXXX by aggregating the time from the first recorded event (e.g., “Job Released”) to the final completion event (e.g., “Task End” at the last operation).  
• A distribution of these times (e.g., average, median, standard deviation) can be visualized via histograms or box plots to highlight variability.

1.2.2 Task Waiting Times at Each Work Center  
• Measure the time between a “Queue Entry (Operation)” event and the corresponding “Setup Start” or “Task Start.”  
• Use process mining tools that allow resource utilization analysis and identify waiting-time hotspots or periods.

1.2.3 Resource Utilization (Machines and Operators)  
• Extract intervals when machines are busy (setup or production) versus idle.  
• Calculate metrics such as utilization percentage for each resource:  
  Utilization = (Busy Time + Setup Time) ÷ (Total Available Time)  
• Use standard process-mining dashboards to visualize resource “heat maps” showing bottlenecks or underused machines.

1.2.4 Analyzing Sequence-Dependent Setup Times  
• Each “Setup Start” to “Setup End” interval is identified. Compare previous job IDs on the same machine to the current job.  
• For each pair of consecutive jobs on a machine, record the setup duration. Summarize or map these to product family or job attributes.  
• Perform statistical analysis or machine-learning approaches to estimate average or probability distributions of setup times, conditioned on the transition from Product Type A to Product Type B.

1.2.5 Schedule Adherence and Tardiness  
• Tardiness = (Completion Time – Due Date), if Completion Time > Due Date; otherwise zero.  
• Collect tardiness data across all completed jobs and generate distribution statistics.  
• Compare planned vs. actual completion times to measure schedule adherence percentage or lateness distribution.

1.2.6 Impact of Disruptions  
• Filter events for “Breakdown Start,” “Maintenance,” or “Priority Change.” Determine how these disruptions correlate with job delays (e.g., top 10 breakdown events and the resulting shift in planned completion).  
• Analyze time lost due to breakdown plus the subsequent backlog or queue buildup at alternate or the same machines.


2. DIAGNOSING SCHEDULING PATHOLOGIES


2.1 Identifying Bottlenecks

• Bottleneck Analysis:  
  – Use resource utilization metrics to pinpoint machines consistently operating at or near 100% capacity.  
  – Observe queue lengths and waiting times in front of these resources.  
  – Process mining “heat maps” or “performance spectrum diagrams” highlight these cluster points of congestion.

• Impact on Throughput:  
  – Late jobs piling up after or at bottleneck resources.  
  – High WIP in queues preceding the bottlenecks.

2.2 Poor Task Prioritization

• Variant Analysis Comparing On-Time vs. Late Jobs:  
  – Split the event log into “on-time” variants and “late” variants. Identify differences in how tasks were handled—did late jobs get stuck behind lower-priority tasks?  
  – High-priority “urgent” jobs might have been delayed because the local dispatching rules (e.g., First-Come-First-Served) ignored global due dates.

2.3 Excessive Setup Times Due to Suboptimal Sequencing

• Evaluate setup durations for consecutive jobs that differ greatly in tooling or fixture; compare to transitions between similar jobs.  
• Process mining sequence analysis: identify frequent transitions that yield high setup times, and see if they appear more than necessary (i.e., the schedule could have been rearranged to avoid them).

2.4 Starvation of Downstream Resources

• Resource Contention Analysis:  
  – Filter usage data for machines that have high idle times despite moderately loaded upstream stations.  
  – Usually a sign that either a bottleneck prevents work from flowing or that the dispatching rules fail to prioritize tasks for downstream continuity.

2.5 Bullwhip Effect in WIP Levels

• Fluctuations in queue lengths:  
  – Time-series analysis of queue sizes at each workstation.  
  – Periods of near-zero WIP followed by spikes, driven by inconsistent release decisions or breakdowns causing lumps in the schedule.

2.6 Using Process Mining Evidence for Pathologies

• Bottleneck charts, throughput dashboards, and resource Gantt charts highlight:  
  – When particular machines block overall progress (bottlenecks).  
  – How local priority rules cause global inefficiencies.  
  – Periods of elevated WIP inflow or starving resources downstream.


3. ROOT CAUSE ANALYSIS OF SCHEDULING INEFFECTIVENESS


3.1 Limitations of Existing Dispatching Rules

• Static heuristics (FCFS, EDD) do not account for real-time variability (machine breakdowns, re-entrant jobs) or sequence-dependent setups, resulting in suboptimal machine loading.  
• They ignore global shop conditions (i.e., the state of downstream machines).

3.2 Lack of Real-Time Visibility

• Operators may only see local queues, not the full impact on subsequent stages.  
• Planners only react when disruptions arise, leading to frequent “firefighting” and last-minute schedule changes.

3.3 Inaccurate Duration or Setup Time Data

• If estimates (planned 60 min) repeatedly deviate from reality (actual 66 min), schedules become unreliable.  
• Tends to accumulate error across multiple operations, causing job tardiness.

3.4 Ineffective Handling of Sequence-Dependent Setups

• Schedules do not group similar jobs or tasks where possible, resulting in more frequent setup changes and increased total setup time.

3.5 Poor Coordination Between Work Centers

• Upstream work centers may push jobs into the system without coordinating with downstream capacities, generating WIP congestion.

3.6 Responding to Breakdowns and Urgent Orders

• No systematic re-optimization or dynamic re-sequencing when a breakdown occurs or a hot job arrives, leading to chaotic re-prioritization and further schedule disruption.

3.7 Distinguishing Scheduling Logic vs. Resource Capacity Issues

• Process mining (via simulation or capacity analysis) can demonstrate that some problems are purely about constraints—if certain machines lack sufficient capacity or if product mix is inherently large.  
• On the other hand, patterns where slight logical changes (such as job grouping by color or material type) drastically cut setup time suggest scheduling logic is the culprit.


4. DEVELOPING ADVANCED DATA-DRIVEN SCHEDULING STRATEGIES


Below are three distinct, sophisticated strategies, each using process mining insights and aiming to tackle specific pathologies.

4.1 Strategy 1: Enhanced Dispatching Rules (Dynamic, Multi-Factor)

4.1.1 Core Logic  
• Extend dispatching beyond a single rule—combine Weighted Shortest Processing Time (WSPT), Slack-based rules (due date minus remaining processing time), and historical sequence-dependent setup predictions.  
• At each decision point (when a machine becomes available):  
  – Compute a priority score for each waiting job using:  
    Priority =  × (1 / Processing Time) +  × (Slack) +  × (Similarity-based Setup Reduction) +  × (Job Priority)  
  – “Similarity-based Setup Reduction” is derived from process-mining analysis of historical transitions—if the new job is similar to the previous one, the job gets a higher priority (less setup).  
• Select the job with the highest composite priority score.

4.1.2 Use of Process Mining Insights  
• Mining historical job transitions to estimate actual setup times for job pairs.  
• Identifying average processing times per part type and operator.  
• Real-time slack (time to due date minus time remaining) updated continuously as tasks progress.

4.1.3 Addressing Identified Pathologies & Expected KPIs Impact  
• Suboptimal sequencing fixed by factoring sequence-dependent setups.  
• Tardiness reduced since Slack-based priority helps push near-due jobs first.  
• Lower WIP since jobs are pulled into the system with more nuanced priority weighting.

4.2 Strategy 2: Predictive Scheduling

4.2.1 Core Logic  
• Leverage historical distributions of task times, including operator-specific speed variances and job complexities.  
• Predictive analytics for breakdown likelihood or time-to-failure on critical machines (if enough maintenance history is logged).  
• Construct a schedule with built-in buffers for high-risk periods.  
• Use rolling horizon re-optimization: recalculate the schedule each shift based on real-time progress and updated predictive forecasts (machine health metrics, actual vs. planned durations).

4.2.2 Use of Process Mining Insights  
• Probability distributions of task durations from logs (e.g., 90% confidence intervals).  
• Historical breakdown patterns (time between failures, average repair duration).  
• Data-driven “stress” level detection on certain machines.

4.2.3 Addressing Identified Pathologies & Expected KPIs Impact  
• More accurate planning reduces the mismatch between planned vs. actual durations  less tardiness and more predictable lead times.  
• Better anticipation of disruptions: dynamic re-scheduling mitigates the chaos from breakdowns or urgent jobs.

4.3 Strategy 3: Setup Time Optimization (Batching & Sequencing)

4.3.1 Core Logic  
• Identify “families” of jobs with similar tooling or material characteristics via clustering analysis of historical logs.  
• At bottleneck machines or high-setup machines, apply a “family scheduling” approach: group similar jobs to run one after another, thereby reducing total sequence-dependent setup.  
• Use an optimized sequence algorithm (e.g., Genetic Algorithm or Tabu Search) that navigates trade-offs between shorter throughput times vs. grouping for minimal setup.

4.3.2 Use of Process Mining Insights  
• Historical transitions show which job sequences yield minimal setup.  
• Clustering or classification modeling to define job families (e.g., part material, geometry, machine tooling requirements).

4.3.3 Addressing Identified Pathologies & Expected KPIs Impact  
• Directly tackles inflated setup times, a major idle-time contributor.  
• Increases effective capacity and lowers WIP at bottlenecks.  
• Smoother flow, since fewer frequent setups give more stable production runs.


5. SIMULATION, EVALUATION, AND CONTINUOUS IMPROVEMENT


5.1 Discrete-Event Simulation for Strategy Validation

5.1.1 Model Construction  
• Build a job shop simulation model parameterized by:  
  – Arrival rates or release patterns from real logs.  
  – Task duration distributions derived from process mining (per operation, machine, product type).  
  – Setup times, including sequence-dependent rules.  
  – Breakdown frequencies and repair durations from historical data.  
• Incorporate each proposed scheduling logic (Strategy 1, 2, 3) into the simulation “decision” modules.

5.1.2 Scenarios to Test  
• High Load: Stress the system at 90–100% utilization to see how the strategies handle peak demand.  
• Frequent Disruptions: Insert breakdown events or urgent jobs more frequently to test resilience.  
• Mixed Model Volumes: Different product mixes to evaluate sequence-dependent setups in different contexts.

5.1.3 Comparison of KPIs  
• Tardiness rate, average lateness, total WIP, lead time distribution, resource utilization.  
• Compare each strategy’s performance with the “baseline” (current FCFS/EDD).  
• Conduct sensitivity analysis on weighting parameters (, , , ) in Strategy 1, or different time horizons in Strategy 2, or different grouping thresholds in Strategy 3.

5.2 Continuous Monitoring and Adaptation

5.2.1 Ongoing Process Mining  
• Keep collecting event logs in real-time.  
• Detect “concept drift” or changes in the underlying process: e.g., new job types, changes in breakdown patterns, or shifts in operator availability.  
• Automated alerts when scheduling performance (e.g., tardiness rate) deviates significantly from historical norms.

5.2.2 Feedback Loop for Strategy Refinement  
• If setup time patterns shift (due to new tooling or new products), re-cluster job families.  
• If predictive maintenance patterns change, update the breakdown probability models.  
• Adjust scheduling rule parameters in Strategy 1 or rescheduling horizon in Strategy 2 as the process evolves.


SUMMARY

By harnessing robust process mining techniques on the detailed MES logs, Precision Parts Inc. can visualize and quantify its actual shop-floor dynamics, diagnosing bottlenecks, tardiness drivers, and inefficiencies in sequence-dependent setups. The root cause analysis reveals that simplistic local dispatching rules, combined with inadequate real-time oversight and inaccurate task/setup estimates, leads to chronic lateness, high WIP, and uneven utilization. 

To address these issues, three advanced strategies are proposed:

• Enhanced Dispatching Rules (Strategy 1) that incorporate multiple factors such as due date slack, sequence-dependent setup reductions, and job priority.  
• Predictive Scheduling (Strategy 2) that leverages historical distributions of processing times and machine breakdown patterns to better forecast delays and dynamically re-optimize.  
• Setup Time Optimization (Strategy 3) that batches and sequences jobs with similar attributes to reduce total setup overhead.

A structured simulation-based evaluation—powered by process-mining-derived parameters—will highlight which strategy or combination thereof yields the best balance of due date performance, WIP control, and resource utilization. Finally, a continuous improvement framework ensures that as the factory environment changes (new products, new disruptions), the data-driven scheduling approach remains adaptive and effective.