Below is a structured, end-to-end plan for applying process mining to Speedy Parcels’ last-mile operations, turning six months of heterogeneous event data into actionable insights and concrete optimizations. The approach combines data engineering, discovery/conformance analysis, performance measurement, root-cause exploration, and data-driven interventions, all aligned with real-world constraints of urban delivery.

1) Process Discovery and Conformance Checking

A. Data preprocessing, integration, and building a cohesive event log

- Objectives and overall approach
  - Create a unified event log where each trace represents an operational unit that can be meaningfully analyzed end-to-end. The natural grain here is a vehicle-day (Case ID: Vehicle-Day, e.g., V12-20241205) because it aligns with vehicle-level shifts and daily routing, but you can also build per-route or per-delivery traces if needed.
  - Each event should have: case_id (vehicle-day), activity (e.g., Depart Depot, Arrive Customer, Delivery Success, Unplanned Stop, Maintenance Start/End), timestamp, resource (driver or vehicle), location (lat/lon or named place), and contextual attributes (speed, vehicle status, package_id when applicable, route/planned step id, planned time window, dwell time, maintenance flag).

- Data sources and mapping
  - GPS Trackers: timestamps, coordinates, speed, vehicle status (ignition, moving/idle). Use to infer travel segments, stop durations, and route deviations. Calculate derived fields: leg distance (between consecutive coordinates), leg travel time, average speed per leg, idling time.
  - Driver Handheld Scanners: delivery milestones with timestamps and package IDs for each stop. Link a delivery event to a stop in the route; capture dwell times (arrival-to-delivery, pickup-to-departure, etc.).
  - Dispatch System: planned routes, assigned packages per vehicle, capacity, time windows, and route sequence. Use to derive planned timings, sequence, and expected stops.
  - Maintenance Logs: start/end times, maintenance type. Link to case_id to flag maintenance-related deviations or unplanned stops.

- Challenges you will likely encounter (and how to address them)
  - Different timestamp semantics and clock drift: synchronize time zones, convert to a common clock, and correct large clock skews using cross-system event sequencing.
  Complexity of multi-package stops: ensure that when several packages are delivered in one stop, each package’s event is linked to the same stop with its own delivery outcome and timestamp.
  Incomplete or missing events: some systems may miss a status (e.g., no “Depart Depot” event). Use tolerance windows and auxiliary indicators (speed, ignition) to infer missing steps; annotate gaps for sensitivity analysis.
  Duplicates and inconsistent labels: standardize event names (e.g., “Depart Depot” vs “Leave Depot”) and create a canonical event taxonomy. Deduplicate near-duplicate events using a combination of timestamp proximity, identical case_id, and same activity.
  Data volume and quality: six months of data across many vehicles will be large. Use incremental loading, partitioned processing, and quality checks (range validations, missing field checks, timestamp monotonicity per case).
  Linking to planned routes: the dispatch system’s plan may evolve. Decide on a versioning policy for route plans and tag events with the plan version they refer to; handle plan revisions in conformance checks.

- Crafting the cohesive event log
  - Primary fields per event: case_id, activity, timestamp, vehicle_id, driver_id, location, speed, route_segment_id, package_id (if applicable), planned_start_time, planned_end_time, maintenance_flag (true/false), delay_from_plan (historical), dwell_time (derived), event_source (GPS/Scanner/Dispatch/Maintenance).
  - Trace definition: a trace starts with some “Start Shift” event and ends with “End Shift” (or after the vehicle returns to depot), including all movements, deliveries, and maintenance events in between.
  - Feature engineering: compute travel times between consecutive events, dwell times at each stop, number of stops per trace, number of failed deliveries, number of maintenance events per shift, total distance traveled per trace, total idling time.

B. Process discovery (visualizing the actual end-to-end process)

- What to discover
  - Use a capable process discovery algorithm to reveal the actual execution behavior, not just the plan. This should show the typical sequence of steps from depot departure to depot return, including travel between stops, deliveries, failed attempts, re-attempts, unscheduled stops (e.g., maintenance), and any deviations (longer-than-expected dwell times, traffic-induced delays, etc.).
  - Tools/algorithms: Inductive Miner (for sound, structured models that handle parallelism well), Heuristics Miner (to surface frequent parallel patterns and common deviations), and, if you want to model timing explicitly, time-aware variants (e.g., time-aware Inductive Miner or process models embedded with time constraints).

- What the output looks like
  - A directed, possibly colored Petri-net or directly-follows graph that shows typical sequences: e.g., Depart Depot  Travel to Stop 1  Arrive  Delivery  Depart  Travel  Stop 2  …  Return to Depot.
  - Parallelism and bottlenecks: the model may reveal that for some routes, multiple deliveries can occur in parallel at certain segments, but for others, drivers are bottlenecked by parking/search time, leading to significant dwell times.
  - Deviations and variants: paths where a delivery failed, a maintenance stop occurred mid-route, or an unplanned stop was added (e.g., for fueling, vehicle issue, or last-minute reroute).

- What to do with the model
  - Use the discovered model to understand the actual end-to-end flow, capture typical vs. atypical patterns, and quantify timing distributions along each segment (e.g., time from Depot to first stop, time at each stop, in-vehicle travel time between stops).

C. Conformance checking (discovered model vs planned routes)

- Purpose
  - Measure how well the actual operations conform to the dispatcher’s planned routes and sequences, and identify specific deviations that lead to lateness or extra costs.

- How to perform alignment-based conformance
  - Build a reference model from the dispatch system: the planned sequence of stops, with expected times, service windows, and stop durations (if provided).
  - Use alignment-based conformance checking to compare each trace (vehicle-day) against the reference model. Compute metrics like fitness (how much of the observed behavior is captured by the plan), precision (whether the plan allows only observed behavior or too much), and generalization (whether the plan is too simplistic).
  - Quantify alignment costs per trace: penalties for:
    - Sequence deviations: e.g., delivering Stop B before Stop A when a plan requires A first.
    - Unplanned stops: stops not present in the plan (fuel, maintenance, searching for parking, etc.).
    - Timing deviations: significant early/late departure or arrival relative to planned times, long dwell times at customer sites, or gaps where travel times exceed plan by a threshold.
    - Missing deliveries or failed delivery events that require re-planning or re-attempts.

- Deviation types to monitor
  - Order deviations: out-of-sequence deliveries or stops.
  - Omitted stops or added stops: unplanned detours (e.g., extra pickups, returns to depot not in plan).
  - Timeliness deviations: late arrivals, early arrivals outside time windows, or long dwell times (> typical service time).
  - Maintenance/unscheduled stops: engine/maintenance events not anticipated in plan.
  - Rework: re-delivery events that imply failed first-attempts.

- How to use conformance results
  - Identify the most frequent deviation patterns and tie them to root causes (traffic, planning errors, driver behavior, system delays).
  - Segment conformance by route, driver, vehicle type, or time of day to spot systematic issues (e.g., certain routes never conform due to inaccurate travel-time estimation).

2) Performance Analysis and Bottleneck Identification

A. Key performance indicators (KPIs) for Speedy Parcels

- On-Time Delivery Rate: percentage of deliveries completed within the customer’s promised time window or SLA.
  - Calculation: number of on-time deliveries / total delivered packages.

- Average Time per Delivery Stop (service time): time spent at each delivery stop (arrival to departure, or arrival to “delivery complete” if multiple actions occur at the stop).
  - Calculation: sum of dwell times at stops / number of stop events.

- Travel Time vs. Service Time Ratio: proportion of time spent traveling versus servicing customers.
  - Calculation: total travel time between stops / total service time at stops.

- Fuel Consumption per Kilometer / per Package: efficiency metric tying fuel use to workload.
  - Calculation (estimate): total fuel used (if available from telematics) or proxy using engine-idle and speed profiles; divide by total kilometers or by number of packages delivered.

- Vehicle Utilization Rate: fraction of time a vehicle is in active service (moving or actively servicing) vs. idle.
  - Calculation: active time (driving + service) / total shift time.

- Frequency/Duration of Traffic Delays: measure of congestion impact on routes.
  - Calculation: delays attributed to traffic (extracted from speed drop/missed progress or explicit traffic events) per route/time window.

- Rate of Failed Deliveries: instances where a delivery attempt did not succeed (and required redelivery or is marked as failed).
  - Calculation: failed_delivery_events / total delivery attempts.

- Unplanned Stops and their Durations: maintenance, fuel, parking/search time, etc.
  - Calculation: count and total duration of non-planned stops per shift/route.

- Schedule Adherence by Driver/Route: how well drivers adhere to planned sequences and timing.
  - Calculation: alignment of each trace’s activity sequence and timestamps with the plan.

B. Process mining techniques to identify bottlenecks

- Bottleneck discovery
  - Performance-mining views: overlay timing information on the discovered process model to identify stages with long average durations (e.g., long dwell time at certain stops, long travel legs, or idle times in high-traffic segments).
  - Throughput time analysis: compute the total time from depot departure to depot return per trace; identify routes with the longest cycle times.
  - Variants analysis: identify which variants (sequence patterns) are most prevalent and which are associated with the worst KPIs (late deliveries, high travel time, many failed deliveries). Compare high-performing vs. low-performing variants.

- Time-to-event and correlational analyses
  - Analyze the distribution of service times at customer locations and correlate with customer type (home vs. business), time of day, or day of week.
  - Correlate traffic indicators or external data (e.g., known bottlenecks on certain corridors) with observed delays on corresponding segments.
  - Link maintenance events to subsequent performance drops (e.g., whether a vehicle with a maintenance flag had higher failure or delays).

- Driver and vehicle-level analyses
  - Variant analysis by driver to reveal differences in performance, route adherence, and dwell times.
  - Vehicle-level bottlenecks: older vehicles, higher maintenance frequency, more unplanned stops, or lower utilization.
  - Route-level bottlenecks: particular routes or neighborhoods with chronic delays or higher fuel consumption.

- Quantifying impact
  - Estimate the incremental impact of bottlenecks on KPIs (e.g., how much late deliveries increase when a specific route segment is delayed by X minutes on Y% of days).
  - Use control charts (e.g., Shewhart or moving-range charts) on KPI time series to identify statistically significant shifts corresponding to bottlenecks.

3) Root Cause Analysis for Inefficiencies

A. Potential root causes to consider (beyond “things are late”)

- Suboptimal route planning (static vs dynamic)
  - Static plans that don’t adapt to traffic, incidents, or real-time constraints lead to longer travel times and missed windows.

- Inaccurate travel time estimations
  - Travel-time biases in the plan cause built-in slack to be insufficient or excessive, degrading adherence.

- Traffic congestion patterns
  - Regular peaks or incident-driven bottlenecks (accidents, roadworks, events) that aren’t reflected in plans.

- High variability in service time at customer locations
  - Some dwell times vary dramatically due to customer interactions, complex access issues, or payment verification needs.

- Vehicle breakdowns or maintenance during shifts
  - Unplanned maintenance or failures causing detours, idle time, or missed windows.

- Driver behavior or skill differences
  - Differences in route choice, parking efficiency, safety constraints, or adherence to plan.

- Failed delivery attempts and re-delivery
  - Attempts that require re-notification, rescheduling, or re-routing can cascade delays.

B. How process mining analyses help validate root causes

- Variant analysis: Compare high-performing vs. low-performing routes/drivers to identify patterns in sequence, dwell times, or detours. If high performers tend to have fewer “depart depot” to first stop delays, the root cause may be initial routing choices or early congestion.

- Time-slice analysis: Break down performance by time-of-day, day-of-week, or season. If delays cluster during certain windows, root causes may be traffic or customer availability.

- Correlation with external data: Overlay traffic data, weather conditions, and event schedules with process data to see if delays align with congestion patterns or weather-related slowdowns.

- Dwell-time analysis: Analyze distribution of service times at each stop. High variability or systematically long dwell times at particular stop types or customer segments indicate training needs or process improvements at those stops.

- Maintenance-event impact: Segment traces with maintenance events and compare KPIs before/after or with/without maintenance to assess the impact of in-shift maintenance or unexpected breakdowns.

- Re-delivery dynamics: Track all failed deliveries and re-deliveries. If re-delivery rate correlates with specific customer segments or times, root causes may be poor pre-delivery communications or time-window misalignment.

- Causal reasoning via experiments: When feasible, pilot targeted changes (e.g., adjusted time windows, driver re-training) and measure before/after process metrics to infer causality.

4) Data-Driven Optimization Strategies

Three or more concrete, actionable strategies, grounded in process-mining insights and tailored to last-mile delivery.

Strategy 1: Dynamic, data-driven routing with real-time feedback and alignment to observed bottlenecks

- Targeted inefficiency/bottleneck
  - Suboptimal plans not accounting for real-time conditions; frequent route deviations and congestion-driven delays.

- Root cause addressed
  - Inaccurate travel-time estimates, static routing, and inflexible dispatch plans.

- How process mining supports the proposal
  - Discovery reveals bottleneck segments and time-window violations; conformance checks show plan drift under real-time conditions.
  - Real-time data fusion (live traffic feeds, incidents) can be used to re-optimize routes mid-shift; process mining confirms that dynamic rerouting reduces delays on the affected routes.

- How it would work
  - Implement a near-real-time routing layer that can adjust route sequences when congestion or incidents occur, updating ETAs for customers and drivers.
  - Trigger re-route decisions when certain thresholds are crossed (e.g., projected arrival delay > X minutes on a given stop/route).
  - Maintain a log of re-routes to re-conduct conformance checks and quantify gains.

- Expected KPI impact
  - Improvement in On-Time Delivery Rate and Reduction in Average Travel Time per delivery; higher Vehicle Utilization due to fewer idle, long-haul detours.

Strategy 2: Route and territory optimization with workload balancing

- Targeted inefficiency/bottleneck
  - Uneven workload across drivers/regions leading to longer dwell times, more idling, and inconsistent service quality.

- Root cause addressed
  - Suboptimal route segmentation and territories that cause chronic congestion or long deadhead distances.

- How process mining supports the proposal
  - Variant and cluster analysis identify routes with consistently poor KPIs and drivers with high variance in performance.
  - Territory-based bottleneck mapping shows hotspots with high delays or high maintenance incidence.

- How it would work
  - Rebalance territories and re-sequence routes to minimize deadheading, balance daily workload among drivers, and reduce peak congestion exposure.
  - Introduce micro-optimization at the planning level (e.g., cluster deliveries within tight geographic areas, assign drivers to these clusters with preferred time windows).

- Expected KPI impact
  - Higher Vehicle Utilization, lower Travel Time, reduced Fuel per package, improved On-Time Delivery Rate due to more predictable and efficient routing.

Strategy 3: Predictive maintenance and maintenance-aware routing

- Targeted inefficiency/bottleneck
  - Unplanned maintenance events that disrupt routes, cause detours, or require re-routing mid-day.

- Root cause addressed
  - Maintenance timing and vehicle reliability issues.

- How process mining supports the proposal
  - Analyze maintenance events in connection with performance metrics to identify vehicles with higher risk of in-shift failures.
  - Align maintenance schedules with low-demand windows or routes with more adjustable segments to minimize disruption.

- How it would work
  - Build predictive maintenance models using usage patterns, mileage, idle time, and prior maintenance data to forecast failure probabilities.
  - Create maintenance-ready routing plans that insert planned vehicle checks during known low-demand periods and adjust routes accordingly.

- Expected KPI impact
  - Reduced in-shift breakdowns, lower Unplanned Stops, improved Reliability, and better Overall Punctuality.

Strategy 4: Time-window optimization and customer engagement to reduce failed deliveries

- Targeted inefficiency/bottleneck
  - High rate of failed deliveries due to aggressive or inaccurately communicated delivery windows, and poor customer anticipation.

- Root cause addressed
  - Inadequate time-window commitments and insufficient customer communication.

- How process mining supports the proposal
  - Identify patterns for failed deliveries and correlate with exact time-window violations or late arrivals.
  - Variant analysis shows which time windows are most often missed and by which routes/drivers.

- How it would work
  - Introduce more realistic, data-informed delivery windows based on historical service times; implement proactive pre-arrival notifications (SMS/app push) with precise ETAs.
  - Offer dynamic, narrower windows when feasible or flexible delivery options (collection points, safe drop, or neighbor delivery) to reduce failed attempts.

- Expected KPI impact
  - Reduced Failed Deliveries rate, lower re-delivery costs, higher On-Time Delivery Rate, and improved customer satisfaction.

5) Considering Operational Constraints and Monitoring

A. Operational constraints to accommodate

- Driver working hours and legal limits
  - Ensure any routing updates respect shift changes and maximum daily driving times; implement guardrails to avoid plan suggestions that would push drivers over legal limits.

- Vehicle capacity and compatibility
  - Maintain cargo capacity constraints within route optimization; consider vehicle-specific constraints (size/weight) and any equipment limitations (e.g., refrigeration needs).

- Customer time windows and service commitments
  - Ensure route plans remain feasible within customer time windows; if dynamic routing is used, maintain robust ETA windows and allow for window adjustments as needed.

- Safety and service quality
  - Any optimization must respect local traffic rules, parking restrictions, and safe loading/unloading practices; incorporate these as constraints in the optimization model.

B. Continuous monitoring plan (post-implementation)

- Dashboards and views to track
  - Process maps with timing overlays: show the end-to-end flow for each trace, highlight deviations from plan, and identify persistent bottlenecks.
  - KPI trend dashboards: On-Time Delivery Rate, Average Time per Delivery Stop, Travel Time per Route, Fuel Efficiency, Vehicle Utilization, and Rate of Failed Deliveries, with weekly and monthly granularity.
  - Conformance dashboards: fitness, precision, and alignment costs by route, driver, and vehicle; track the proportion of traces that conform to plan and the most common deviation patterns.
  - Bottleneck heatmaps: map long dwell times, congested segments, and maintenance-related delays by route and time of day.
  - Variant analysis panels: compare high-performing vs. low-performing routes/drivers, with actionable differences (sequence patterns, dwell times, detours).

- Data refresh and governance
  - Establish a data pipeline that ingests GPS, scanner, dispatch, and maintenance data daily or in near real-time for time-sensitive decisions.
  - Maintain versioned route plans and a mapping between plan versions and traces for meaningful conformance analysis.

- Alerting and governance
  - Create threshold-based alerts for KPI breaches (e.g., sudden drop in On-Time Rate, spikes in Fuel per km, repeated maintenance-induced detours).
  - Define escalation procedures and assign ownership to route planners, fleet managers, and drivers to close the loop quickly.

- Pilot, measure, scale
  - Run small pilots to validate each optimization strategy (e.g., dynamic routing on a subset of routes, territory realignment in a region, enhanced customer time-window policy) and measure KPI impact before broader rollout.

Implementation notes and practical tips

- Start with a robust data model
  - Build a clean, canonical event log with consistent timestamps, case_id (vehicle-day), validated event types, and derived fields (travel time, dwell time, leg distance, alignment with plan).
  - Store metadata about the plan version, route segment IDs, and the time window definitions to enable precise conformance checks.

- Choose the right tools
  - For process discovery and conformance: PM4Py (open-source), ProM, or commercial process-mining suites like Celonis (for enterprise-scale dashboards and real-time conformance).
  - For data engineering and analytics: Python (pandas, geopandas, scikit-learn for predictive maintenance and regression analyses), SQL-based data marts, and a visualization layer (Power BI/Tableau/Looker).

- Data quality guardrails
  - Implement data quality checks during ingestion: track missing fields, timestamp gaps, and duplicate events; apply data imputation and sensitivity analyses where appropriate.
  - Document assumptions: e.g., how you handle missing dwell times, how you assign package-level events to a stop, and how you align plan versions to traces.

- Ethical and privacy considerations
  - Ensure driver and customer data handling complies with applicable policies and regulations; consider aggregating data to protect individual privacy where necessary.

In summary, Speedy Parcels can turn raw, multi-source event data into a cohesive, process-mined view of delivery operations. The approach enables visualizing the true end-to-end process, measuring how closely operations align with plans, quantifying bottlenecks, uncovering root causes, and guiding concrete, data-driven optimization strategies that improve punctuality and reduce fuel and maintenance costs—while respecting real-world constraints and maintaining a framework for ongoing monitoring and continuous improvement.