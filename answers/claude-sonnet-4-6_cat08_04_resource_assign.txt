# Comprehensive Process Mining Analysis for Resource Assignment Optimization at TechSolve Solutions

---

## Executive Summary

TechSolve Solutions is experiencing compounding operational inefficiencies rooted in dysfunctional resource assignment practices. The combination of SLA breaches, frequent reassignments, specialist misutilization, and uneven workload distribution points to a systemic failure in matching tickets to the right agents at the right time. This document presents a rigorous, process mining–driven methodology to diagnose these problems precisely, identify their root causes, and implement sustainable, data-driven corrective strategies.

---

## Section 1: Analyzing Resource Behavior and Assignment Patterns

### 1.1 Agent and Tier Performance Metrics

The event log contains the raw material to construct a comprehensive resource performance picture. The analysis begins by computing a structured set of metrics at both the individual agent and tier aggregate levels.

**Workload Distribution Metrics:**
- **Ticket volume per agent per time period:** Count of cases where each Agent ID appears as a resource, normalized by working hours available. This reveals whether volume is evenly spread or concentrated among a subset of agents.
- **Active concurrent tickets:** By aligning START and COMPLETE timestamps, we can compute how many open tickets each agent carries at any given moment, identifying chronic overload conditions.
- **Arrival rate versus service rate per tier:** Comparing how quickly new tickets arrive into each tier versus the rate at which agents resolve them reveals whether queue buildup is structural (insufficient capacity) or transient (temporary surges).

**Processing Time Metrics:**
- **Activity processing time per agent:** The duration between "Work L1/L2/L3 Start" and "Work L1/L2/L3 End" events per agent. Comparing distributions across agents with similar ticket types and required skills exposes genuine performance variance versus ticket complexity effects.
- **Waiting time before assignment:** The gap between "Ticket Created" or "Escalate L2/L3" and "Work LX Start" events. High waiting times indicate queue congestion or dispatcher delays, not necessarily agent slowness.
- **End-to-end resolution time by tier path:** Tickets resolved purely at L1 versus those escalating to L2 versus L3 should be compared. This decomposes where calendar time is spent and where interventions will have the greatest impact.

**Quality and Effectiveness Metrics:**
- **First-Contact Resolution (FCR) rate for L1:** The proportion of tickets where L1 logs a "Work L1 End" followed directly by ticket closure, without any "Escalate" activity. Low FCR reveals either insufficient L1 capability or incorrect ticket assignment to L1 in the first place.
- **Escalation rate per L1 agent:** Some agents escalate far more than others even when handling similar ticket categories, which may indicate training gaps or overly risk-averse behavior.
- **Reassignment frequency per ticket:** Count of "Reassign" and subsequent "Assign" events per case. Cases with more than one reassignment are flagged as problematic process variants.
- **Skill match rate at assignment:** For each assignment event, compare the "Required Skill" attribute on the ticket with the documented skills of the assigned agent. Compute the percentage of assignments where there is a documented match.

**Ticket Type Handling Frequency:**
- Cross-tabulation of Agent ID versus Ticket Category and Required Skill reveals which agents actually handle which ticket types, which may diverge significantly from their documented skill profiles.

### 1.2 Revealing Actual Assignment Patterns Through Process Mining Techniques

The gap between the *intended* assignment logic (round-robin within tiers, manual escalation) and *actual* behavior can be made visible through several process mining techniques applied to the event log.

**Handover-of-Work Social Network Analysis:**
By constructing a social network where nodes are agents (or agent roles/tiers) and directed edges represent ticket handovers — each time a ticket moves from one agent to another — the following become apparent:
- **Hub agents:** Certain agents may appear as disproportionate recipients of handovers, indicating informal escalation paths or skill concentrations that the formal structure does not acknowledge.
- **Isolated agents:** Some agents receive few handovers and rarely pass work on, suggesting they either resolve tickets independently or are systematically bypassed.
- **Tier-bypass patterns:** Edges that skip from L1 directly to L3 without L2 involvement indicate cases where the tiered model is not followed, possibly because L2 lacks certain skills or is unavailable.
- **Back-transfers:** Edges pointing from L2 back to L1, or from L3 back to L2, indicate incorrect upward escalations that are being reversed, representing wasted work.

Using the event log snippet as an example: INC-1001 shows a handover from Agent A05 (L1) to Dispatcher, then to Agent B12 (L2), then a reassignment to Agent B15 due to a skill mismatch. The social network would show A05  B12  B15, with the B12  B15 edge flagging an intra-L2 reassignment that the intended logic presumably should have prevented.

**Role Discovery and Conformance Checking:**
Using resource clustering algorithms (e.g., k-means on activity execution profiles), the actual roles agents play can be discovered from behavioral data rather than assumed from organizational charts. An agent officially designated as L1 who consistently handles complex Software-App tickets and rarely escalates may be functioning as an informal L2. Comparing discovered roles against documented roles highlights structural mismatches.

Conformance checking against a reference process model (defining when escalation should occur, which tiers handle which categories) will produce conformance scores per case. Systematically low-conformance cases cluster around specific ticket categories, agents, or time periods, pinpointing where the intended logic breaks down most severely.

**Process Discovery with Resource Filters:**
Applying the Directly-Follows Graph (DFG) or Inductive Miner with resource filters — for example, generating the process model only for cases where a reassignment occurred — reveals what process paths are uniquely associated with reassignment events versus smooth cases. The comparison between these two process variants is foundational to root cause analysis.

### 1.3 Skill Utilization Analysis

**Skill Demand Mapping:**
Aggregate all tickets by Required Skill and compute the volume, average resolution time, and SLA compliance rate for each skill category. This produces a demand profile showing which skills are most critical and most scarce.

**Skill Supply Mapping:**
From agent profiles, map documented skills to agents and tiers. Compute the total available agent-hours per skill category, weighting by tier (an L3 agent's skill-hours are more expensive and scarcer than an L1 agent's).

**Skill Utilization Rate:**
For each agent, compute the proportion of their work time spent on tickets that actually require their documented specialist skills. An L3 Database specialist spending 40% of their time on P4 Software-OS tickets that L2 or even L1 agents could handle represents a significant misutilization cost.

**Skill Mismatch Frequency:**
Cross-reference every assignment event's Required Skill with the assigned agent's documented skills. Compute:
- **Overskilling rate:** Percentage of assignments where the agent's highest skill level exceeds what the ticket requires (specialist doing generalist work).
- **Underskilling rate:** Percentage of assignments where the agent lacks the required skill (leading to likely reassignment or extended resolution time).

The underskilling rate is particularly actionable: it directly predicts which assignments will generate reassignments, and it reveals gaps in the dispatcher's awareness of agent capabilities.

---

## Section 2: Identifying Resource-Related Bottlenecks and Issues

### 2.1 Bottleneck Identification Methodology

**Skill-Specific Queue Bottlenecks:**
After computing waiting time distributions segmented by Required Skill, bottlenecks appear as spikes in waiting time concentrated in specific skill categories. For example, if Networking-Firewall tickets consistently wait 3–4 hours for L2 assignment while App-CRM tickets wait 20 minutes, the bottleneck is a shortage of available Networking-Firewall specialists, not a general capacity problem. This distinction is critical for targeted intervention.

Concretely, for each Required Skill category:
- Compute median and 90th percentile waiting time from escalation to L2/L3 work start.
- Correlate with SLA breach rate for that category.
- Compute the number of agents who have the skill versus the ticket volume demanding it (demand-to-supply ratio).

A high demand-to-supply ratio combined with high waiting time and high SLA breach rate definitively identifies a skill bottleneck.

**Reassignment Delay Quantification:**
Every reassignment event introduces measurable delay. From the event log, compute:
- **Time from "Reassign" event to the subsequent "Work LX Start" on the new agent:** This is the direct delay attributable to the reassignment.
- **Aggregate across all reassignment events:** Sum and average these delays. If the data shows, for example, that each reassignment adds an average of 47 minutes of delay (a realistic estimate given queue wait times plus dispatcher processing), and there are 800 reassignments per month, the total monthly delay attributable to reassignments is approximately 627 agent-hours of lost resolution time.
- **Reassignment rate by ticket category and initial assigning agent:** Identifies which ticket types and which dispatchers or L1 agents most frequently generate reassignments.

**Incorrect Initial Assignment Impact:**
Filter cases where the first L1 or dispatcher assignment was to an agent whose documented skills did not match the Required Skill. Compute the correlation between initial skill mismatch and:
- Whether the ticket was reassigned (expected to be strongly positive).
- Total resolution time (expected to be significantly higher than correctly matched cases).
- SLA breach probability (expected to be substantially higher).

If, for instance, 35% of all P2 tickets are initially assigned with a skill mismatch, and those tickets breach SLA at a rate of 60% versus 15% for correctly matched tickets, the contribution of initial misassignment to SLA breaches is quantifiable and substantial.

**Agent Overload and Underutilization:**
Using the concurrent ticket load metric from Section 1.1, identify:
- Agents whose average concurrent load exceeds a defined threshold (e.g., more than 8 active tickets simultaneously for an L2 agent) consistently.
- Agents whose average concurrent load is below a minimum utilization threshold (e.g., fewer than 2 active tickets when the tier queue is non-empty).

Cross-reference overloaded agents with SLA breach rates on their tickets: if tickets assigned to overloaded agents breach SLA at higher rates than identical tickets assigned to agents with normal loads, overload is a confirmed SLA risk factor.

### 2.2 SLA Breach Correlation Analysis

A logistic regression or decision tree analysis using ticket and resource attributes as predictors and SLA breach (yes/no) as the outcome variable will reveal which factors most strongly predict breaches. Expected key predictors:

- **Required Skill not matched at initial assignment:** Likely the single strongest predictor.
- **Number of reassignments:** Each additional reassignment increases breach probability.
- **Waiting time in L2 queue exceeds X minutes for P2 tickets:** Identifies a threshold beyond which breach becomes near-certain.
- **Assigned agent concurrent load at time of assignment:** High load correlates with breach.
- **Escalation from L1 after SLA clock has been running for Y% of SLA window:** Late escalations leave insufficient time for L2/L3 resolution.

Expressing these as quantified findings — for example, "each additional reassignment increases P2 SLA breach probability by 23 percentage points" or "65% of P2 SLA breaches occurred on tickets that waited more than 90 minutes for an available Networking-Firewall specialist" — provides the evidence base for prioritizing specific interventions.

---

## Section 3: Root Cause Analysis for Assignment Inefficiencies

### 3.1 Structural Root Causes

**Round-Robin Assignment Without Skill or Workload Awareness:**
The current round-robin logic treats all tickets and all agents within a tier as interchangeable. This is the most fundamental structural flaw. It guarantees that a significant proportion of assignments will be skill mismatches regardless of how well-documented agent skills are, because the assignment mechanism never consults skill profiles. This single-factor deficiency explains the chain: mismatch  reassignment  delay  SLA breach.

**Inaccurate or Stale Agent Skill Profiles:**
Even if a skill-based system were in place, its effectiveness depends entirely on skill profile accuracy. Process mining can test this by comparing documented skills with observed behavior: if an agent documented as having "App-CRM" skill consistently fails to resolve App-CRM tickets (escalating after prolonged work time), either the skill documentation is aspirational rather than verified, the agent's proficiency level is insufficient, or the skill has not been maintained through recent use.

**Poor Initial Ticket Categorization:**
If the Required Skill field on newly created tickets is frequently wrong or overly generic, all downstream assignment logic fails at the first step. Analyzing cases where the Required Skill was changed mid-ticket lifecycle (visible as updates to ticket attributes in the event log) reveals the frequency and pattern of initial categorization errors. If 25% of Software-App tickets initially categorized as needing "App-Generic" are later recategorized as needing "App-CRM" or "App-ERP," the initial categorization is systematically inadequate.

**Lack of Real-Time Workload Visibility:**
Dispatcher decisions made without access to current agent queue depths and concurrent load will be suboptimal even with good intentions. If dispatchers are working from static roster lists rather than dynamic availability dashboards, they cannot avoid assigning tickets to already-overloaded agents.

**Insufficient L1 Empowerment and Training:**
An L1 escalation rate that is higher than necessary wastes L2/L3 capacity and lengthens resolution times for customers. Process mining can identify specific ticket types — for example, simple password resets that occasionally get escalated, or common Software-App errors with well-documented fixes — where L1 FCR is near zero despite the ticket category being theoretically within L1 scope. This indicates training gaps or inadequate knowledge base articles rather than genuine complexity.

### 3.2 Variant Analysis for Root Cause Identification

**Smooth vs. Problematic Case Comparison:**
Separate the event log into two populations:
- **Smooth cases:** Resolved with zero or one assignment, no reassignments, SLA compliant.
- **Problematic cases:** Two or more assignments, at least one reassignment, and/or SLA breached.

Compare these populations across every available attribute:
- **Ticket attributes:** Which priority, category, and required skill combinations are over-represented in problematic cases? If Networking-Firewall P2 tickets appear in problematic cases at 5x the rate expected from their volume, that combination is a priority intervention target.
- **Channel of arrival:** Are phone-reported tickets (which may be categorized in real time by an L1 agent who may be uncertain) more frequently problematic than web-portal tickets (where customers self-categorize)?
- **Time of day and day of week:** Are problematic cases concentrated in shift-change periods or low-staffing hours, suggesting handover gaps or overnight queue buildup?
- **Dispatcher involved:** Are certain dispatchers associated with higher reassignment rates, indicating individual decision-making quality issues?
- **L1 agent involved in escalation decision:** Are certain L1 agents escalating tickets that similar L1 agents resolve, identifying training gaps?

**Decision Mining for Assignment Logic:**
Apply decision tree mining to the "Assign L2" events, using as input features: ticket priority, category, required skill, time of day, L1 agent who escalated, and as the output: whether the assignment resulted in a reassignment or not. The decision tree will reveal which input combinations most reliably predict assignment failure. For example: "When Required Skill = Networking-Firewall AND Time of Day = 14:00–18:00 AND assigned agent is from the general L2 pool rather than the Network specialist sub-pool, reassignment probability = 78%."

This transforms qualitative suspicion about assignment logic deficiencies into quantitative, actionable decision rules that can directly inform the improved assignment algorithm.

---

## Section 4: Developing Data-Driven Resource Assignment Strategies

### Strategy 1: Skill-Proficiency–Weighted Routing Engine

**The Assignment Issue It Addresses:**
The fundamental mismatch between ticket Required Skill and assigned agent skills, which is the primary driver of reassignments and SLA breaches.

**How It Leverages Process Mining Insights:**
The skill utilization analysis from Section 1.3 produces the empirical foundation: not just which agents are documented as having which skills, but which agents *demonstrably perform well* on which ticket types based on historical resolution success and time metrics. An agent documented as having "App-CRM" skill but who consistently takes twice as long as peers on App-CRM tickets and escalates 60% of them should be weighted lower for App-CRM assignments than a peer with shorter resolution times and high FCR on the same ticket type.

**Mechanism:**
Construct a skill-proficiency matrix where each cell represents a (Agent, Skill) pair with a proficiency score computed from:
- Historical average resolution time for tickets requiring that skill, normalized by ticket complexity indicators.
- Historical success rate (resolved without further escalation) for that skill-ticket combination.
- Recency weighting: proficiency scores decay if not refreshed by recent tickets of that type, addressing skill currency.

When a new ticket is created or escalated with Required Skill = X, the routing engine:
1. Filters the available agent pool to those with Skill X and a proficiency score above a minimum threshold.
2. Among eligible agents, ranks by proficiency score.
3. From the top-ranked agents, applies availability/workload constraints (see Strategy 2) to make the final selection.

For ticket categories where no available agent meets the minimum proficiency threshold, an automatic escalation trigger fires rather than assigning to an unqualified agent.

**Data Requirements:**
- Complete, accurate agent skill documentation (initial input, then continuously updated from observed performance).
- Historical event log to compute initial proficiency scores per (Agent, Skill) pair.
- Real-time ticket Required Skill field (depends on accurate categorization — see Strategy 3).
- Integration with ticketing system to enforce routing decisions programmatically.

**Expected Benefits:**
- Reduction in initial-assignment skill mismatches by an estimated 60–75% (based on typical outcomes from skill-based routing implementations in comparable IT service desks).
- Direct reduction in reassignment rate, with corresponding reduction in per-ticket delay.
- Estimated 20–30% reduction in P2/P3 SLA breach rate for tickets where skill mismatch was the breach driver.
- Long-term: proficiency data accumulates, continuously improving routing accuracy.

---

### Strategy 2: Real-Time Workload-Aware Assignment Algorithm

**The Assignment Issue It Addresses:**
Agent overload and underutilization, where the current round-robin logic ignores current queue depths and active concurrent ticket loads, resulting in some agents receiving new tickets while already overloaded and others sitting idle.

**How It Leverages Process Mining Insights:**
The concurrent load analysis from Section 2.1 reveals agent-specific capacity thresholds — the concurrent ticket load above which resolution times degrade and SLA breach rates increase. These empirically derived thresholds become the constraints in the workload-aware algorithm. The demand pattern analysis (workload peaks by hour and day of week) informs proactive staffing adjustments.

**Mechanism:**
A real-time assignment engine with the following logic:

1. **Availability scoring:** Each agent receives a real-time availability score computed from:
   - Current number of active (open) tickets assigned to them.
   - Estimated remaining work time on current tickets (derived from historical processing time distributions for ticket types currently in their queue).
   - Scheduled break/meeting commitments pulled from calendar integration.
   - Tier-specific capacity thresholds derived from process mining (e.g., L2 agents perform optimally below 6 concurrent tickets).

2. **Assignment decision:**
   - New ticket is assessed for Required Skill, Priority, and expected complexity.
   - The agent pool is filtered by skill match (from Strategy 1).
   - Among skill-matched agents, rank by availability score (highest availability first).
   - Priority weighting: P1 and P2 tickets can temporarily exceed normal capacity thresholds by one ticket, but P3 and P4 tickets cannot be assigned to agents already at threshold.

3. **Queue overflow management:**
   - When all skill-matched agents in a tier are at capacity, the system flags the ticket for expedited handling or activates a cross-tier capacity sharing protocol (see also Strategy 5 element below).

**Data Requirements:**
- Real-time feed of ticket status and assignment data from the ITSM platform.
- Calendar/scheduling integration for agent availability.
- Historical processing time distributions per agent per ticket category for estimated remaining work calculations.
- Dashboard for dispatchers showing real-time agent availability status.

**Expected Benefits:**
- More even workload distribution, reducing peak overload by an estimated 35–50%.
- Elimination of the scenario where tickets are assigned to overloaded agents while other qualified agents are available.
- Reduction in overload-driven SLA breaches.
- Improved agent wellbeing and reduced burnout among consistently overloaded specialists.
- Estimated 15–20% improvement in average resolution time through better concurrent load management.

---

### Strategy 3: ML-Driven Predictive Ticket Categorization and Skill Requirement Identification

**The Assignment Issue It Addresses:**
Poor initial ticket categorization that causes all downstream assignment logic to fail from the first step. Even the best routing engine cannot assign correctly if the Required Skill field is wrong or generic.

**How It Leverages Process Mining Insights:**
The variant analysis from Section 3.2 identifies which ticket categories are most frequently miscategorized initially (evidenced by Required Skill changes mid-lifecycle). Natural language processing applied to ticket descriptions (from the free-text notes fields in the event log) combined with the eventual correct Required Skill provides a labeled training dataset for a classification model.

**Mechanism:**

1. **Training data construction:** From the historical event log, extract all tickets where the Required Skill was either correct from the start (no changes) or was corrected during the lifecycle. Use the *final correct* Required Skill as the label. Extract ticket description text, category selections, channel of origin, priority, and any other structured attributes as features.

2. **Model training:** Train a multi-class text classification model (e.g., a fine-tuned BERT model for text features combined with structured attribute features) to predict Required Skill from ticket creation attributes. Validate on a held-out test set, targeting high precision for the top-priority skill categories (those with highest SLA breach rates from Section 2.2).

3. **Deployment:**
   - For web portal submissions: The model runs as tickets are created, suggesting a predicted Required Skill that the user can confirm or override.
   - For phone-reported tickets: L1 agents are prompted with the model's prediction as they complete the ticket form, reducing the cognitive burden of correct categorization.
   - For email-submitted tickets: Automatic pre-categorization before the ticket reaches the dispatcher.

4. **Continuous learning:** As new tickets are resolved, the final validated Required Skill is fed back into the training dataset, keeping the model current with evolving technology environments and new ticket types.

**Data Requirements:**
- Historical event log with ticket descriptions and final correct Required Skill labels (at minimum several hundred labeled examples per skill category).
- Text of ticket descriptions (requires access to free-text ticket fields, not just the structured event log).
- NLP preprocessing infrastructure.
- Integration point with the ticketing system to display and apply predictions.

**Expected Benefits:**
- Reduction in initial categorization errors by an estimated 40–60%.
- Cascading improvement in assignment accuracy (Strategy 1 and 2 work better when Required Skill is correct).
- Reduction in time spent by L1 agents manually categorizing complex tickets.
- Particular value for tickets arriving after hours when experienced categorizers are unavailable.
- Estimated 10–15% additional reduction in reassignment rate beyond what Strategy 1 alone achieves, by fixing the upstream data quality problem.

---

### Strategy 4: Evidence-Based Escalation Criteria and L1 Empowerment Program

**The Assignment Issue It Addresses:**
Excessive or premature L1 escalations that overload L2/L3 with work they did not need to handle, and unnecessary escalation delays that consume SLA budget before specialists even begin working.

**How It Leverages Process Mining Insights:**
The FCR analysis from Section 1.1 and the variant analysis from Section 3.2 produce a data-driven picture of which ticket types *could* be resolved at L1 (similar tickets resolved by other L1 agents without escalation) versus which *cannot* (no L1 agent successfully resolved this type). For every ticket category-skill combination, this analysis produces an "L1-resolvable" flag backed by empirical evidence.

**Mechanism:**

1. **Evidence-based escalation guidelines:**
   - Compute L1 FCR rate by ticket category and required skill.
   - For combinations with L1 FCR > 60%: Develop detailed resolution guides, decision trees, and knowledge base articles. Define explicit criteria that must be checked before escalation is permitted.
   - For combinations with L1 FCR 20–60%: Provide guided troubleshooting tools with branching logic based on symptom patterns, with escalation triggered by specific diagnostic outcomes rather than L1 agent judgment.
   - For combinations with L1 FCR < 20%: Auto-route directly to L2 at ticket creation, bypassing L1 entirely to save SLA time. This prevents the current pattern of L1 working the ticket for 20 minutes only to escalate it, consuming SLA budget.

2. **L1 capability development:**
   - Identify the specific ticket types where L1 FCR is below the benchmark for that category — these represent training opportunities.
   - Develop targeted micro-training modules for these ticket types.
   - Pair underperforming L1 agents with experienced L1 agents who have higher FCR on the same ticket types for shadowing and mentoring.
   - Provide L1 agents with a recommendation engine that suggests resolution steps based on the ticket's predicted Required Skill and similar resolved tickets (a knowledge base retrieval system).

3. **Escalation quality monitoring:**
   - Track L1 escalations by agent and by ticket type. Escalations that L2 resolves quickly (under 15 minutes) may indicate L1 could have resolved them with better guidance.
   - Provide regular feedback to L1 agents on their escalation decisions, showing them cases where L2 used an approach they had access to but did not attempt.

**Data Requirements:**
- L1 FCR rates by agent and ticket category (from event log analysis).
- Historical resolved ticket data for knowledge base population.
- Agent performance tracking for training impact measurement.
- Resolution step data (if available in ticket notes) for L1 empowerment tooling.

**Expected Benefits:**
- Estimated 15–25% reduction in escalation volume from L1 to L2, freeing specialist capacity for genuinely complex tickets.
- Reduction in average time-to-L2-work-start by eliminating unnecessary L1 work time on tickets that will inevitably escalate.
- Improved customer experience through faster first-contact resolution where appropriate.
- L2/L3 specialists freed from routine tasks they are currently handling, improving their job satisfaction and retention.
- Estimated 10% improvement in overall SLA compliance through faster routing of complex tickets and better L1 resolution of simple ones.

---

### Strategy 5: Dynamic Cross-Tier Capacity Reallocation Based on Demand Patterns

**The Assignment Issue It Addresses:**
Unevenly distributed workload across tiers due to demand fluctuations that the current static tier structure cannot accommodate. When L2 is overwhelmed with P2 tickets but L1 has spare capacity, or when a specific skill's queue overflows while other L2 agents sit idle, a static structure has no mechanism to adapt.

**How It Leverages Process Mining Insights:**
The demand pattern analysis (Section 2.1) reveals predictable surge patterns by hour, day of week, and potentially season. The skill utilization analysis shows which skills are chronically over-demanded and which agents have complementary skills that could serve as overflow capacity.

**Mechanism:**

1. **Demand-based staffing schedule optimization:**
   - Use historical demand patterns (tickets by hour/day/week by category and skill) to compute predicted demand for each skill category in each time window.
   - Align staffing schedules to demand patterns: ensure Networking-Firewall specialists are scheduled during peak Networking-Firewall demand periods, not uniformly distributed.
   - Cross-train selected L1 agents in the most frequently demanded L2 skills that have shorter mastery curves, creating a flexible "bridge tier" that can absorb overflow.

2. **Real-time surge response protocol:**
   - Define queue depth thresholds for each skill category. When the queue for a specific Required Skill exceeds the threshold, the system triggers an automatic escalation alert.
   - Pre-define which cross-trained or adjacent-skilled agents can be temporarily redirected from lower-priority work to the surging skill queue.
   - Dispatcher dashboard shows real-time queue depth by skill with traffic-light indicators, enabling proactive redirection before queues become critical.

3. **Flexible tier assignment for eligible tickets:**
   - For ticket types where L2 and capable L1 agents have overlapping resolution capacity (identified from FCR data), implement an overflow rule: when L2 queue depth exceeds threshold, eligible tickets route to the capable L1 agents first.

**Data Requirements:**
- Historical demand time series by ticket category and Required Skill for schedule optimization.
- Real-time queue depth data by skill category.
- Agent skill matrices including cross-training information.
- Threshold parameters derived from SLA constraint modeling (how long can a P2 ticket wait before breach becomes likely given typical L2 resolution times).

**Expected Benefits:**
- Smoothed workload distribution across the agent pool, reducing both overload peaks and underutilization troughs.
- Reduction in queue-depth-driven SLA breaches by ensuring adequate capacity is available during predictable surge periods.
- Better utilization of cross-trained agents, who currently may work on generic tasks when their skills could be redirected to high-demand areas.
- Long-term: reduced need to hire additional L2/L3 specialists by better utilizing existing capacity.

---

## Section 5: Simulation, Implementation, and Monitoring

### 5.1 Pre-Implementation Simulation

Before committing to implementation costs and organizational change, business process simulation informed by the mined process model allows virtual testing of each strategy. The approach proceeds in structured phases:

**Phase 1: Baseline Simulation Model Construction**
Using the discovered process model (from applying a process discovery algorithm such as the Inductive Miner to the full event log), construct a simulation model that reproduces the current process with high fidelity. Key parameters to calibrate from the event log:
- **Arrival rates:** Ticket inter-arrival time distributions by priority and category, by time of day and day of week.
- **Activity duration distributions:** Processing time distributions per activity, per agent tier, and per ticket category, including their statistical shape (often log-normal for IT support tasks).
- **Resource parameters:** Number of agents per tier, shift schedules, capacity constraints.
- **Routing probabilities:** Probability of escalation from L1, probability of reassignment, conditional on ticket type.

The baseline simulation should replicate the observed KPIs from the event log (average resolution time, SLA breach rates, reassignment frequency) within a defined tolerance (e.g., ±10%), validating that the model accurately represents the real system.

**Phase 2: Strategy Scenario Simulation**
Implement each proposed strategy as a modification to the simulation model:

- **Strategy 1 (Skill-Based Routing):** Change the routing logic from random-within-tier to skill-matched routing. Model the residual mismatch rate based on the proficiency score distribution. Compute the expected reduction in reassignment events and the corresponding time savings.

- **Strategy 2 (Workload-Aware Assignment):** Add workload state tracking to each resource node. Implement the capacity threshold constraints. Observe whether the simulated workload distribution becomes more even and whether overload-driven processing time degradation is reduced.

- **Strategy 3 (Predictive Categorization):** Modify the ticket arrival process to reduce the initial miscategorization rate by the model's projected accuracy improvement. Observe the downstream impact on reassignment rates and SLA compliance.

- **Strategies 4 and 5:** Adjust escalation routing probabilities based on the evidence-based escalation criteria, and implement the dynamic capacity reallocation rules. Observe the impact on L2 queue depths and L2-related SLA breaches.

**Combined Strategy Simulation:**
Run a final simulation incorporating all strategies simultaneously, as their effects interact (e.g., better categorization makes skill-based routing more effective). The combined model projects the achievable improvement under full implementation.

**Sensitivity Analysis:**
Test each simulation scenario under pessimistic assumptions (e.g., skill-based routing achieves only 50% of projected mismatch reduction, ML categorization model has lower-than-expected accuracy) to understand the robustness of projected improvements and identify which strategies deliver value even under challenging conditions.

The simulation output provides management with a risk-quantified projection: not just "we expect X% SLA improvement" but "under realistic assumptions, SLA improvement ranges from X% to Y%, with the most likely outcome at Z%."

### 5.2 Phased Implementation Plan

Simulation results inform a phased rollout that manages risk:

**Phase A (Months 1–2): Quick Wins and Foundation**
- Implement real-time workload visibility dashboards for dispatchers (Strategy 2 precursor).
- Begin evidence-based escalation guideline development and initial L1 training (Strategy 4).
- Deploy ML categorization model in "advisory" mode — it suggests categorization but does not override human decisions, allowing accuracy to be validated before full deployment.

**Phase B (Months 3–5): Core Routing Engine**
- Implement skill-proficiency–weighted routing (Strategy 1) for a pilot ticket category (choose the category with highest reassignment rate and clearest skill-matching data).
- Expand workload-aware assignment (Strategy 2) into production routing.
- Evaluate pilot results against simulation projections; calibrate and adjust before full rollout.

**Phase C (Months 6–9): Full Deployment**
- Roll out skill-based routing across all ticket categories and tiers.
- Deploy ML categorization model in automated mode for web portal and email channels.
- Implement dynamic capacity reallocation protocols (Strategy 5) and monitoring thresholds.
- Complete L1 empowerment program across all L1 agents (Strategy 4).

### 5.3 Post-Implementation Monitoring with Process Mining Dashboards

The same process mining infrastructure used for diagnosis becomes the ongoing monitoring system. A purpose-built dashboard tracks the following KPIs continuously:

**Tier 1: SLA and Resolution Performance (Outcome KPIs)**

| KPI | Measurement | Target |
|---|---|---|
| SLA Compliance Rate by Priority | % tickets resolved within SLA, tracked weekly | P1: 99%, P2: 95%, P3: 90% |
| Average End-to-End Resolution Time | Mean and 90th percentile, by priority and category | Reduce by 25% from baseline |
| First-Contact Resolution Rate (L1) | % L1 tickets closed without escalation | Increase from baseline by 15pp |
| Average Time-to-Assignment | From creation/escalation to work start, by tier | Reduce by 40% from baseline |

**Tier 2: Assignment Quality KPIs (Process KPIs)**

| KPI | Measurement | Target |
|---|---|---|
| Skill Match Rate at First Assignment | % assignments where agent skill matches Required Skill | >90% |
| Reassignment Rate | Reassignment events per 100 tickets | Reduce by 60% from baseline |
| Average Delay per Reassignment | Time added per reassignment event | Monitor trend; target <15 min |
| Inappropriate Escalation Rate | L1 escalations where L2 resolved in <10 min | Reduce by 50% from baseline |

**Tier 3: Resource Utilization KPIs (Capacity KPIs)**

| KPI | Measurement | Target |
|---|---|---|
| Agent Workload Distribution (Gini Coefficient) | Inequality measure of ticket distribution across agents | Reduce toward 0 (perfect equality) |
| Specialist Utilization on Appropriate Tasks | % L2/L3 time on skill-matched tickets | Increase to >80% |
| Queue Depth by Required Skill | Real-time and trending, flagged at thresholds | No skill queue exceeds threshold for >30 min |
| Cross-tier Reallocation Frequency | How often Strategy 5 protocols are activated | Monitor — should reduce over time as scheduling improves |

**Dashboard Views:**

1. **Real-Time Operations View:** Live ticket queue depths by skill and priority, agent availability heatmap, active SLA breach risk alerts (tickets approaching SLA deadline currently assigned to overloaded agents).

2. **Weekly Performance View:** Trend charts for all Tier 1 KPIs, with automatic flagging of KPIs that have deteriorated from prior period. Drill-down into specific ticket categories or time periods with performance changes.

3. **Resource Analysis View:** Agent-level performance scorecards comparing each agent's processing times, FCR rates, and skill match rates against tier benchmarks. Updated monthly; used for individual performance conversations and training needs identification.

4. **Assignment Quality Conformance View:** Process mining conformance checking run weekly against the intended assignment process model. Cases deviating from the model are clustered by deviation type, enabling rapid identification of emerging process degradation before it propagates.

5. **Model Performance View (for Strategy 3):** ML categorization model accuracy tracked over time, with distribution shift monitoring to detect when the training data is becoming stale relative to current ticket patterns.

**Continuous Improvement Loop:**
Monthly review of dashboard trends with a cross-functional team (operations management, L1/L2/L3 team leads, IT systems) to:
- Identify KPIs trending in the wrong direction early.
- Assess whether simulation projections were accurate and update models with new data.
- Identify emerging ticket categories or new technologies creating new skill gaps not covered by current routing logic.
- Refresh proficiency scores and routing weights with the most recent performance data.

---

## Conclusion

The resource assignment challenges at TechSolve Solutions are systemic but addressable through rigorous, data-driven process mining analysis. The diagnostic work reveals that SLA breaches, reassignments, and specialist misutilization are not random failures but predictable consequences of specific structural deficiencies: skill-blind round-robin routing, unchecked categorization inaccuracy, static tier structures, and insufficient L1 empowerment.

The five proposed strategies form an integrated response: Strategy 3 fixes the data quality problem at the source; Strategies 1 and 2 transform the assignment engine to be skill- and workload-aware; Strategy 4 recalibrates the tier structure based on empirical capability evidence; and Strategy 5 makes the entire system dynamically adaptive to demand fluctuations. Together, they target an estimated 30–45% improvement in SLA compliance and a 50–65% reduction in reassignments, with the simulation phase providing the risk-quantified projections needed for executive investment approval.

The process mining infrastructure does not conclude with the diagnosis — it becomes the operational nervous system that detects new problems before they become crises, continuously validating that the improved assignment logic is functioning as designed and evolving as the business changes.