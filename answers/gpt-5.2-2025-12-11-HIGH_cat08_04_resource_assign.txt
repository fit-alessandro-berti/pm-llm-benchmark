## 1) Analyzing Resource Behavior and Assignment Patterns

### 1.1 Build a “resource-aware” event log (foundation)
From the raw incident log, create (or validate) these analysis-ready fields per event/case:

- **Case attributes:** Priority, Category, Required Skill (as captured), Channel, Site/Customer (if available), CI/Application, time of day/day of week.
- **Event attributes:** Activity, Timestamp, Resource (agent), Agent Tier, Agent Skills (set), Assignment group/queue (if exists), “Timestamp Type” (START/COMPLETE).
- **Derived intervals per case:**  
  - **Assignment-to-start (queue time):** `Work X Start – Assign X`  
  - **Handle time:** `Work X End – Work X Start` (or START/COMPLETE)  
  - **Escalation delay:** `Assign L2 – Escalate L2` and similarly for L3  
  - **Reassignment delay:** `next Work Start – Reassign` (and count reassignments)

This enables separating **waiting** (queue/dispatch) from **working** time—critical for SLA breach root causes.

### 1.2 Metrics to assess agents and tiers (L1/L2/L3)

**Workload & utilization**
- **Tickets handled per agent per week**, split by tier and priority.
- **Active time vs waiting time contribution** by tier:
  - % of total lead time spent in queues vs being worked.
- **WIP (Work-in-progress) per agent** over time (how many cases concurrently assigned/open).

**Speed & flow**
- **Median/percentile handle time** per agent/tier/activity (use P50/P75/P90; averages hide tail problems).
- **Queue time distributions** by tier, required skill, priority, and time-of-day (heatmaps).

**Quality/efficiency**
- **L1 First-Call Resolution (FCR) rate:** % cases closed without L2/L3 escalation (overall and by category/required skill).
- **Reassignment rate:** reassignments per case, by agent, by required skill, by queue.
- **Escalation appropriateness proxy:** cases escalated but later resolved by a skill that exists in L1 (possible missed FCR opportunity).

**Skill alignment**
- **Skill-match indicator:** whether assigned agent has the required skill (exact match or “skill family” match).
- **Overqualification indicator:** L2/L3 handling cases historically resolved by L1 with high success (or simple categories).
- **Skill utilization matrix:** for each skill, count of cases + time spent, by tier and by individual agent.

### 1.3 Process mining techniques to reveal actual assignment behavior

**a) Organizational / resource mining (role discovery)**
- Use clustering/role discovery to infer “de facto roles” from behavior:
  - Agents who mostly do “Work L2 on Network” form a discovered role even if formally labeled L2 generalists.
- Compare discovered roles vs HR/roster tiers and documented skill profiles to detect misalignment.

**b) Handover-of-work & social network analysis (SNA)**
- Build handover graphs based on sequences like:
  - L1 agent  dispatcher  L2 agent (or L2  L2 via reassignment)
- Identify:
  - **Bottleneck nodes** (dispatchers/queues that appear in many handovers and add delay)
  - **Ping-pong patterns** (tickets bouncing among the same few agents/queues)
  - **High centrality agents** who become “unofficial routers” (often a sign routing rules aren’t working)

**c) Performance-oriented process discovery**
- Discover the actual incident flow (including reassign loops) and overlay:
  - Waiting times on edges (e.g., *Assign L2  Work L2 Start*)
  - Frequency of rework loops (e.g., *Reassign  Assign L2  Work L2 Start*)

**d) Conformance checking vs intended routing policy**
- Encode intended rules (e.g., “Network/Firewall P2  L2 Networking within X minutes”).
- Measure conformance:
  - % of cases violating “skill first” assignment
  - % of cases violating “no L2 before L1” (if that’s the policy)
  - Deviations that correlate with SLA breaches

### 1.4 Skill utilization effectiveness (specialist vs non-specialist work)
Create a **skill-task segmentation**:

- Define “specialist tasks” (e.g., Networking-Firewall, Database-SQL, Security-IAM) and “commodity tasks” (password resets, basic troubleshooting).
- For each specialist:
  - % of time on commodity tasks
  - # of tickets where required skill  specialist skill set (or doesn’t require specialization)
- For each skill:
  - Demand (cases/week) vs capacity (available skilled agent-hours/week)
  - Queue time and SLA breach rates by skill (reveals scarce-skill bottlenecks)

---

## 2) Identifying Resource-Related Bottlenecks and Issues (and quantifying impact)

### 2.1 Pinpoint bottlenecks
Use **queue-time decomposition** and **skill-based segmentation**:

- For each required skill and tier:
  - `Median(Assign  Work Start)` = skill queue delay
  - `Median(Work Start  Work End)` = handling time
- If queue delay dominates for certain skills (e.g., Networking-Firewall), that’s a capacity or routing bottleneck.

**Capacity red flags**
- A few agents handle a disproportionate share of a skill (high concentration ratio).
- High queue times for a skill during specific shifts (time-of-day effect).

### 2.2 Reassignment/escalation impact
Quantify reassignments as measurable waste:

- **Reassignment count distribution:** % cases with 0/1/2/3+ reassignments.
- **Average delay per reassignment:**  
  `Avg(next Work Start – Reassign)` (or median to avoid outliers)
- **End-to-end impact:** compare lead time for cases with 0 reassignments vs 2+ (variant-based comparison).

Also measure **“wrong-queue first”**:
- % cases where first L2 assignee lacks required skill (skill mismatch at assignment time).
- Resulting incremental delay: difference in queue+resolution time for mismatched vs matched first assignment.

### 2.3 Incorrect initial assignments (L1/dispatcher quality)
Measure “assignment quality” at key points:

- **L1 escalation precision:** among escalated tickets, % that:
  - were resolved at L2 without needing the required specialist skill (could indicate L1 training/KB gap), or
  - got reassigned because required skill was misidentified (categorization gap).
- **Dispatcher assignment precision:** % of Assign L2 that match required skill and avoid reassignment within N hours.

### 2.4 Overloaded vs underutilized agents/teams
Create agent-tier dashboards:
- Utilization proxies: WIP, active time, queue accumulation in their assigned tickets.
- “Overload signature”: high WIP + rising queue times + increasing reassignment outflow.
- “Underuse signature”: low throughput despite having in-demand skills.

### 2.5 Correlate patterns with SLA breaches
Treat SLA breach as an outcome and test drivers:

- Segment breach rate by:
  - required skill, category, tier path (L1-only vs L1L2 vs L1L2L3), # reassignments
- Model statistically:
  - Logistic regression / gradient boosting with features:
    - priority, category, required skill, time-of-day, first assignee tier, skill-match flag, # reassignments, queue times
- Output: **attributable risk** (e.g., “skill mismatch on first L2 assignment increases breach probability by X%”).

---

## 3) Root Cause Analysis for Assignment Inefficiencies

### 3.1 Likely root causes (mapped to evidence)
**Round-robin within tiers ignoring skills/workload**
- Evidence: frequent reassignment loops inside L2; high mismatch rate; uneven WIP.

**Inaccurate skill profiles or stale skills**
- Evidence: agents repeatedly receive tickets requiring skills not listed; or listed skills don’t translate to faster resolution.

**Poor initial categorization / required-skill identification**
- Evidence: high rate of “Required Skill changes” after L2 starts; reassignments accompanied by “needs different skill” notes.

**Lack of real-time visibility**
- Evidence: assignments sent to agents with high WIP while others idle; queue spikes correlate with specific shifts.

**L1 capability/empowerment gap**
- Evidence: low FCR for categories that other L1 agents resolve well; escalations that L2 resolves with basic steps.

### 3.2 Variant analysis (smooth vs problematic cases)
Split cases into cohorts, for example:
- “Smooth”: 0 reassignments, resolved within SLA
- “Problematic”: 2+ reassignments and/or SLA breach

Compare cohorts on:
- First assignment (tier/agent/skill match)
- Category/priority mix
- Queue delays at each tier
- Time-of-day and shift

This often reveals patterns like “P2 Network tickets created after-hours are routed to general L2 first  reassigned to firewall specialist  breach.”

### 3.3 Decision mining to explain bad routing decisions
Apply decision mining at points like **Assign L2** and **Reassign**:

- Target: chosen assignee/queue or whether a reassignment happens.
- Features: required skill, category, priority, channel, current WIP, agent availability, previous resolver patterns, keywords from description (if available).
- Output: interpretable rules (decision trees) such as:
  - “If Category=Network and Priority=P2 and time=after 18:00  assigned to L2 general queue” (leading to delays)
  - “If initial assignee=WIP>10  reassignment likelihood doubles”

This turns “suspected inefficiency” into **explainable causes**.

---

## 4) Data-Driven Resource Assignment Strategies (concrete proposals)

### Strategy A — Skill-based routing with proficiency and “skill family” fallback
**Issue addressed:** skill mismatch, reassignments, specialist queues clogged by wrong work.

**What to implement**
- Route assignments to agents/queues using:
  1) **Required skill exact match** (highest weight)  
  2) **Skill family match** (e.g., Network  Firewall/VPN)  
  3) **Proficiency level** (derived from historical outcomes: resolution speed, reopen rate, reassignment rate for that skill)  
  4) **Priority-aware rules** (P1/P2 prefer best proficiency, not just availability)

**Process mining insights leveraged**
- Skill mismatch rates by activity and tier
- Which agents actually resolve which skills fastest (discovered roles)
- Reassignment loops showing wrong-first assignment

**Data required**
- Reliable required-skill field (or predicted required skill; see Strategy C)
- Agent skill taxonomy + proficiency scores (from event log performance, not only self-reported)
- Historic resolution outcomes (SLA met, reopen, reassignment)

**Expected benefits**
- Fewer L2/L3 reassignments and shorter lead times
- Higher SLA compliance for P2/P3 by reducing “routing waste”
- Better specialist utilization (less time spent on misrouted tickets)

---

### Strategy B — Workload-aware assignment (WIP limits + queue time minimization)
**Issue addressed:** uneven workload, overloaded agents, long queues despite available capacity.

**What to implement**
- Replace pure round-robin with a scoring function per eligible agent:
  - Score = f(skill match, proficiency, current WIP, age of oldest assigned ticket, shift/availability)
- Enforce **WIP caps** by tier/skill:
  - If a specialist hits cap, new tickets route to next-best eligible agent or to a skill queue with explicit SLA-aware ordering.
- Add **priority preemption rules** (P2 can override WIP caps within limits).

**Process mining insights leveraged**
- WIP vs delay relationship per agent (overload signatures)
- Queue heatmaps by shift/time-of-day
- Identification of underutilized agents with relevant skills

**Data required**
- Near-real-time open ticket assignments (from ITSM tool)
- Agent availability/shift schedule
- Event-derived WIP baselines and “safe” WIP thresholds per tier/skill

**Expected benefits**
- Reduced queue time variance and fewer SLA breaches caused by overload
- More predictable performance (especially P3 backlog control)
- Reduced reassignment triggered by “agent too busy” situations

---

### Strategy C — Predictive required-skill and complexity classification at ticket creation
**Issue addressed:** poor categorization/required-skill identification driving wrong routing and escalations.

**What to implement**
- ML/NLP model to predict:
  - **Required skill** (multi-class) and **likely tier needed** (L1 vs L2/L3)
  - Optional: “complexity score” to route complex incidents directly to the right tier/skill queue
- Inputs: category, CI/app, short description, full text, user/org, channel, historical similar tickets.

**Process mining insights leveraged**
- Decision mining showing which attributes drive reassignments/breaches
- Frequent “required skill changes” after work starts (ground truth for misclassification)
- Variants where correct early identification leads to smooth resolution

**Data required**
- Ticket text fields + historical labeled outcomes (final resolver skill/tier)
- Feedback loop: when L2/L3 changes required skill, capture as training signal
- Governance to monitor model drift

**Expected benefits**
- Better first assignment quality, fewer reassignments
- Faster routing for P2/P3, improved SLA adherence
- Reduced dispatcher load (automation support)

---

### Strategy D — Escalation policy optimization + targeted L1 enablement
**Issue addressed:** excessive escalations and specialists doing work L1 could handle.

**What to implement**
- Mine “L1-resolvable” patterns:
  - Identify categories/keywords where L1 success is high and resolution steps are repeatable.
- Implement:
  - **Escalation guardrails** (minimum troubleshooting checklist before escalate)
  - **Suggested KB articles / guided diagnostics** in the ticket UI
  - **Coaching** for L1 agents with low FCR on specific categories (data-driven)

**Process mining insights leveraged**
- FCR by category/agent and the activities performed before escalation
- Variants where L1 resolved successfully vs escalated unnecessarily
- Reopen/reassignment patterns indicating insufficient troubleshooting

**Data required**
- Detailed L1 activity traces (steps taken)
- Knowledge article usage (if available)
- Outcome measures: reopen rates, repeat incidents

**Expected benefits**
- Higher L1 containment, freeing L2/L3 capacity
- Lower end-to-end lead time for P3 volume
- Reduced escalations that create queue pressure and SLA risk

---

## 5) Simulation, Implementation, and Monitoring

### 5.1 Pre-implementation evaluation via simulation (what-if)
Use the mined process model + resource parameters to run **discrete-event simulation**:

**Calibrate from event log**
- Arrival rates by priority/category/time-of-day
- Service time distributions by tier/skill (not just averages)
- Routing probabilities (current vs proposed)
- Reassignment probabilities conditional on mismatch
- Resource calendars (shifts) and WIP behaviors

**Scenarios to simulate**
- Baseline (current round-robin + manual escalation)
- Strategy A only (skill-based)
- A + B combined (skill + workload-aware)
- A + B + C (add predictive classification)
- Add staffing changes (e.g., add 1 firewall specialist shift coverage)

**Outputs to compare**
- SLA attainment by priority (P2/P3 focus)
- Mean/median/P90 resolution time
- Queue times by tier/skill
- Reassignment counts
- Specialist utilization and commodity-work share

This makes trade-offs explicit (e.g., “skill-based routing improves SLA but increases load on scarce skill; workload-aware balances but may slightly increase handle time for low priority”).

### 5.2 Implementation plan (practical)
1) **Pilot scope:** pick top 2–3 high-breach categories/skills (e.g., Network-Firewall, App-CRM).  
2) **Deploy routing logic** in the ITSM assignment engine (or via a routing service).  
3) **Run parallel monitoring**: keep old routing as control group if possible (A/B test by queue, site, or time window).  
4) **Iterate thresholds** (proficiency weights, WIP caps, escalation guardrails) based on observed performance.

### 5.3 Post-implementation monitoring with process mining dashboards
Set up continuous dashboards with alerts:

**Assignment quality**
- % first assignments skill-matched (exact/family)
- Reassignment rate within 24h (early rework indicator)
- “Wrong-tier first” rate (L1 vs direct L2/L3 when predicted complex)

**Flow efficiency**
- Queue time by tier/skill/priority (P50/P90)
- End-to-end resolution time by segment
- Escalation rates and paths (L1-only, L1L2, L1L2L3)

**Resource health**
- WIP distribution by agent and tier
- Utilization/throughput per agent (with fairness metrics; identify chronic overload)
- Specialist time spent on commodity tasks (%)

**SLA control**
- SLA breach rate by priority, required skill, and assignment policy version
- Breach early-warning: rising queue time for a skill + low capacity on shift

**Conformance & drift**
- Conformance to new routing rules (why deviations happen)
- Drift detection: changes in ticket mix (new apps, seasonal spikes) degrading model/rules

---

### Summary of expected outcomes
By combining organizational mining (actual roles/handovers), performance decomposition (queue vs work), and decision/variant mining (why assignments go wrong), TechSolve can move from manual/round-robin routing to **skill- and workload-aware assignment** supported by **predictive classification** and **data-driven L1 enablement**. The result should be fewer reassignments, better specialist utilization, reduced queue times for key skills, and improved P2/P3 SLA performance—validated first via simulation and sustained via continuous process-mining monitoring.