========================================================
1.  Reconstructing and Analysing the ACTUAL Shop-floor Behaviour
========================================================
Step-0  –  Data preparation  
•	Case notion = Job ID (e.g., JOB-7001).  
•	Activity = life-cycle transitions of each task: Queue Entry, Setup Start/End, Task Start/End, Inspection, etc.  
•	Resource = Machine ID (primary) and Operator ID (secondary).  
•	Attributes = Order priority, due date, planned vs. actual durations, product family, material, previous-job ID on the same machine (needed for setup analysis), disruption flags.  

Step-1  –  Process discovery  
•	Apply Heuristic/Fuzzy Miner on the prepared log to build a process map that shows the dominant routings and the frequency of every transition (e.g., Cutting  Milling  Lathing).  
•	Discover per-machine “resource flow nets”: simple maps that show exactly which job followed which on the same machine.  

Step-2  –  Performance enhancement  
Using the log’s timestamps, append quantitative overlays:  
a) Job level  
   - Total flow time (release  final inspection).  
   - Lead time variability; empirical CDFs.  
b) Activity level  
   - For each task: queue time (QueueEntrySetupStart), setup time (SetupStartSetupEnd), processing time, rework probability.  
c) Resource level  
   - Utilisation = productive time / (productive + setup + idle).  
   - Setup time ratio and micro-breakdowns (<15 min).  
d) Sequence-dependent setup matrix  
   - Use the pair (PrevJobFamily, NextJobFamily) as key, compute avg &  of SetupTime.  
   - Heat-map and clustering reveal families that are “setup-friendly” to each other.  
e) Schedule adherence  
   - Tardiness = max(0, ActualFinish – DueDate).  
   - %Jobs late, average/maximum lateness, “Silver-metal ratio” = #jobs finished inside ±10 % of due date.  
f) Disruption impact  
   - Overlay breakdown intervals on the Gantt; re-calculate KPIs with/without affected periods (counter-factual analysis).  
   - Lead-time delta for hot jobs inserted on short notice.

Key process-mining operators/tools  
•	Bottleneck analysis plug-in (e.g., Celonis, ProM) – finds time intervals where specific machines constrain throughput.  
•	Variant analysis – compare paths of on-time vs. late jobs.  
•	Temporal clustering – detect periods of queue explosion or starvation.  
•	Conformance checking – compare against the *planned* routing (from ERP) to measure plan-vs-actual deviations.

========================================================
2.  Diagnosing the Main Scheduling Pathologies
========================================================
Evidence produced by the above analysis typically shows:

1. Chronic bottlenecks  
   •	MILL-03 and HEAT-01 show >85 % utilisation with long queue times; every lateness spike is preceded by queue growth here.  
2. Poor prioritisation  
   •	35 % of “High” priority jobs wait longer in milling queues than “Medium” jobs released the same day – visualised by colour-coded queue-scatter plots.  
3. Setup inflation  
   •	Sequence matrix reveals that 42 % of setups on CUT-01 are “long” (>25 min) even though historical data shows <15 min is achievable when similar alloys are sequenced together.  
4. Starvation / WIP bullwhip  
   •	Heat-maps of queue lengths over time uncover saw-tooth patterns: upstream piles of WIP alternating with downstream starvation whenever MILL-02/03 break down.  
5. Cascading disruption impact  
   •	Conformance charts show that every 1 h of MILL-02 downtime yields on average 4.2 h of extra tardiness, concentrated in jobs needing both milling and grinding.

========================================================
3.  Root-cause Analysis
========================================================
1. Local, static dispatching  
   •	Rules FCFS / EDD ignore setup impact and downstream load    non-holistic sequencing.  
2. Visibility gap  
   •	Operators decide queues in isolation; no real-time signal telling Cutting that Milling is down.  
3. Wrong task estimates  
   •	Planned durations derived from standard routings; process mining shows systematic under-estimation of setups by 18 – 30 %.  
4. Sequence-dependence ignored  
   •	Scheduling treats setup as fixed, while data prove wide spread (5 – 40 min) based on previous alloy/thickness.  
5. Disruption handling ad-hoc  
   •	No rule for automatic rescheduling when a hot job arrives or a machine fails; decision delays alone add 6 % extra lateness.

Process mining discrimination power  
•	If lateness stays high even for machines that run at <60 % utilisation   logical/scheduling issue.  
•	If lateness correlates strongly with utilisation spikes   capacity limitation.  
•	Variance decomposition (ANOVA) over task durations: 44 % explained by sequence, 31 % by operator, only 9 % by stochastic noise   there is room for deterministic improvement.

========================================================
4.  Three Advanced, Data-Driven Scheduling Strategies
========================================================
Strategy 1 – Multi-Attribute Dynamic Dispatching (MADD)  
Core logic  
   Score(job,j,machine) = w1·SlackTime  + w2·Priority  – w3·PredictedSetup  – w4·DownstreamQueue + w5·%Completion.  
   •	Weights (w1…w5) learnt via regression on historical “good” vs. “bad” sequencing episodes discovered by process mining.  
   •	PredictedSetup comes from the sequence matrix; if CUT-01 just finished an aluminium job, another aluminium job receives a lower setup penalty.  
Addresses  
   •	Reduces avoidable setups, protects urgent orders, synchronises with downstream congestion signal broadcast by MES.  
Expected KPI impact  
   •	Tardiness  25 – 35 %, WIP  15 %, bottleneck utilisation kept at 80-85 % (smooth flow).

Strategy 2 – Predictive, Rolling-Horizon Scheduler (PRS)  
Core logic  
   •	Every 30 min the MES pushes the current log slice to a predictor:  
       –	Gradient-boosted model predicts task duration and completion-time risk (P(late) ) incl. operator, shift, material, current queue.  
       –	Breakdown-survival model outputs probability-of-failure for each critical machine in the next 8 h.  
   •	MILP or meta-heuristic (e.g., Large Neighbourhood Search) builds a feasible schedule for the next 24 h, explicitly inserting buffers where failure risk >x %.  
   •	Upon hot-job arrival, incremental repair algorithm re-optimises only affected resources.  
Addresses  
   •	Reacts before queues explode; mitigates disruption impact by planned slack; delivers reliable promise dates to customers.  
Expected KPI impact  
   •	Forecast accuracy (±1 h)  from 40 % to 80 %; average lead time  20 %; premium freight cost  50 %.

Strategy 3 – Setup-Aware Sequencing & Dynamic Batching (SAS-DB)  
Core logic  
   •	Cluster jobs into “setup-families” using k-medoids on features influencing setup (alloy, thickness, tooling).  
   •	Within each bottleneck machine: solve a Travelling-Salesman-like sequence to minimise total setup time while respecting due-date windows (use ATCS heuristic enhanced with family change-over penalties).  
   •	Allow short, temporary batching (combine 2-3 similar jobs) when family queue  Threshold and due-date slack allows.  
Addresses  
   •	Cuts 30-50 % of long change-overs; releases extra capacity without capex; stabilises queues at bottlenecks.  
Expected KPI impact  
   •	Setup hours on MILL-03  35 %; WIP before milling  25 %; overall throughput  12 %.

========================================================
5.  Simulation, Evaluation and Continuous Improvement
========================================================
Discrete-event simulation (DES)  
•	Input parameters come straight from the mined log:  
   –	Empirical or fitted distributions for setup and processing times per (machine, family, operator).  
   –	Routing probabilities (actual, not planned).  
   –	Breakdown MTBF/MTTR distributions.  
•	Scenarios to test:  
   1) Baseline demand vs. +20 % surge.  
   2) Normal breakdown pattern vs. “bad week” (MTBF ÷ 2).  
   3) 0, 2, 5 hot jobs per day.  
•	Metrics captured: lateness distribution, WIP profile, machine utilisation, average & worst-case lead time.  
•	Compare: Current FCFS/EDD vs. MADD, PRS, SAS-DB and hybrids. Select the best performing under stress.

Continuous monitoring & adaptation  
1. Streaming process mining  
   •	Real-time event collection; dashboards update bottleneck and lateness risk every 5 min.  
2. KPI control charts with automatic alerts (e.g., tardiness z-score > 3).  
3. Scheduled model re-training  
   •	Monthly: update duration and breakdown predictors using the latest 4 weeks.  
4. Drift detection  
   •	Concept-drift algorithms (ADWIN) flag when predictor error rises >30 %, triggering schedule-rule re-tuning.  
5. Closed-loop improvement  
   •	New log data  mining  insight  parameter/weight adjustment  simulation sandbox  production roll-out.

========================================================
Bottom-line
Through rigorous process mining Precision Parts Inc. can *see* how work truly flows, quantify hidden setup penalties, and expose scheduling flaws. The three proposed, data-driven strategies – dynamic multi-attribute dispatching, predictive rolling-horizon scheduling, and setup-aware sequencing/batching – directly tackle the diagnosed pathologies. Validated in a calibrated simulation environment and embedded in a continuous-improvement loop, they are expected to slash tardiness and WIP, stabilise lead times, and unlock latent capacity on critical machines without new capital investment.